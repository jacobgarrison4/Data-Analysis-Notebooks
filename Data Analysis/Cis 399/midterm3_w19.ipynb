{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "midterm3_w19.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "CcejYk1YkV0f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h1>\n",
        "<center>\n",
        "Midterm 3\n",
        "</center>\n",
        "</h1>\n",
        "<div class=h1_cell>\n",
        "<p>\n",
        "There are 2 parts on the midterm, 50 points each. Each part has 3 questions.\n",
        "<p>\n",
        "We will use the Titanic table for this midterm. I have a wrangled version of it on google sheets that I set up for you.\n",
        "<p>\n",
        "</div>"
      ]
    },
    {
      "metadata": {
        "id": "vkh1bqA3kV0m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "titanic_table = pd.read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vR2XbLnUuYlxaFMdS8_bBX3iKUIDEii6Lg5Rxesf-Oh8a6z8-vAN6UDGejaOrBg5130h4O_dLkecKWQ/pub?output=csv')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uScGH6USkV0r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_columns', None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5AEsijjqF3JH",
        "colab_type": "code",
        "outputId": "dc800d33-a9a8-4e83-b0c0-e2ed4f89b91d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        }
      },
      "cell_type": "code",
      "source": [
        "titanic_table.head(1)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "      <th>no_age</th>\n",
              "      <th>filled_age</th>\n",
              "      <th>emb_C</th>\n",
              "      <th>emb_Q</th>\n",
              "      <th>emb_S</th>\n",
              "      <th>emb_nan</th>\n",
              "      <th>age_bin</th>\n",
              "      <th>age_Child</th>\n",
              "      <th>age_Adult</th>\n",
              "      <th>age_Senior</th>\n",
              "      <th>sex_female</th>\n",
              "      <th>sex_male</th>\n",
              "      <th>ok_child</th>\n",
              "      <th>pclass_1</th>\n",
              "      <th>pclass_2</th>\n",
              "      <th>pclass_3</th>\n",
              "      <th>pclass_nan</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.25</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "      <td>0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Child</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Survived  Pclass                     Name   Sex   Age  SibSp  Parch  \\\n",
              "0         0       3  Braund, Mr. Owen Harris  male  22.0      1      0   \n",
              "\n",
              "      Ticket  Fare Cabin Embarked  no_age  filled_age  emb_C  emb_Q  emb_S  \\\n",
              "0  A/5 21171  7.25   NaN        S       0        22.0      0      0      1   \n",
              "\n",
              "   emb_nan age_bin  age_Child  age_Adult  age_Senior  sex_female  sex_male  \\\n",
              "0        0   Child          1          0           0           0         1   \n",
              "\n",
              "   ok_child  pclass_1  pclass_2  pclass_3  pclass_nan  \n",
              "0         0         0         0         1           0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "k8aUB0VpgqXA",
        "colab_type": "code",
        "outputId": "d4a0cca5-ced0-4f73-9a52-364c606d16cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "!rm library_w19_week7.py"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'library_w19_week7.py': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dnHr-TA6gvK5",
        "colab_type": "code",
        "outputId": "bcf2c514-8c08-4157-8ee5-d144fb370829",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5dad3e31-69bf-48b7-b298-e1420be972dd\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-5dad3e31-69bf-48b7-b298-e1420be972dd\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving library_w19_week7.py to library_w19_week7.py\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'library_w19_week7.py': b'import pandas as pd\\r\\nimport numpy as np\\r\\nfrom functools import reduce\\r\\nfrom types import SimpleNamespace\\r\\nimport random\\r\\nimport matplotlib.pyplot as plt  \\r\\nimport operator\\r\\n\\r\\ndef predictor_case(row, pred, target):\\r\\n  case_dict = {(0,0): \\'true_negative\\', (1,1): \\'true_positive\\', (0,1): \\'false_negative\\', (1,0): \\'false_positive\\'}\\r\\n  actual = row[target]\\r\\n  prediction = row[pred]\\r\\n  case = case_dict[(prediction, actual)]\\r\\n  return case\\r\\n\\r\\ndef informedness(cases):\\r\\n  tp = 0\\r\\n  if \\'true_positive\\' in cases:\\r\\n    tp = cases[\\'true_positive\\']\\r\\n  tn = 0\\r\\n  if \\'true_negative\\' in cases:\\r\\n    tn = cases[\\'true_negative\\']\\r\\n  fp = 0\\r\\n  if \\'false_positive\\' in cases:\\r\\n    fp = cases[\\'false_positive\\']\\r\\n  fn = 0\\r\\n  if \\'false_negative\\' in cases:\\r\\n    fn = cases[\\'false_negative\\']\\r\\n  if (((tp+fn) == 0) or ((tn+fp) == 0)):\\r\\n    return -1\\r\\n  else:\\r\\n    recall = 1.0*tp/(tp+fn)\\r\\n    specificity = 1.0*tn/(tn+fp)\\r\\n    J = (recall + specificity) - 1\\r\\n    \\r\\n  return J\\r\\n\\r\\ndef accuracy(cases):\\r\\n  tp = 0\\r\\n  if \\'true_positive\\' in cases:\\r\\n    tp = cases[\\'true_positive\\']\\r\\n  tn = 0\\r\\n  if \\'true_negative\\' in cases:\\r\\n    tn = cases[\\'true_negative\\']\\r\\n  fp = 0\\r\\n  if \\'false_positive\\' in cases:\\r\\n    fp = cases[\\'false_positive\\']\\r\\n  fn = 0\\r\\n  if \\'false_negative\\' in cases:\\r\\n    fn = cases[\\'false_negative\\']\\r\\n  if (tp + tn + fp + fn) == 0:\\r\\n    return 0\\r\\n  else:\\r\\n    return (tp + tn)/(tp+tn+fp+fn)\\r\\n\\r\\ndef f1(cases):\\r\\n  #the heart of the matrix\\r\\n  tp = 0\\r\\n  if \\'true_positive\\' in cases:\\r\\n    tp = cases[\\'true_positive\\']\\r\\n  tn = 0\\r\\n  if \\'true_negative\\' in cases:\\r\\n    tn = cases[\\'true_negative\\']\\r\\n  fp = 0\\r\\n  if \\'false_positive\\' in cases:\\r\\n    fp = cases[\\'false_positive\\']\\r\\n  fn = 0\\r\\n  if \\'false_negative\\' in cases:\\r\\n    fn = cases[\\'false_negative\\']\\r\\n\\t\\r\\n\\t#other measures we can derive\\r\\n  if (((tp+fn) == 0) or ((tp+fp) == 0)):\\r\\n    return 0\\r\\n  else:\\r\\n    recall = 1.0*tp/(tp+fn)\\r\\n    precision = 1.0*tp/(tp+fp)\\r\\n\\t\\r\\n\\t#now for the one we want\\r\\n  if ((recall == 0) or (precision == 0)):\\r\\n    return 0\\r\\n  else:\\r\\n\\t   f1 = 2/(1/recall + 1/precision)\\r\\n\\t\\r\\n  return f1\\r\\n\\r\\ndef gig(starting_table, split_column, target_column):\\r\\n    \\r\\n    #split into two branches, i.e., two sub-tables\\r\\n    true_table = starting_table.loc[starting_table[split_column] == 1]\\r\\n    false_table = starting_table.loc[starting_table[split_column] == 0]\\r\\n    \\r\\n    #Now see how the target column is divided up in each sub-table (and the starting table)\\r\\n    true_counts = true_table[target_column].value_counts()  # Note using true_table and not starting_table\\r\\n    false_counts = false_table[target_column].value_counts()  # Note using false_table and not starting_table\\r\\n    starting_counts = starting_table[target_column].value_counts() \\r\\n    \\r\\n    #compute the gini impurity for the 3 tables\\r\\n    starting_gini = gini(starting_counts)\\r\\n    true_gini = gini(true_counts)\\r\\n    false_gini = gini(false_counts)\\r\\n\\r\\n    #compute the weights\\r\\n    starting_size = len(starting_table.index)\\r\\n    true_weight = 0.0 if starting_size == 0 else len(true_table.index)/starting_size\\r\\n    false_weight = 0.0 if starting_size == 0 else len(false_table.index)/starting_size\\r\\n    \\r\\n    #wrap it up and put on a bow\\r\\n    gig = starting_gini - (true_weight * true_gini + false_weight * false_gini)\\r\\n    \\r\\n    return gig\\r\\n\\r\\ndef gini(counts):\\r\\n    (p0,p1) = probabilities(counts)\\r\\n    sum_probs = p0**2 + p1**2\\r\\n    gini = 1 - sum_probs\\r\\n    return gini\\r\\n\\r\\ndef probabilities(counts):\\r\\n    count_0 = 0 if 0 not in counts else counts[0]  #could have no 0 values\\r\\n    count_1 = 0 if 1 not in counts else counts[1]\\r\\n    total = count_0 + count_1\\r\\n    probs = (0,0) if total == 0 else (count_0/total, count_1/total)  #build 2-tuple\\r\\n    return probs\\r\\n\\r\\ndef build_pred(column, branch):\\r\\n    return lambda row: row[column] == branch\\r\\n\\r\\ndef find_best_splitter(table, choice_list, target):\\r\\n  \\r\\n    assert (len(table)>0),\"Cannot split empty table\"\\r\\n    assert (target in table),\"Target must be column in table\"\\r\\n    \\r\\n    gig_scores = map(lambda col: (col, gig(table, col, target)), choice_list)  #compute tuple (col, gig) for each column\\r\\n    gig_sorted = sorted(gig_scores, key=lambda item: item[1], reverse=True)  # sort on gig\\r\\n    return gig_sorted\\r\\n\\r\\nfrom functools import reduce\\r\\n\\r\\ndef generate_table(table, conjunction):\\r\\n  \\r\\n    assert (len(table)>0),\"Cannot generate from empty table\"\\r\\n\\r\\n    sub_table = reduce(lambda subtable, pair: subtable.loc[pair[1]], conjunction, table)\\r\\n    return sub_table\\r\\n\\r\\ndef compute_prediction(table, target):\\r\\n  \\r\\n    assert (len(table)>0),\"Cannot predict from empty table\"\\r\\n    assert (target in table),\"Target must be column in table\"\\r\\n    \\r\\n    counts = table[target].value_counts()  # counts looks like {0: v1, 1: v2}\\r\\n\\r\\n    if 0 not in counts:\\r\\n        prediction = 1\\r\\n    elif 1 not in counts:\\r\\n        prediction = 0\\r\\n    elif counts[1] > counts[0]:  # ties go to 0 (negative)\\r\\n        prediction = 1\\r\\n    else:\\r\\n        prediction = 0\\r\\n\\r\\n    return prediction\\r\\n\\r\\ndef build_tree_iter(table, choices, target, hypers={} ):\\r\\n\\r\\n    assert (len(choices)>0),\"Must have at least one column in choices\"\\r\\n    assert (target in table), \"Target column not in table\"\\r\\n    assert (len(table) > 1), \"Table must have more than 1 row\"\\r\\n    \\r\\n    k = hypers[\\'max-depth\\'] if \\'max-depth\\' in hypers else min(4, len(choices))\\r\\n    gig_cutoff = hypers[\\'gig-cutoff\\'] if \\'gig-cutoff\\' in hypers else 0.0\\r\\n    \\r\\n    def iterative_build(k):\\r\\n        columns_sorted = find_best_splitter(table, choices, target)\\r\\n        (best_column, gig_value) = columns_sorted[0]\\r\\n        \\r\\n        #Note I add _1 or _0 to make it more readable for debugging\\r\\n        current_paths = [{\\'conjunction\\': [(best_column, build_pred(best_column, 1))],\\r\\n                          \\'prediction\\': None,\\r\\n                          \\'gig_score\\': gig_value},\\r\\n                         {\\'conjunction\\': [(best_column, build_pred(best_column, 0))],\\r\\n                          \\'prediction\\': None,\\r\\n                          \\'gig_score\\': gig_value}\\r\\n                        ]\\r\\n        k -= 1  # we just built a level as seed so subtract 1 from k\\r\\n        tree_paths = []  # add completed paths here\\r\\n        \\r\\n        while k>0:\\r\\n            new_paths = []\\r\\n            for path in current_paths:\\r\\n                old_conjunction = path[\\'conjunction\\']  # a list of (name, lambda)\\r\\n                before_table = generate_table(table, old_conjunction)  #the subtable the current conjunct leads to\\r\\n                columns_sorted = find_best_splitter(before_table, choices, target)\\r\\n                (best_column, gig_value) = columns_sorted[0]\\r\\n                if gig_value > gig_cutoff:\\r\\n                    new_path_1 = {\\'conjunction\\': old_conjunction + [(best_column, build_pred(best_column, 1))],\\r\\n                                \\'prediction\\': None,\\r\\n                                 \\'gig_score\\': gig_value}\\r\\n                    new_paths.append( new_path_1 ) #true\\r\\n                    new_path_0 = {\\'conjunction\\': old_conjunction + [(best_column, build_pred(best_column, 0))],\\r\\n                                \\'prediction\\': None,\\r\\n                                 \\'gig_score\\': gig_value}\\r\\n                    new_paths.append( new_path_0 ) #false\\r\\n                else:\\r\\n                    #not worth splitting so complete the path with a prediction\\r\\n                    path[\\'prediction\\'] = compute_prediction(before_table, target)\\r\\n                    tree_paths.append(path)\\r\\n            #end for loop\\r\\n            \\r\\n            current_paths = new_paths\\r\\n            if current_paths != []:\\r\\n                k -= 1\\r\\n            else:\\r\\n                break  # nothing left to extend so have copied all paths to tree_paths\\r\\n        #end while loop\\r\\n\\r\\n        #Generate predictions for all paths that have None\\r\\n        for path in current_paths:\\r\\n            conjunction = path[\\'conjunction\\']\\r\\n            before_table = generate_table(table, conjunction)\\r\\n            path[\\'prediction\\'] = compute_prediction(before_table, target)\\r\\n            tree_paths.append(path)\\r\\n        return tree_paths\\r\\n\\r\\n    return {\\'paths\\': iterative_build(k), \\'weight\\': None}\\r\\n\\r\\ndef tree_predictor(row, tree):\\r\\n    \\r\\n    #go through each path, one by one (could use a map instead of for loop?)\\r\\n    for path in tree[\\'paths\\']:\\r\\n        conjuncts = path[\\'conjunction\\']\\r\\n        result = map(lambda tuple: tuple[1](row), conjuncts)  # potential to be parallelized\\r\\n        if all(result):\\r\\n            return path[\\'prediction\\']\\r\\n    raise LookupError(\\'No true paths found for row: \\' + str(row))\\r\\n\\r\\ndef path_id(row, tree):\\r\\n\\tassert (len(tree[\\'paths\\']) > 0)\\r\\n\\tfor path in tree[\\'paths\\']:\\r\\n\\t\\tconjuncts = path[\\'conjunction\\']\\r\\n\\t\\tresult = map(lambda tuple: tuple[1](row), conjuncts)  # potential to be parallelized\\r\\n\\t\\tif all(result):\\r\\n\\t  \\t\\treturn tree[\\'paths\\'].index(path)\\r\\n\\r\\ndef reorder_paths(table, tree):\\r\\n\\tpath_count = table.apply(lambda row: path_id(row, tree), axis = 1)\\r\\n\\tvalue = path_count.value_counts()\\r\\n\\tpath = sorted(value.items(), key=lambda x: x[1], reverse=True)\\r\\n\\tprint(path)\\r\\n\\tnew_paths = []\\r\\n\\tprev_path = tree3[\\'paths\\']\\r\\n\\tfor a, b in plist3:\\r\\n\\t\\tprev = prev_path[a]\\r\\n\\t\\tnew_paths.append(prev)\\r\\n\\treturn new_paths\\r\\n\\r\\ndef produce_scores(table, tree, target):\\r\\n    scratch_table = pd.DataFrame(columns=[\\'prediction\\', \\'actual\\'])\\r\\n    scratch_table[\\'prediction\\'] = table.apply(lambda row: tree_predictor(row, tree), axis=1)\\r\\n    scratch_table[\\'actual\\'] = table[target]  # just copy the target column\\r\\n    cases = scratch_table.apply(lambda row: predictor_case(row, pred=\\'prediction\\', target=\\'actual\\'), axis=1)\\r\\n    vc = cases.value_counts()\\r\\n    return [accuracy(vc), f1(vc), informedness(vc)]\\r\\n\\r\\ndef k_fold(table, k, target, hypers, candidate_columns):\\r\\n  \\r\\n    #set up the table where we will record fold results\\r\\n    result_columns = [\\'name\\',  \\'accuracy\\', \\'f1\\', \\'informedness\\']\\r\\n    k_fold_results_table = pd.DataFrame(columns=result_columns)\\r\\n    \\r\\n    #generate the slices\\r\\n    total_len = len(table.index)\\r\\n    slice_size = int(total_len/(1.0*k))\\r\\n    slices = []\\r\\n    for i in range(k-1):\\r\\n        a_slice =  table[i*slice_size:(i+1)*slice_size]\\r\\n        slices.append( a_slice )\\r\\n    slices.append( table[(k-1)*slice_size:] )  # whatever is left\\r\\n    \\r\\n    #generate test results\\r\\n    all_scores = []  #keep track of all k results\\r\\n    for i in range(k):\\r\\n        test_table = slices[i]\\r\\n        train_table = compute_training(slices, i)\\r\\n        fold_tree = build_tree_iter(train_table, candidate_columns, target, hypers)  # train\\r\\n        scores = produce_scores(test_table, fold_tree, target)  # test\\r\\n        results_row = {\\'name\\': \\'fold_\\'+str(i), \\'accuracy\\': scores[0], \\'f1\\': scores[1], \\'informedness\\': scores[2]}\\r\\n        k_fold_results_table = k_fold_results_table.append(results_row,ignore_index=True)\\r\\n        all_scores.append(scores)\\r\\n    \\r\\n    #compute average of all folds\\r\\n    avg_scores = tuple(reduce(lambda total, triple: np.add(triple, total), all_scores)/k)\\r\\n    results_row = {\\'name\\': \\'average\\', \\'accuracy\\': avg_scores[0], \\'f1\\': avg_scores[1], \\'informedness\\': avg_scores[2]}\\r\\n    k_fold_results_table = k_fold_results_table.append(results_row,ignore_index=True)\\r\\n    \\r\\n    #note that I add the meta comment as last step to avoid it being wiped out\\r\\n    k_fold_results_table.meta = SimpleNamespace()\\r\\n    k_fold_results_table.meta.hypers  = hypers # adds comment to remind me of hyper params used\\r\\n    \\r\\n    return k_fold_results_table\\r\\n\\r\\ndef compute_training(slices, left_out):\\r\\n    training_slices = []\\r\\n    for i,slice in enumerate(slices):\\r\\n        if i == left_out:\\r\\n            continue\\r\\n        training_slices.append(slices[i])\\r\\n    return pd.concat(training_slices)\\r\\n\\r\\nfrom sklearn.utils import shuffle\\r\\n\\r\\n#Determine if slices are mutually exclusive\\r\\ndef verify_unique(slices):\\r\\n    print((\\'total length all slices\\', sum([len(s) for s in slices])))\\r\\n    for i, a_slice in enumerate(slices[:-1]):\\r\\n        a_set = set(a_slice.index)\\r\\n        for j, b_slice in enumerate(slices[i+1:]):\\r\\n            b_set = set(b_slice.index)\\r\\n            int_set = a_set.intersection(b_set)  # should be empty set as result\\r\\n            print((i,j+i+1,int_set))\\r\\n    return None\\r\\n\\r\\ndef k_fold_random(table, k, target, hypers, candidate_columns):\\r\\n  #set up the table where we will record fold results\\r\\n    result_columns = [\\'name\\',  \\'accuracy\\', \\'f1\\', \\'informedness\\']\\r\\n    k_fold_results_table = pd.DataFrame(columns=result_columns)\\r\\n    \\r\\n    #generate the slices\\r\\n    # here is sequential slice code from k_fold if you want to use it as base.\\r\\n    # modify it to produce slices with random rows in each slice.\\r\\n\\r\\n    table = shuffle(loan_table)\\r\\n    total_len = len(table.index)\\r\\n    slice_size = int(total_len/(1.0*k))\\r\\n    slices = []\\r\\n    #generate the slices\\r\\n    for i in range(k-1):\\r\\n      a_slice =  table[i*slice_size:(i+1)*slice_size]\\r\\n      slices.append( a_slice )\\r\\n    slices.append( table[(k-1)*slice_size:] )\\r\\n\\r\\n    verify_unique(slices)  # I ask you to define this debugging function below\\r\\n    \\r\\n    #generate test results\\r\\n    all_scores = []  #keep track of all k results\\r\\n    for i in range(k):\\r\\n        test_table = slices[i]\\r\\n        train_table = compute_training(slices, i)\\r\\n        fold_tree = build_tree_iter(train_table, candidate_columns, target, hypers)  # train\\r\\n        scores = produce_scores(test_table, fold_tree, target)  # test\\r\\n        results_row = {\\'name\\': \\'fold_\\'+str(i), \\'accuracy\\': scores[0], \\'f1\\': scores[1], \\'informedness\\': scores[2]}\\r\\n        k_fold_results_table = k_fold_results_table.append(results_row,ignore_index=True)\\r\\n        all_scores.append(scores)\\r\\n    \\r\\n    #compute average of all folds\\r\\n    avg_scores = tuple(reduce(lambda total, triple: np.add(triple, total), all_scores)/5)\\r\\n    results_row = {\\'name\\': \\'average\\', \\'accuracy\\': avg_scores[0], \\'f1\\': avg_scores[1], \\'informedness\\': avg_scores[2]}\\r\\n    k_fold_results_table = k_fold_results_table.append(results_row,ignore_index=True)\\r\\n    \\r\\n    #note that I add the meta comment as last step to avoid it being wiped out\\r\\n    k_fold_results_table.meta = SimpleNamespace()\\r\\n    k_fold_results_table.meta.hypers  = hypers # adds comment to remind me of hyper params used\\r\\n    \\r\\n    return k_fold_results_table\\r\\n\\r\\ndef vote_taker(row, forest):\\r\\n    votes = {0:0, 1:0}\\r\\n    for tree in forest:\\r\\n        prediction = tree_predictor(row, tree)\\r\\n        votes[prediction] += 1\\r\\n    winner = 1 if votes[1]>votes[0] else 0  #ties go to 0\\r\\n    return winner\\r\\n\\r\\ndef forest_scores(table, forest, target):\\r\\n    scratch_table = pd.DataFrame(columns=[\\'prediction\\', \\'actual\\'])\\r\\n    scratch_table[\\'prediction\\'] = table.apply(lambda row: vote_taker(row, forest), axis=1)  #only change is to call vote_taker\\r\\n    scratch_table[\\'actual\\'] = table[target]  # just copy the target column\\r\\n    cases = scratch_table.apply(lambda row: predictor_case(row, pred=\\'prediction\\', target=\\'actual\\'), axis=1)\\r\\n    vc = cases.value_counts()\\r\\n    return [accuracy(vc), f1(vc), informedness(vc)]\\r\\n\\r\\ndef forest_builder(table, column_choices, target, hypers):\\r\\n\\r\\n    tree_n = 5 if \\'total-trees\\' not in hypers else hypers[\\'total-trees\\']\\r\\n    m = int(len(column_choices)**.5) if \\'m\\' not in hypers else hypers[\\'m\\']\\r\\n    k = hypers[\\'max-depth\\'] if \\'max-depth\\' in hypers else min(2, len(column_choices))\\r\\n    gig_cutoff = hypers[\\'gig-cutoff\\'] if \\'gig-cutoff\\' in hypers else 0.0\\r\\n    rgen = hypers[\\'random-state\\'] if \\'random-state\\' in hypers else 0  #an int will work as seed with the sample method.\\r\\n\\r\\n    #build a single tree of depth n - call it multiple times to build multiple trees\\r\\n    def iterative_build(n):\\r\\n        train = table.sample(frac=1.0, replace=True, random_state=rgen)\\r\\n        train = train.reset_index()\\r\\n        left_out = table.loc[~table.index.isin(train[\\'index\\'])]\\r\\n        left_out = left_out.reset_index() # this gives us the old index in its own column\\r\\n        oob_list = left_out[\\'index\\'].tolist()  # list of row indices from original titanic table\\r\\n        \\r\\n        rcols = random.sample(column_choices, m)  # subspcace sampling - uses random.seed, not rng\\r\\n        columns_sorted = find_best_splitter(train, rcols, target)\\r\\n        (best_column, gig_value) = columns_sorted[0]\\r\\n\\r\\n        #Note I add _1 or _0 to make it more readable for debugging\\r\\n        current_paths = [{\\'conjunction\\': [(best_column+\\'_1\\', build_pred(best_column, 1))],\\r\\n                          \\'prediction\\': None,\\r\\n                          \\'gig_score\\': gig_value},\\r\\n                         {\\'conjunction\\': [(best_column+\\'_0\\', build_pred(best_column, 0))],\\r\\n                          \\'prediction\\': None,\\r\\n                          \\'gig_score\\': gig_value}\\r\\n                        ]\\r\\n        n -= 1  # we just built a level as seed so subtract 1 from n\\r\\n        tree_paths = []  # add completed paths here\\r\\n\\r\\n        while n>0:\\r\\n            new_paths = []\\r\\n            for path in current_paths:\\r\\n                conjunct = path[\\'conjunction\\']  # a list of (name, lambda)\\r\\n                before_table = generate_table(train, conjunct)  #the subtable the current conjunct leads to\\r\\n                rcols = random.sample(column_choices, m)  # subspace\\r\\n                columns_sorted = find_best_splitter(before_table, rcols, target)\\r\\n                (best_column, gig_value) = columns_sorted[0]\\r\\n                if gig_value > gig_cutoff:\\r\\n                    new_path_1 = {\\'conjunction\\': conjunct + [(best_column+\\'_1\\', build_pred(best_column, 1))],\\r\\n                                \\'prediction\\': None,\\r\\n                                 \\'gig_score\\': gig_value}\\r\\n                    new_paths.append( new_path_1 ) #true\\r\\n                    new_path_0 = {\\'conjunction\\': conjunct + [(best_column+\\'_0\\', build_pred(best_column, 0))],\\r\\n                                \\'prediction\\': None,\\r\\n                                 \\'gig_score\\': gig_value\\r\\n                                 }\\r\\n                    new_paths.append( new_path_0 ) #false\\r\\n                else:\\r\\n                    #not worth splitting so complete the path with a prediction\\r\\n                    path[\\'prediction\\'] = compute_prediction(before_table, target)\\r\\n                    tree_paths.append(path)\\r\\n            #end for loop\\r\\n\\r\\n            current_paths = new_paths\\r\\n            if current_paths != []:\\r\\n                n -= 1\\r\\n            else:\\r\\n                break  # nothing left to extend so have copied all paths to tree_paths\\r\\n        #end while loop\\r\\n\\r\\n        #Generate predictions for all paths that have None\\r\\n        for path in current_paths:\\r\\n            conjunct = path[\\'conjunction\\']\\r\\n            before_table = generate_table(train, conjunct)\\r\\n            path[\\'prediction\\'] = compute_prediction(before_table, target)\\r\\n            tree_paths.append(path)\\r\\n        return (tree_paths, oob_list)\\r\\n    \\r\\n    #let\\'s build a forest\\r\\n    forest = []\\r\\n    for i in range(tree_n):\\r\\n        (paths, oob) = iterative_build(k)  #always use k for now\\r\\n        forest.append({\\'paths\\': paths, \\'weight\\': None, \\'oob\\': oob})\\r\\n        \\r\\n    return forest\\r\\n\\r\\n#row_index is the row we want to test\\r\\n#table is \\'loan_table\\'\\r\\n#k is number of neighbors we take\\r\\n#columns is \\'splitter_columns\\'\\r\\n#target is \\'Loan_Status\\'\\r\\ndef euclidean_distance(vector1, vector2):\\r\\n  return np.sqrt(sum([(a - b) ** 2 for a, b in zip(vector1, vector2)]))\\r\\n\\r\\ndef knn(row_index, table, columns, k, target):\\r\\n  dist = []\\r\\n  init_row = table[columns].values[row_index].tolist() #values instead of iloc\\r\\n  for index, row in table.iterrows():\\r\\n    if index == row_index:\\r\\n      continue\\r\\n    dist.append((index, euclidean_distance(init_row, row[columns].tolist())))\\r\\n  dist.sort(key=operator.itemgetter(1))\\r\\n  vote = []\\r\\n  for (x, y) in dist[:k]:\\r\\n    vote.append(table[target].values[x]) #same here\\r\\n  return max(set(vote), key=vote.count)\\r\\n\\r\\ndef knn_tester(table, k, columns, target):\\r\\n  all_votes = []\\r\\n  for i in range(len(table)):\\r\\n    pred = knn(i, table, columns, k, target)\\r\\n    all_votes.append(pred)\\r\\n  table[\\'all_votes\\'] = all_votes\\r\\n  table[\\'vote_type\\'] = table.apply(lambda row: predictor_case(row, pred=\\'all_votes\\', target=target), axis=1)\\r\\n  p1_types = table[\\'vote_type\\'].value_counts()\\r\\n  return accuracy(p1_types)\\r\\n\\r\\ndef oob_test(forest):\\r\\n  oob_list = []\\r\\n  for tree in forest:\\r\\n    oob_list += tree[\\'oob\\']\\r\\n  oob_list = list(set(oob_list))\\r\\n  testing_table = loan_table.loc[loan_table.index.isin(oob_list)]\\r\\n  testing_table = testing_table.reset_index()\\r\\n  return testing_table\\r\\n\\r\\ndef oob_vote_taker(row, forest):\\r\\n    votes = {0:0, 1:0}\\r\\n    for tree in forest:\\r\\n        # check to see if it is in oob\\r\\n        if row[\\'index\\'] in tree[\\'oob\\']:\\r\\n            prediction = tree_predictor(row, tree)\\r\\n            votes[prediction] += 1\\r\\n    winner = 1 if votes[1]>votes[0] else 0  #ties go to 0\\r\\n    return winner\\r\\n\\r\\ndef oob_forest_scores(table, forest, target):\\r\\n    scratch_table = pd.DataFrame(columns=[\\'prediction\\', \\'actual\\'])\\r\\n    scratch_table[\\'prediction\\'] = table.apply(lambda row: oob_vote_taker(row, forest), axis=1)\\r\\n    scratch_table[\\'actual\\'] = table[target]  # just copy the target column\\r\\n    cases = scratch_table.apply(lambda row: predictor_case(row, pred=\\'prediction\\', target=\\'actual\\'), axis=1)\\r\\n    vc = cases.value_counts()\\r\\n    return [accuracy(vc), f1(vc), informedness(vc)]'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "Il6HlbWggzMB",
        "colab_type": "code",
        "outputId": "7ba0f7c6-2f1c-4c98-cb23-ea88761a3ace",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "cell_type": "code",
      "source": [
        "from library_w19_week7 import *\n",
        "\n",
        "%who function"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy\t build_pred\t build_tree_iter\t compute_prediction\t compute_training\t euclidean_distance\t f1\t find_best_splitter\t forest_builder\t \n",
            "forest_scores\t generate_table\t gig\t gini\t informedness\t k_fold\t k_fold_random\t knn\t knn_tester\t \n",
            "oob_forest_scores\t oob_test\t oob_vote_taker\t path_id\t predictor_case\t probabilities\t produce_scores\t reorder_paths\t shuffle\t \n",
            "tree_predictor\t verify_unique\t vote_taker\t \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mYPJRcSZsznx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h2>Columns used in all questions</h2>\n",
        "\n",
        "We will use 14 columns from the table to make predictions on `Survived`."
      ]
    },
    {
      "metadata": {
        "id": "3TDm9WllKCAv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "usable_columns = [\n",
        " 'emb_C',\n",
        " 'emb_Q',\n",
        " 'emb_S',\n",
        " 'emb_nan',\n",
        " 'age_Child',\n",
        " 'age_Adult',\n",
        " 'age_Senior',\n",
        " 'no_age',\n",
        " 'ok_child',\n",
        " 'sex_female',\n",
        " 'pclass_1',\n",
        " 'pclass_2',\n",
        " 'pclass_3',\n",
        " 'pclass_nan'\n",
        "]\n",
        "\n",
        "target = 'Survived'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "843csVX-py7C"
      },
      "cell_type": "markdown",
      "source": [
        "<h1>\n",
        "Part 1. Explore random forest behavior\n",
        "</h1>\n",
        "<div class=h1_cell>\n",
        "<p>\n",
        "For prediction purposes, we have been treating a forest as a single predictor. It does call on its trees to get a prediction, but we don't see that. All we see is the final prediction. I'd like to dig deeper into individual tree behavior. I'll ask you to complete a set of programming problems to do this.\n",
        "</div>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "l9S58jH5py7D"
      },
      "cell_type": "markdown",
      "source": [
        "<h2>\n",
        "Problem 1. Build a matrix of tree predictions (5 points)\n",
        "</h2>\n",
        "<div class=h1_cell>\n",
        "<p>\n",
        "The matrix will be a list of lists. Let's say the forest we are working with has 13 trees. Then the first list will be the predictions of the 13 trees for row 0 of the Titanic table, i.e., it will be a list of 13 binary values. The next list will be the 13 predictions for row 1 of the Titanic table. Given that we have 891 rows in the Titanic table, we will have 891 lists in our outer list.\n",
        "<p>\n",
        "Let's say I store my matrix in `all_trees`. Then `all_trees[i][j]` will represent the vote of the jth tree for row i.\n",
        "  <p>\n",
        "    Here is what you should see for the first 10 rows.\n",
        "<p>\n",
        "<pre>\n",
        "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        " [1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1],\n",
        " [0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0],\n",
        " [1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0],\n",
        " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        " [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0],\n",
        " [0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1],\n",
        " [0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0],\n",
        " [1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1]]\n",
        " </pre>\n",
        "\n",
        "</div>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "kr4hJ08Tpy7D"
      },
      "cell_type": "markdown",
      "source": [
        "<h2>\n",
        "Here is forest to test on\n",
        "</h2>\n",
        "<div class=h1_cell>\n",
        "<p>\n",
        "  But first set random seeds so you get same results as mine.\n",
        "</div>"
      ]
    },
    {
      "metadata": {
        "id": "NN01O5OJqioB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "rng = np.random.RandomState(24)  #Will pass as arg to pandas sample method\n",
        "random.seed(2000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "4db4f402-091d-4b9b-b72f-07ee47a82805",
        "id": "GysL7AY8py7N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "forest13 = forest_builder(titanic_table, usable_columns, target, hypers={'total-trees':13, 'random-state':rng})\n",
        "len(forest13)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "IHHWb3Vj2xns",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "Build the voting matrix for the 13 trees. "
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "8e0daf4a-d998-4f60-fbd0-4e4fbb9d6e50",
        "id": "UjMSCnflpy7R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        }
      },
      "cell_type": "code",
      "source": [
        "all_trees = []\n",
        "for index, row in titanic_table.iterrows():\n",
        "  temp_list = []\n",
        "  for tree in forest13:\n",
        "    prediction = tree_predictor(row,tree)\n",
        "    temp_list.append(prediction)\n",
        "  all_trees.append(temp_list)\n",
        "  \n",
        "all_trees[:10]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              " [1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1],\n",
              " [0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0],\n",
              " [1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0],\n",
              " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0],\n",
              " [0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1],\n",
              " [0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0],\n",
              " [1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "Jci-WoYQkV1E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h1>\n",
        "Problem 2: most incorrect tree (15 points)\n",
        "</h1>\n",
        "<div class=h1_cell>\n",
        "<p>\n",
        "Produce an ordered list, from most incorrect to least incorrect, of the 13 trees taken over the 891 rows. A tree is incorrect if its prediction is a mismatch with the `Survived` column in the target row. Here are my results.\n",
        "  <pre>\n",
        "[(9, 317),\n",
        " (8, 314),\n",
        " (5, 310),\n",
        " (12, 304),\n",
        " (0, 296),\n",
        " (11, 296),\n",
        " (3, 278),\n",
        " (7, 254),\n",
        " (6, 248),\n",
        " (4, 217),\n",
        " (1, 190),\n",
        " (10, 190),\n",
        " (2, 184)]\n",
        " </pre>\n",
        "  The loser is tree9. It was incorrect 317 out of 891 times.\n",
        "</div>"
      ]
    },
    {
      "metadata": {
        "id": "YFUk-V7NBLIM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "9a04a90f-98a9-4349-e3c4-11334141ad81"
      },
      "cell_type": "code",
      "source": [
        "len(titanic_table)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "891"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "qOQr56-AWICk",
        "colab_type": "code",
        "outputId": "97d15284-a5be-46d1-f86c-99d635f787b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "tree_a = []\n",
        "for index, row in titanic_table.iterrows():\n",
        "  target = row['Survived']\n",
        "  for tree in forest13:\n",
        "    prediction = tree_predictor(row,tree)\n",
        "    if (prediction == row['Survived']):\n",
        "      tree_a.append(forest13.index(tree))\n",
        "all_val = []\n",
        "for item in range(len(forest13)):\n",
        "  all_val.append((item,len(titanic_table)-tree_a.count(item)))\n",
        "  all_val.sort(key=operator.itemgetter(1),reverse=True)\n",
        "print(all_val)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(9, 317), (8, 314), (5, 310), (12, 304), (0, 296), (11, 296), (3, 278), (7, 254), (6, 248), (4, 217), (1, 190), (10, 190), (2, 184)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7e4hXgK9So7t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h1>\n",
        "Problem 3: voting blocks (30 points)\n",
        "</h1>\n",
        "<div class=h1_cell>\n",
        "<p>\n",
        "Taking trees as triples, produce an ordered list of which trees vote the same (right or wrong) most often.\n",
        "  <p>\n",
        "    For each specific row:\n",
        "    <pre>\n",
        " 1. if (tree1,tree2, tree3) vote the same then I record that.\n",
        " 2. if (tree1,tree2, tree4) vote the same then I record that.\n",
        " etc\n",
        "</pre>\n",
        "I do that for the entire table. Here is first part of sorted list I got for forest13.\n",
        "<pre>\n",
        "[((5, 8, 12), 849),\n",
        " ((2, 7, 10), 787),\n",
        " ((2, 3, 10), 769),\n",
        " ((1, 4, 6), 742),\n",
        " ((3, 7, 10), 721),\n",
        " ((1, 2, 10), 719),\n",
        " ((2, 3, 7), 693),\n",
        " ((2, 6, 10), 689),\n",
        " ((7, 9, 10), 679),\n",
        " ((1, 6, 10), 676)]\n",
        "</pre>\n",
        "  So tree5 and tree8 and tree12 vote the same (right or wrong) 849 out of 891 times.\n",
        "</div>"
      ]
    },
    {
      "metadata": {
        "id": "J775mmc1Dq6t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "list_columns = []\n",
        "for i in range(len(all_trees[0])):\n",
        "  tree_list = [row[i] for row in all_trees]\n",
        "  list_columns.append(tree_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0nbpHc_PCfCm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "outputId": "0801084b-989c-4718-b87d-337eaa7dfb41"
      },
      "cell_type": "code",
      "source": [
        "def vote_same(tree1,tree2,tree3):\n",
        "  count = 0\n",
        "  for row in range(len(tree1)):\n",
        "    if (tree1[row] == tree2[row] == tree3[row]):\n",
        "      indicator = True\n",
        "      count += 1\n",
        "    else:\n",
        "      indicator = False\n",
        "  return count\n",
        "\n",
        "def triples(alist):\n",
        "  result = []\n",
        "  for p1 in range(len(alist)):\n",
        "    for p2 in range(p1+1,len(alist)):\n",
        "      for p3 in range(p2+1, len(alist)):\n",
        "        result.append([(p1,alist[p1]),(p2,alist[p2]),(p3,alist[p3])])\n",
        "  return result\n",
        "\n",
        "l_pairs = triples(list_columns)\n",
        "result = []\n",
        "for pair in l_pairs:\n",
        "  count = vote_same(pair[0][1],pair[1][1],pair[2][1])\n",
        "  i_tup = (pair[0][0],pair[1][0],pair[2][0])\n",
        "  vote_tup = (i_tup,count)\n",
        "  result.append(vote_tup)\n",
        "result.sort(key= operator.itemgetter(1),reverse=True)\n",
        "result[:10]"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[((5, 8, 12), 849),\n",
              " ((2, 7, 10), 787),\n",
              " ((2, 3, 10), 769),\n",
              " ((1, 4, 6), 742),\n",
              " ((3, 7, 10), 721),\n",
              " ((1, 2, 10), 719),\n",
              " ((2, 3, 7), 693),\n",
              " ((2, 6, 10), 689),\n",
              " ((7, 9, 10), 679),\n",
              " ((1, 6, 10), 676)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "metadata": {
        "id": "1Tv7gzhjSsdZ",
        "colab_type": "code",
        "outputId": "04ed4679-b36b-4b32-d418-1249613bbaf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "block3_list[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[((5, 8, 12), 849),\n",
              " ((2, 7, 10), 787),\n",
              " ((2, 3, 10), 769),\n",
              " ((1, 4, 6), 742),\n",
              " ((3, 7, 10), 721),\n",
              " ((1, 2, 10), 719),\n",
              " ((2, 3, 7), 693),\n",
              " ((2, 6, 10), 689),\n",
              " ((7, 9, 10), 679),\n",
              " ((1, 6, 10), 676)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "uDz3NazI3upr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "It looks like for 891 rows, trees 5 and 8 and 12 vote the same 849 times."
      ]
    },
    {
      "metadata": {
        "id": "pGLaWlIMhMoP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h1>\n",
        "Part 2. Explore knn behavior\n",
        "</h1>\n",
        "<div class=h1_cell>\n",
        "<p>\n",
        "If I set k=10, then I take the 10 rows with the smallest distance as voters. You all know that. But the value for k is somewhat arbitrary. What if I chose k=11? Would it matter?\n",
        "  <p>\n",
        "So what I am interested in is if I set k=10, what about the 11th row? It is the one that just missed the cut. Maybe it has useful info to offer but I keep cutting it off. I am going to ask you to explore the set of just left out rows, e.g., the 11th row when k=10. If we find that the 11th row is usually correct, we can increment k to be 11.\n",
        "    <p>\n",
        "      I'll ask you to do exploration in a set of 3 problems.\n",
        "</div>"
      ]
    },
    {
      "metadata": {
        "id": "3ipjCjQb4Fjp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "small_titanic = titanic_table[:100]  #use this slice in your code to cut down on computing time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a8T3WbkRp6ko",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h1>\n",
        "Problem 4: A row's just-missed counts (15 points)\n",
        "</h1>\n",
        "<div class=h1_cell>\n",
        "<p>\n",
        "  Loop through all the rows in the small titanic table and compute the sorted list of differences for each. For now, I don't care about the first k. All I want is the index of the k+1 item in the sorted distances, i.e., the row that almost made the cut but not quite.\n",
        "For instance, if k is 10, I want to know the index of 11th item (actually the 10th item with 0-indexing). Record the 11th item's index. When finished print out how many times each row was just missed. Here are the first part of my results. I will use k=10 for all the questions in this part.\n",
        "  <pre>\n",
        "[(91, 11),\n",
        " (51, 8),\n",
        " (2, 7),\n",
        " (76, 7),\n",
        " (5, 6),\n",
        " (21, 6),\n",
        " (64, 5),\n",
        " (17, 4),\n",
        " (23, 4),\n",
        " (26, 4)]\n",
        " </pre>\n",
        "  So row 51 just missed being in the top-10 8 times.\n",
        "</div>"
      ]
    },
    {
      "metadata": {
        "id": "jkUkXrAjOR9M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "GdBa0TbrNbOo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "e8e0c2f9-a9d0-40b5-f135-5a1bbeee6340"
      },
      "cell_type": "code",
      "source": [
        "def knn2(row_index,table,columns,k,target):\n",
        "  table2 = table.copy()\n",
        "  distances = []\n",
        "  table2 = table.as_matrix(columns=columns)\n",
        "  row1 = table2[row_index]\n",
        "  for item in range(len(table)):\n",
        "    if item == row_index:\n",
        "      continue\n",
        "    distances.append((item,euclidean_distance(row1,table2[item])))\n",
        "  distances.sort(key=operator.itemgetter(1))\n",
        "  \n",
        "  return distances[k]  \n",
        "\n",
        "def knn_tester2(table,k,columns, target):\n",
        "  result = []\n",
        "  count_dict = {}\n",
        "  for i in range(len(small_titanic)):\n",
        "    count_dict[i] = 0\n",
        "  \n",
        "  for n, row in small_titanic.iterrows():\n",
        "    topk = [knn2(n,small_titanic,usable_columns,10,target)]\n",
        "    for item in topk:\n",
        "      count_dict[item[0]] +=1\n",
        "  \n",
        "\n",
        "  for index in range(len(small_titanic)):\n",
        "    tup = (index,count_dict[index])\n",
        "    result.append(tup)\n",
        "  result.sort(key=operator.itemgetter(1),reverse=True)\n",
        "  print(result[:k])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "just_missed_list = knn_tester2(small_titanic,10,usable_columns,target)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(91, 11), (51, 8), (2, 7), (76, 7), (5, 6), (21, 6), (64, 5), (17, 4), (23, 4), (26, 4)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GRGbsp05_2JW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h1>\n",
        "Problem 5: Just missed was correct (15 points)\n",
        "</h1>\n",
        "<div class=h1_cell>\n",
        "<p>\n",
        "Let's delve a little deeper into the k+1 rows. I'd like to know how many times they were correct. If k=10 then count how many times the 11th row was correct. Store your result in missed_correct_list, in sorted fashion. Here are the first part of my results.\n",
        "  <pre>\n",
        "[(91, 11),\n",
        " (5, 6),\n",
        " (51, 6),\n",
        " (2, 5),\n",
        " (69, 4),\n",
        " (17, 3),\n",
        " (64, 3),\n",
        " (76, 3),\n",
        " (10, 2),\n",
        " (21, 2)]\n",
        " </pre>\n",
        "  So when row 51 was in the top-10, it was correct 6 times.\n",
        "</div>"
      ]
    },
    {
      "metadata": {
        "id": "sxAmR4HQPgyQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2339
        },
        "outputId": "b87ebbd4-d714-4da6-ae37-56e3c8367b12"
      },
      "cell_type": "code",
      "source": [
        "cl = []\n",
        "cd = {}\n",
        "for i in range(len(small_titanic)):\n",
        "  cd[i] = 0\n",
        "  \n",
        "for j,row in small_titanic.iterrows():\n",
        "  actual = small_titanic.loc[target][j]\n",
        "  top = knn2(j, small_titanic, usable_columns, 10, target)\n",
        "  for item in top:\n",
        "    pred = small_titanic.loc[target][j]\n",
        "    if actual == pred:\n",
        "      cd[j] += 1\n",
        "      \n",
        "for index in range(len(small_titanic)):\n",
        "  correct_missed = (index, cd[index])\n",
        "  cl.append(correct_missed)\n",
        "  \n",
        "cl.sort(key=operator.itemgetter(1), reverse=True)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "(91, 0.0)\n",
            "0\n",
            "3\n",
            "(54, 1.7320508075688772)\n",
            "0\n",
            "Braund, Mr. Owen Harris\n",
            "(51, 1.0)\n",
            "0\n",
            "male\n",
            "(40, 1.4142135623730951)\n",
            "0\n",
            "22.0\n",
            "(76, 1.0)\n",
            "0\n",
            "1\n",
            "(48, 1.4142135623730951)\n",
            "0\n",
            "0\n",
            "(96, 1.4142135623730951)\n",
            "0\n",
            "A/5 21171\n",
            "(69, 1.0)\n",
            "0\n",
            "7.25\n",
            "(2, 1.4142135623730951)\n",
            "0\n",
            "nan\n",
            "(2, 2.0)\n",
            "0\n",
            "S\n",
            "(0, 1.4142135623730951)\n",
            "0\n",
            "0\n",
            "(83, 1.7320508075688772)\n",
            "0\n",
            "22.0\n",
            "(91, 0.0)\n",
            "0\n",
            "0\n",
            "(76, 1.0)\n",
            "0\n",
            "0\n",
            "(51, 1.0)\n",
            "0\n",
            "1\n",
            "(21, 1.7320508075688772)\n",
            "0\n",
            "0\n",
            "(51, 1.7320508075688772)\n",
            "0\n",
            "Child\n",
            "(76, 1.4142135623730951)\n",
            "0\n",
            "1\n",
            "(2, 1.4142135623730951)\n",
            "0\n",
            "0\n",
            "(82, 1.4142135623730951)\n",
            "0\n",
            "0\n",
            "(23, 1.4142135623730951)\n",
            "0\n",
            "0\n",
            "(23, 1.4142135623730951)\n",
            "0\n",
            "1\n",
            "(10, 1.7320508075688772)\n",
            "0\n",
            "0\n",
            "(21, 1.4142135623730951)\n",
            "0\n",
            "0\n",
            "(0, 1.4142135623730951)\n",
            "0\n",
            "0\n",
            "(2, 1.4142135623730951)\n",
            "0\n",
            "1\n",
            "(64, 1.4142135623730951)\n",
            "0\n",
            "0\n",
            "(67, 1.4142135623730951)\n",
            "0\n",
            "[(12, 0.0), (37, 0.0), (51, 0.0), (59, 0.0), (67, 0.0), (69, 0.0), (75, 0.0), (80, 0.0), (86, 0.0), (89, 0.0)]\n",
            "(26, 1.7320508075688772)\n",
            "0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   2559\u001b[0m             return self._engine.get_value(s, k,\n\u001b[0;32m-> 2560\u001b[0;31m                                           tz=getattr(series.dtype, 'tz', None))\n\u001b[0m\u001b[1;32m   2561\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 29",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-82-59f61e5421f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msmall_titanic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mactual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmall_titanic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0mtop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmall_titanic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musable_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    621\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   2564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2565\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2566\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mlibts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2567\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2568\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.get_value_box\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.get_value_box\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index out of bounds"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "3I7M9aHDD0bT",
        "colab_type": "code",
        "outputId": "4ae570f8-ae19-413a-9477-4b291b7d3511",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "cell_type": "code",
      "source": [
        "correct_missed_list[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(91, 11),\n",
              " (5, 6),\n",
              " (51, 6),\n",
              " (2, 5),\n",
              " (69, 4),\n",
              " (17, 3),\n",
              " (64, 3),\n",
              " (76, 3),\n",
              " (10, 2),\n",
              " (21, 2)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "dhkbicwyCE4-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h1>\n",
        "Problem 6: Tip the scales (20 points)\n",
        "</h1>\n",
        "<div class=h1_cell>\n",
        "<p>\n",
        "Ok, finally to the question I really want to answer. If I am going to start including the 11th row by making k=11, I want to know if adding the row makes a difference. Would it have tipped the scales? As usual, go through all 891 rows and get the sorted distances for each. But now go ahead and get the votes of the top 10. Once you count the 10 votes, you will come up with a prediction as normal. What I want to know is whether the 11th vote would have tipped the scales. If you took just the 10, you get one result. If you add in the 11th vote you get a different result. Give me a sorted list of rows that tipped the scales acting as the 11th voter.\n",
        "  <pre>\n",
        "[(2, 4),\n",
        " (23, 3),\n",
        " (53, 2),\n",
        " (65, 1),\n",
        " (84, 1),\n",
        " (0, 0),\n",
        " (1, 0),\n",
        " (3, 0),\n",
        " (4, 0),\n",
        " (5, 0)]\n",
        " </pre>\n",
        "  So row 2. acting as the k+1 voter, switched the outcome of the vote 4 times. Looking at this list, I would probably give up adding an 11th voter (i.e., changing k=11). Only a small number of examples where it actually makes a difference.\n",
        "</div>"
      ]
    },
    {
      "metadata": {
        "id": "e9H6bXVIm_uh",
        "colab_type": "code",
        "outputId": "e77734d9-20e8-4157-c5fd-3fb0e0ee3339",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "cell_type": "code",
      "source": [
        "scale_tipper_list[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(2, 4),\n",
              " (23, 3),\n",
              " (53, 2),\n",
              " (65, 1),\n",
              " (84, 1),\n",
              " (0, 0),\n",
              " (1, 0),\n",
              " (3, 0),\n",
              " (4, 0),\n",
              " (5, 0)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    }
  ]
}