{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rf_assignment_w19.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "_zyEMPhCnHC_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h1>\n",
        "<center>\n",
        "Module 6: Random Forests\n",
        "</center>\n",
        "</h1>\n",
        "<div class=h1_cell>\n",
        "\n",
        "You will be working with the loan table again.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "metadata": {
        "id": "KJT0kc6FhooT",
        "colab_type": "code",
        "outputId": "49a2725c-e772-49f4-a1fd-24ce8e2ce2b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YRgA76lahpmR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('/content/gdrive/My Drive/class_tables/loan_table_week4.csv', 'r') as f:\n",
        "  loan_table = pd.read_csv(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RjDDjSE-htzN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm library_w19_week6.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SCblsgv0nHDB",
        "colab_type": "code",
        "outputId": "d444ddf9-7006-4228-f6d0-806828fc2791",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fb635e14-a531-47bb-838a-ac9e7cc2964d\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-fb635e14-a531-47bb-838a-ac9e7cc2964d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving library_w19_week6.py to library_w19_week6.py\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'library_w19_week6.py': b'import pandas as pd\\r\\nimport numpy as np\\r\\nfrom functools import reduce\\r\\nfrom types import SimpleNamespace\\r\\nimport random\\r\\n\\r\\ndef predictor_case(row, pred, target):\\r\\n  case_dict = {(0,0): \\'true_negative\\', (1,1): \\'true_positive\\', (0,1): \\'false_negative\\', (1,0): \\'false_positive\\'}\\r\\n  actual = row[target]\\r\\n  prediction = row[pred]\\r\\n  case = case_dict[(prediction, actual)]\\r\\n  return case\\r\\n\\r\\ndef informedness(cases):\\r\\n  tp = 0\\r\\n  if \\'true_positive\\' in cases:\\r\\n    tp = cases[\\'true_positive\\']\\r\\n  tn = 0\\r\\n  if \\'true_negative\\' in cases:\\r\\n    tn = cases[\\'true_negative\\']\\r\\n  fp = 0\\r\\n  if \\'false_positive\\' in cases:\\r\\n    fp = cases[\\'false_positive\\']\\r\\n  fn = 0\\r\\n  if \\'false_negative\\' in cases:\\r\\n    fn = cases[\\'false_negative\\']\\r\\n  if (((tp+fn) == 0) or ((tn+fp) == 0)):\\r\\n    return -1\\r\\n  else:\\r\\n    recall = 1.0*tp/(tp+fn)\\r\\n    specificity = 1.0*tn/(tn+fp)\\r\\n    J = (recall + specificity) - 1\\r\\n    \\r\\n  return J\\r\\n\\r\\ndef accuracy(cases):\\r\\n  tp = 0\\r\\n  if \\'true_positive\\' in cases:\\r\\n    tp = cases[\\'true_positive\\']\\r\\n  tn = 0\\r\\n  if \\'true_negative\\' in cases:\\r\\n    tn = cases[\\'true_negative\\']\\r\\n  fp = 0\\r\\n  if \\'false_positive\\' in cases:\\r\\n    fp = cases[\\'false_positive\\']\\r\\n  fn = 0\\r\\n  if \\'false_negative\\' in cases:\\r\\n    fn = cases[\\'false_negative\\']\\r\\n  if (tp + tn + fp + fn) == 0:\\r\\n    return 0\\r\\n  else:\\r\\n    return (tp + tn)/(tp+tn+fp+fn)\\r\\n\\r\\ndef f1(cases):\\r\\n  #the heart of the matrix\\r\\n  tp = 0\\r\\n  if \\'true_positive\\' in cases:\\r\\n    tp = cases[\\'true_positive\\']\\r\\n  tn = 0\\r\\n  if \\'true_negative\\' in cases:\\r\\n    tn = cases[\\'true_negative\\']\\r\\n  fp = 0\\r\\n  if \\'false_positive\\' in cases:\\r\\n    fp = cases[\\'false_positive\\']\\r\\n  fn = 0\\r\\n  if \\'false_negative\\' in cases:\\r\\n    fn = cases[\\'false_negative\\']\\r\\n\\t\\r\\n\\t#other measures we can derive\\r\\n  if (((tp+fn) == 0) or ((tp+fp) == 0)):\\r\\n    return 0\\r\\n  else:\\r\\n    recall = 1.0*tp/(tp+fn)\\r\\n    precision = 1.0*tp/(tp+fp)\\r\\n\\t\\r\\n\\t#now for the one we want\\r\\n  if ((recall == 0) or (precision == 0)):\\r\\n    return 0\\r\\n  else:\\r\\n\\t   f1 = 2/(1/recall + 1/precision)\\r\\n\\t\\r\\n  return f1\\r\\n\\r\\ndef gig(starting_table, split_column, target_column):\\r\\n    \\r\\n    #split into two branches, i.e., two sub-tables\\r\\n    true_table = starting_table.loc[starting_table[split_column] == 1]\\r\\n    false_table = starting_table.loc[starting_table[split_column] == 0]\\r\\n    \\r\\n    #Now see how the target column is divided up in each sub-table (and the starting table)\\r\\n    true_counts = true_table[target_column].value_counts()  # Note using true_table and not starting_table\\r\\n    false_counts = false_table[target_column].value_counts()  # Note using false_table and not starting_table\\r\\n    starting_counts = starting_table[target_column].value_counts() \\r\\n    \\r\\n    #compute the gini impurity for the 3 tables\\r\\n    starting_gini = gini(starting_counts)\\r\\n    true_gini = gini(true_counts)\\r\\n    false_gini = gini(false_counts)\\r\\n\\r\\n    #compute the weights\\r\\n    starting_size = len(starting_table.index)\\r\\n    true_weight = 0.0 if starting_size == 0 else len(true_table.index)/starting_size\\r\\n    false_weight = 0.0 if starting_size == 0 else len(false_table.index)/starting_size\\r\\n    \\r\\n    #wrap it up and put on a bow\\r\\n    gig = starting_gini - (true_weight * true_gini + false_weight * false_gini)\\r\\n    \\r\\n    return gig\\r\\n\\r\\ndef gini(counts):\\r\\n    (p0,p1) = probabilities(counts)\\r\\n    sum_probs = p0**2 + p1**2\\r\\n    gini = 1 - sum_probs\\r\\n    return gini\\r\\n\\r\\ndef probabilities(counts):\\r\\n    count_0 = 0 if 0 not in counts else counts[0]  #could have no 0 values\\r\\n    count_1 = 0 if 1 not in counts else counts[1]\\r\\n    total = count_0 + count_1\\r\\n    probs = (0,0) if total == 0 else (count_0/total, count_1/total)  #build 2-tuple\\r\\n    return probs\\r\\n\\r\\ndef build_pred(column, branch):\\r\\n    return lambda row: row[column] == branch\\r\\n\\r\\ndef find_best_splitter(table, choice_list, target):\\r\\n  \\r\\n    assert (len(table)>0),\"Cannot split empty table\"\\r\\n    assert (target in table),\"Target must be column in table\"\\r\\n    \\r\\n    gig_scores = map(lambda col: (col, gig(table, col, target)), choice_list)  #compute tuple (col, gig) for each column\\r\\n    gig_sorted = sorted(gig_scores, key=lambda item: item[1], reverse=True)  # sort on gig\\r\\n    return gig_sorted\\r\\n\\r\\nfrom functools import reduce\\r\\n\\r\\ndef generate_table(table, conjunction):\\r\\n  \\r\\n    assert (len(table)>0),\"Cannot generate from empty table\"\\r\\n\\r\\n    sub_table = reduce(lambda subtable, pair: subtable.loc[pair[1]], conjunction, table)\\r\\n    return sub_table\\r\\n\\r\\ndef compute_prediction(table, target):\\r\\n  \\r\\n    assert (len(table)>0),\"Cannot predict from empty table\"\\r\\n    assert (target in table),\"Target must be column in table\"\\r\\n    \\r\\n    counts = table[target].value_counts()  # counts looks like {0: v1, 1: v2}\\r\\n\\r\\n    if 0 not in counts:\\r\\n        prediction = 1\\r\\n    elif 1 not in counts:\\r\\n        prediction = 0\\r\\n    elif counts[1] > counts[0]:  # ties go to 0 (negative)\\r\\n        prediction = 1\\r\\n    else:\\r\\n        prediction = 0\\r\\n\\r\\n    return prediction\\r\\n\\r\\ndef build_tree_iter(table, choices, target, hypers={} ):\\r\\n\\r\\n    assert (len(choices)>0),\"Must have at least one column in choices\"\\r\\n    assert (target in table), \"Target column not in table\"\\r\\n    assert (len(table) > 1), \"Table must have more than 1 row\"\\r\\n    \\r\\n    k = hypers[\\'max-depth\\'] if \\'max-depth\\' in hypers else min(4, len(choices))\\r\\n    gig_cutoff = hypers[\\'gig-cutoff\\'] if \\'gig-cutoff\\' in hypers else 0.0\\r\\n    \\r\\n    def iterative_build(k):\\r\\n        columns_sorted = find_best_splitter(table, choices, target)\\r\\n        (best_column, gig_value) = columns_sorted[0]\\r\\n        \\r\\n        #Note I add _1 or _0 to make it more readable for debugging\\r\\n        current_paths = [{\\'conjunction\\': [(best_column, build_pred(best_column, 1))],\\r\\n                          \\'prediction\\': None,\\r\\n                          \\'gig_score\\': gig_value},\\r\\n                         {\\'conjunction\\': [(best_column, build_pred(best_column, 0))],\\r\\n                          \\'prediction\\': None,\\r\\n                          \\'gig_score\\': gig_value}\\r\\n                        ]\\r\\n        k -= 1  # we just built a level as seed so subtract 1 from k\\r\\n        tree_paths = []  # add completed paths here\\r\\n        \\r\\n        while k>0:\\r\\n            new_paths = []\\r\\n            for path in current_paths:\\r\\n                old_conjunction = path[\\'conjunction\\']  # a list of (name, lambda)\\r\\n                before_table = generate_table(table, old_conjunction)  #the subtable the current conjunct leads to\\r\\n                columns_sorted = find_best_splitter(before_table, choices, target)\\r\\n                (best_column, gig_value) = columns_sorted[0]\\r\\n                if gig_value > gig_cutoff:\\r\\n                    new_path_1 = {\\'conjunction\\': old_conjunction + [(best_column, build_pred(best_column, 1))],\\r\\n                                \\'prediction\\': None,\\r\\n                                 \\'gig_score\\': gig_value}\\r\\n                    new_paths.append( new_path_1 ) #true\\r\\n                    new_path_0 = {\\'conjunction\\': old_conjunction + [(best_column, build_pred(best_column, 0))],\\r\\n                                \\'prediction\\': None,\\r\\n                                 \\'gig_score\\': gig_value}\\r\\n                    new_paths.append( new_path_0 ) #false\\r\\n                else:\\r\\n                    #not worth splitting so complete the path with a prediction\\r\\n                    path[\\'prediction\\'] = compute_prediction(before_table, target)\\r\\n                    tree_paths.append(path)\\r\\n            #end for loop\\r\\n            \\r\\n            current_paths = new_paths\\r\\n            if current_paths != []:\\r\\n                k -= 1\\r\\n            else:\\r\\n                break  # nothing left to extend so have copied all paths to tree_paths\\r\\n        #end while loop\\r\\n\\r\\n        #Generate predictions for all paths that have None\\r\\n        for path in current_paths:\\r\\n            conjunction = path[\\'conjunction\\']\\r\\n            before_table = generate_table(table, conjunction)\\r\\n            path[\\'prediction\\'] = compute_prediction(before_table, target)\\r\\n            tree_paths.append(path)\\r\\n        return tree_paths\\r\\n\\r\\n    return {\\'paths\\': iterative_build(k), \\'weight\\': None}\\r\\n\\r\\ndef tree_predictor(row, tree):\\r\\n    \\r\\n    #go through each path, one by one (could use a map instead of for loop?)\\r\\n    for path in tree[\\'paths\\']:\\r\\n        conjuncts = path[\\'conjunction\\']\\r\\n        result = map(lambda tuple: tuple[1](row), conjuncts)  # potential to be parallelized\\r\\n        if all(result):\\r\\n            return path[\\'prediction\\']\\r\\n    raise LookupError(\\'No true paths found for row: \\' + str(row))\\r\\n\\r\\ndef path_id(row, tree):\\r\\n\\tassert (len(tree[\\'paths\\']) > 0)\\r\\n\\tfor path in tree[\\'paths\\']:\\r\\n\\t\\tconjuncts = path[\\'conjunction\\']\\r\\n\\t\\tresult = map(lambda tuple: tuple[1](row), conjuncts)  # potential to be parallelized\\r\\n\\t\\tif all(result):\\r\\n\\t  \\t\\treturn tree[\\'paths\\'].index(path)\\r\\n\\r\\ndef reorder_paths(table, tree):\\r\\n\\tpath_count = table.apply(lambda row: path_id(row, tree), axis = 1)\\r\\n\\tvalue = path_count.value_counts()\\r\\n\\tpath = sorted(value.items(), key=lambda x: x[1], reverse=True)\\r\\n\\tprint(path)\\r\\n\\tnew_paths = []\\r\\n\\tprev_path = tree3[\\'paths\\']\\r\\n\\tfor a, b in plist3:\\r\\n\\t\\tprev = prev_path[a]\\r\\n\\t\\tnew_paths.append(prev)\\r\\n\\treturn new_paths\\r\\n\\r\\ndef produce_scores(table, tree, target):\\r\\n    scratch_table = pd.DataFrame(columns=[\\'prediction\\', \\'actual\\'])\\r\\n    scratch_table[\\'prediction\\'] = table.apply(lambda row: tree_predictor(row, tree), axis=1)\\r\\n    scratch_table[\\'actual\\'] = table[target]  # just copy the target column\\r\\n    cases = scratch_table.apply(lambda row: predictor_case(row, pred=\\'prediction\\', target=\\'actual\\'), axis=1)\\r\\n    vc = cases.value_counts()\\r\\n    return [accuracy(vc), f1(vc), informedness(vc)]\\r\\n\\r\\ndef k_fold(table, k, target, hypers, candidate_columns):\\r\\n  \\r\\n    #set up the table where we will record fold results\\r\\n    result_columns = [\\'name\\',  \\'accuracy\\', \\'f1\\', \\'informedness\\']\\r\\n    k_fold_results_table = pd.DataFrame(columns=result_columns)\\r\\n    \\r\\n    #generate the slices\\r\\n    total_len = len(table.index)\\r\\n    slice_size = int(total_len/(1.0*k))\\r\\n    slices = []\\r\\n    for i in range(k-1):\\r\\n        a_slice =  table[i*slice_size:(i+1)*slice_size]\\r\\n        slices.append( a_slice )\\r\\n    slices.append( table[(k-1)*slice_size:] )  # whatever is left\\r\\n    \\r\\n    #generate test results\\r\\n    all_scores = []  #keep track of all k results\\r\\n    for i in range(k):\\r\\n        test_table = slices[i]\\r\\n        train_table = compute_training(slices, i)\\r\\n        fold_tree = build_tree_iter(train_table, candidate_columns, target, hypers)  # train\\r\\n        scores = produce_scores(test_table, fold_tree, target)  # test\\r\\n        results_row = {\\'name\\': \\'fold_\\'+str(i), \\'accuracy\\': scores[0], \\'f1\\': scores[1], \\'informedness\\': scores[2]}\\r\\n        k_fold_results_table = k_fold_results_table.append(results_row,ignore_index=True)\\r\\n        all_scores.append(scores)\\r\\n    \\r\\n    #compute average of all folds\\r\\n    avg_scores = tuple(reduce(lambda total, triple: np.add(triple, total), all_scores)/k)\\r\\n    results_row = {\\'name\\': \\'average\\', \\'accuracy\\': avg_scores[0], \\'f1\\': avg_scores[1], \\'informedness\\': avg_scores[2]}\\r\\n    k_fold_results_table = k_fold_results_table.append(results_row,ignore_index=True)\\r\\n    \\r\\n    #note that I add the meta comment as last step to avoid it being wiped out\\r\\n    k_fold_results_table.meta = SimpleNamespace()\\r\\n    k_fold_results_table.meta.hypers  = hypers # adds comment to remind me of hyper params used\\r\\n    \\r\\n    return k_fold_results_table\\r\\n\\r\\ndef compute_training(slices, left_out):\\r\\n    training_slices = []\\r\\n    for i,slice in enumerate(slices):\\r\\n        if i == left_out:\\r\\n            continue\\r\\n        training_slices.append(slices[i])\\r\\n    return pd.concat(training_slices)\\r\\n\\r\\nfrom sklearn.utils import shuffle\\r\\n\\r\\n#Determine if slices are mutually exclusive\\r\\ndef verify_unique(slices):\\r\\n    print((\\'total length all slices\\', sum([len(s) for s in slices])))\\r\\n    for i, a_slice in enumerate(slices[:-1]):\\r\\n        a_set = set(a_slice.index)\\r\\n        for j, b_slice in enumerate(slices[i+1:]):\\r\\n            b_set = set(b_slice.index)\\r\\n            int_set = a_set.intersection(b_set)  # should be empty set as result\\r\\n            print((i,j+i+1,int_set))\\r\\n    return None\\r\\n\\r\\ndef k_fold_random(table, k, target, hypers, candidate_columns):\\r\\n  #set up the table where we will record fold results\\r\\n    result_columns = [\\'name\\',  \\'accuracy\\', \\'f1\\', \\'informedness\\']\\r\\n    k_fold_results_table = pd.DataFrame(columns=result_columns)\\r\\n    \\r\\n    #generate the slices\\r\\n    # here is sequential slice code from k_fold if you want to use it as base.\\r\\n    # modify it to produce slices with random rows in each slice.\\r\\n\\r\\n    table = shuffle(loan_table)\\r\\n    total_len = len(table.index)\\r\\n    slice_size = int(total_len/(1.0*k))\\r\\n    slices = []\\r\\n    #generate the slices\\r\\n    for i in range(k-1):\\r\\n      a_slice =  table[i*slice_size:(i+1)*slice_size]\\r\\n      slices.append( a_slice )\\r\\n    slices.append( table[(k-1)*slice_size:] )\\r\\n\\r\\n    verify_unique(slices)  # I ask you to define this debugging function below\\r\\n    \\r\\n    #generate test results\\r\\n    all_scores = []  #keep track of all k results\\r\\n    for i in range(k):\\r\\n        test_table = slices[i]\\r\\n        train_table = compute_training(slices, i)\\r\\n        fold_tree = build_tree_iter(train_table, candidate_columns, target, hypers)  # train\\r\\n        scores = produce_scores(test_table, fold_tree, target)  # test\\r\\n        results_row = {\\'name\\': \\'fold_\\'+str(i), \\'accuracy\\': scores[0], \\'f1\\': scores[1], \\'informedness\\': scores[2]}\\r\\n        k_fold_results_table = k_fold_results_table.append(results_row,ignore_index=True)\\r\\n        all_scores.append(scores)\\r\\n    \\r\\n    #compute average of all folds\\r\\n    avg_scores = tuple(reduce(lambda total, triple: np.add(triple, total), all_scores)/5)\\r\\n    results_row = {\\'name\\': \\'average\\', \\'accuracy\\': avg_scores[0], \\'f1\\': avg_scores[1], \\'informedness\\': avg_scores[2]}\\r\\n    k_fold_results_table = k_fold_results_table.append(results_row,ignore_index=True)\\r\\n    \\r\\n    #note that I add the meta comment as last step to avoid it being wiped out\\r\\n    k_fold_results_table.meta = SimpleNamespace()\\r\\n    k_fold_results_table.meta.hypers  = hypers # adds comment to remind me of hyper params used\\r\\n    \\r\\n    return k_fold_results_table\\r\\n\\r\\ndef vote_taker(row, forest):\\r\\n    votes = {0:0, 1:0}\\r\\n    for tree in forest:\\r\\n        prediction = tree_predictor(row, tree)\\r\\n        votes[prediction] += 1\\r\\n    winner = 1 if votes[1]>votes[0] else 0  #ties go to 0\\r\\n    return winner\\r\\n\\r\\ndef forest_scores(table, forest, target):\\r\\n    scratch_table = pd.DataFrame(columns=[\\'prediction\\', \\'actual\\'])\\r\\n    scratch_table[\\'prediction\\'] = table.apply(lambda row: vote_taker(row, forest), axis=1)  #only change is to call vote_taker\\r\\n    scratch_table[\\'actual\\'] = table[target]  # just copy the target column\\r\\n    cases = scratch_table.apply(lambda row: predictor_case(row, pred=\\'prediction\\', target=\\'actual\\'), axis=1)\\r\\n    vc = cases.value_counts()\\r\\n    return [accuracy(vc), f1(vc), informedness(vc)]\\r\\n\\r\\ndef forest_builder(table, column_choices, target, hypers):\\r\\n\\r\\n    tree_n = 5 if \\'total-trees\\' not in hypers else hypers[\\'total-trees\\']\\r\\n    m = int(len(column_choices)**.5) if \\'m\\' not in hypers else hypers[\\'m\\']\\r\\n    k = hypers[\\'max-depth\\'] if \\'max-depth\\' in hypers else min(2, len(column_choices))\\r\\n    gig_cutoff = hypers[\\'gig-cutoff\\'] if \\'gig-cutoff\\' in hypers else 0.0\\r\\n    rgen = hypers[\\'random-state\\'] if \\'random-state\\' in hypers else 0  #an int will work as seed with the sample method.\\r\\n\\r\\n    #build a single tree of depth n - call it multiple times to build multiple trees\\r\\n    def iterative_build(n):\\r\\n        train = table.sample(frac=1.0, replace=True, random_state=rgen)\\r\\n        train = train.reset_index()\\r\\n        left_out = table.loc[~table.index.isin(train[\\'index\\'])]\\r\\n        left_out = left_out.reset_index() # this gives us the old index in its own column\\r\\n        oob_list = left_out[\\'index\\'].tolist()  # list of row indices from original titanic table\\r\\n        \\r\\n        rcols = random.sample(column_choices, m)  # subspcace sampling - uses random.seed, not rng\\r\\n        columns_sorted = find_best_splitter(train, rcols, target)\\r\\n        (best_column, gig_value) = columns_sorted[0]\\r\\n\\r\\n        #Note I add _1 or _0 to make it more readable for debugging\\r\\n        current_paths = [{\\'conjunction\\': [(best_column+\\'_1\\', build_pred(best_column, 1))],\\r\\n                          \\'prediction\\': None,\\r\\n                          \\'gig_score\\': gig_value},\\r\\n                         {\\'conjunction\\': [(best_column+\\'_0\\', build_pred(best_column, 0))],\\r\\n                          \\'prediction\\': None,\\r\\n                          \\'gig_score\\': gig_value}\\r\\n                        ]\\r\\n        n -= 1  # we just built a level as seed so subtract 1 from n\\r\\n        tree_paths = []  # add completed paths here\\r\\n\\r\\n        while n>0:\\r\\n            new_paths = []\\r\\n            for path in current_paths:\\r\\n                conjunct = path[\\'conjunction\\']  # a list of (name, lambda)\\r\\n                before_table = generate_table(train, conjunct)  #the subtable the current conjunct leads to\\r\\n                rcols = random.sample(column_choices, m)  # subspace\\r\\n                columns_sorted = find_best_splitter(before_table, rcols, target)\\r\\n                (best_column, gig_value) = columns_sorted[0]\\r\\n                if gig_value > gig_cutoff:\\r\\n                    new_path_1 = {\\'conjunction\\': conjunct + [(best_column+\\'_1\\', build_pred(best_column, 1))],\\r\\n                                \\'prediction\\': None,\\r\\n                                 \\'gig_score\\': gig_value}\\r\\n                    new_paths.append( new_path_1 ) #true\\r\\n                    new_path_0 = {\\'conjunction\\': conjunct + [(best_column+\\'_0\\', build_pred(best_column, 0))],\\r\\n                                \\'prediction\\': None,\\r\\n                                 \\'gig_score\\': gig_value\\r\\n                                 }\\r\\n                    new_paths.append( new_path_0 ) #false\\r\\n                else:\\r\\n                    #not worth splitting so complete the path with a prediction\\r\\n                    path[\\'prediction\\'] = compute_prediction(before_table, target)\\r\\n                    tree_paths.append(path)\\r\\n            #end for loop\\r\\n\\r\\n            current_paths = new_paths\\r\\n            if current_paths != []:\\r\\n                n -= 1\\r\\n            else:\\r\\n                break  # nothing left to extend so have copied all paths to tree_paths\\r\\n        #end while loop\\r\\n\\r\\n        #Generate predictions for all paths that have None\\r\\n        for path in current_paths:\\r\\n            conjunct = path[\\'conjunction\\']\\r\\n            before_table = generate_table(train, conjunct)\\r\\n            path[\\'prediction\\'] = compute_prediction(before_table, target)\\r\\n            tree_paths.append(path)\\r\\n        return (tree_paths, oob_list)\\r\\n    \\r\\n    #let\\'s build a forest\\r\\n    forest = []\\r\\n    for i in range(tree_n):\\r\\n        (paths, oob) = iterative_build(k)  #always use k for now\\r\\n        forest.append({\\'paths\\': paths, \\'weight\\': None, \\'oob\\': oob})\\r\\n        \\r\\n    return forest\\r\\n\\r\\n    '}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "rtmSW_2BnHDF",
        "colab_type": "code",
        "outputId": "17a1b7c5-52f7-4203-da46-65d1c6e84682",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "cell_type": "code",
      "source": [
        "from library_w19_week6 import *\n",
        "\n",
        "%who function"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy\t build_pred\t build_tree_iter\t compute_prediction\t compute_training\t f1\t find_best_splitter\t forest_builder\t forest_scores\t \n",
            "generate_table\t gig\t gini\t informedness\t k_fold\t k_fold_random\t path_id\t predictor_case\t probabilities\t \n",
            "produce_scores\t reorder_paths\t shuffle\t tree_predictor\t verify_unique\t vote_taker\t \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "YnHkUajjnHDQ",
        "colab_type": "code",
        "outputId": "192487bf-f64a-494c-f0a1-3058dca0be22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_columns', None)\n",
        "loan_table.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Gender</th>\n",
              "      <th>Married</th>\n",
              "      <th>Dependents</th>\n",
              "      <th>Education</th>\n",
              "      <th>Self_Employed</th>\n",
              "      <th>ApplicantIncome</th>\n",
              "      <th>CoapplicantIncome</th>\n",
              "      <th>LoanAmount</th>\n",
              "      <th>Loan_Amount_Term</th>\n",
              "      <th>Credit_History</th>\n",
              "      <th>Property_Area</th>\n",
              "      <th>Loan_Status</th>\n",
              "      <th>no_lam</th>\n",
              "      <th>filled_lam</th>\n",
              "      <th>pa_Rural</th>\n",
              "      <th>pa_Semiurban</th>\n",
              "      <th>pa_Urban</th>\n",
              "      <th>pa_nan</th>\n",
              "      <th>lam_bin</th>\n",
              "      <th>lam_Low</th>\n",
              "      <th>lam_Average</th>\n",
              "      <th>lam_High</th>\n",
              "      <th>ch_bad</th>\n",
              "      <th>ch_good</th>\n",
              "      <th>ch_nan</th>\n",
              "      <th>apin_binned</th>\n",
              "      <th>apin_low</th>\n",
              "      <th>apin_average</th>\n",
              "      <th>apin_high</th>\n",
              "      <th>apin_nan</th>\n",
              "      <th>dep_0</th>\n",
              "      <th>dep_1</th>\n",
              "      <th>dep_2</th>\n",
              "      <th>dep_3+</th>\n",
              "      <th>dep_nan</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Male</td>\n",
              "      <td>No</td>\n",
              "      <td>0</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>No</td>\n",
              "      <td>5849</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Urban</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>146.412162</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Low</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>low</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Male</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>No</td>\n",
              "      <td>4583</td>\n",
              "      <td>1508.0</td>\n",
              "      <td>128.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Rural</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>128.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Low</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>low</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Male</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>Yes</td>\n",
              "      <td>3000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Urban</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>66.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Low</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>low</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Male</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0</td>\n",
              "      <td>Not Graduate</td>\n",
              "      <td>No</td>\n",
              "      <td>2583</td>\n",
              "      <td>2358.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Urban</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>120.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Low</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>low</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Male</td>\n",
              "      <td>No</td>\n",
              "      <td>0</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>No</td>\n",
              "      <td>6000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>141.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Urban</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>141.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Low</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>low</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Gender Married Dependents     Education Self_Employed  ApplicantIncome  \\\n",
              "0   Male      No          0      Graduate            No             5849   \n",
              "1   Male     Yes          1      Graduate            No             4583   \n",
              "2   Male     Yes          0      Graduate           Yes             3000   \n",
              "3   Male     Yes          0  Not Graduate            No             2583   \n",
              "4   Male      No          0      Graduate            No             6000   \n",
              "\n",
              "   CoapplicantIncome  LoanAmount  Loan_Amount_Term  Credit_History  \\\n",
              "0                0.0         NaN             360.0             1.0   \n",
              "1             1508.0       128.0             360.0             1.0   \n",
              "2                0.0        66.0             360.0             1.0   \n",
              "3             2358.0       120.0             360.0             1.0   \n",
              "4                0.0       141.0             360.0             1.0   \n",
              "\n",
              "  Property_Area  Loan_Status  no_lam  filled_lam  pa_Rural  pa_Semiurban  \\\n",
              "0         Urban            1       1  146.412162         0             0   \n",
              "1         Rural            0       0  128.000000         1             0   \n",
              "2         Urban            1       0   66.000000         0             0   \n",
              "3         Urban            1       0  120.000000         0             0   \n",
              "4         Urban            1       0  141.000000         0             0   \n",
              "\n",
              "   pa_Urban  pa_nan lam_bin  lam_Low  lam_Average  lam_High  ch_bad  ch_good  \\\n",
              "0         1       0     Low        1            0         0       0        1   \n",
              "1         0       0     Low        1            0         0       0        1   \n",
              "2         1       0     Low        1            0         0       0        1   \n",
              "3         1       0     Low        1            0         0       0        1   \n",
              "4         1       0     Low        1            0         0       0        1   \n",
              "\n",
              "   ch_nan apin_binned  apin_low  apin_average  apin_high  apin_nan  dep_0  \\\n",
              "0       0         low         1             0          0         0      1   \n",
              "1       0         low         1             0          0         0      0   \n",
              "2       0         low         1             0          0         0      1   \n",
              "3       0         low         1             0          0         0      1   \n",
              "4       0         low         1             0          0         0      1   \n",
              "\n",
              "   dep_1  dep_2  dep_3+  dep_nan  \n",
              "0      0      0       0        0  \n",
              "1      1      0       0        0  \n",
              "2      0      0       0        0  \n",
              "3      0      0       0        0  \n",
              "4      0      0       0        0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "gVKmmwDqnHDW",
        "colab_type": "code",
        "outputId": "e8a0b7a0-2ce8-43ff-cdca-076b82355d89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "cell_type": "code",
      "source": [
        "loan_table.columns.values"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Gender', 'Married', 'Dependents', 'Education', 'Self_Employed',\n",
              "       'ApplicantIncome', 'CoapplicantIncome', 'LoanAmount',\n",
              "       'Loan_Amount_Term', 'Credit_History', 'Property_Area',\n",
              "       'Loan_Status', 'no_lam', 'filled_lam', 'pa_Rural', 'pa_Semiurban',\n",
              "       'pa_Urban', 'pa_nan', 'lam_bin', 'lam_Low', 'lam_Average',\n",
              "       'lam_High', 'ch_bad', 'ch_good', 'ch_nan', 'apin_binned',\n",
              "       'apin_low', 'apin_average', 'apin_high', 'apin_nan', 'dep_0',\n",
              "       'dep_1', 'dep_2', 'dep_3+', 'dep_nan'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "VpXRjQHtnHDa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<hr>\n",
        "<h1>\n",
        "1: Explore forest options (20)\n",
        "</h1>\n",
        "<p>\n",
        "<div class=h1_cell>\n",
        "<p>\n",
        "Check out the results you get from forests of size 5, 11, 17.\n",
        "<p>\n",
        "First, define the columns to use. I do that for you below.\n",
        "</div>"
      ]
    },
    {
      "metadata": {
        "id": "DNRyB8DvnHDc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "splitter_columns = [\n",
        "        #Dependents\n",
        "        'dep_0', 'dep_1', 'dep_2', 'dep_3+',\n",
        "        #ApplicantIncome\n",
        "       'apin_low', 'apin_high', 'apin_average',\n",
        "        #Property_Area\n",
        "        'pa_Rural', 'pa_Semiurban','pa_Urban',\n",
        "        #LoanAmount\n",
        "        'lam_Low', 'lam_Average', 'lam_High',\n",
        "        #Credit_History\n",
        "        'ch_bad', 'ch_good']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zPLu2ub9nHDg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<hr>\n",
        "<h2>\n",
        "Set seeds so get consistent results\n",
        "</h2>\n",
        "<p>\n",
        "<div class=h1_cell>\n",
        "<p>\n",
        "\n",
        "</div>"
      ]
    },
    {
      "metadata": {
        "id": "W1eNjUiSnW0p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "912d9dfb-db0b-4b84-f6d5-af26a1035630"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "rng = np.random.RandomState(42)  #Will pass as arg to pandas sample method\n",
        "random.seed(2000)\n",
        "random.random()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4484570179105285"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "iuhvnqw3nHDh",
        "colab_type": "code",
        "outputId": "b00540ba-4f02-42a7-cc3e-8716e2e7db53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "forest1 = forest_builder(loan_table, splitter_columns, 'Loan_Status', hypers={'total-trees':5, 'random-state':rng})\n",
        "len(forest1)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "-fCS27OonHDm",
        "colab_type": "code",
        "outputId": "f77566d5-1043-4b2e-8753-49d181f4743e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "forest_scores(loan_table, forest1, 'Loan_Status')\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8094462540716613, 0.8764519535374868, 0.4104956556082149]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "Rjc3x2M8nHDr",
        "colab_type": "code",
        "outputId": "19268d19-a378-46c2-f337-d7b257aaf5f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "forest2 = forest_builder(loan_table, splitter_columns, 'Loan_Status', hypers={'total-trees':11, 'random-state':rng})\n",
        "len(forest2)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "IXRcCWcpnHDx",
        "colab_type": "code",
        "outputId": "54ea65ad-d0ed-47bc-98ea-a75ae0759b2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "forest_scores(loan_table, forest2, 'Loan_Status')\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7785016286644951, 0.8597938144329897, 0.3058599921011058]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "I-n4Tf5bnHD2",
        "colab_type": "code",
        "outputId": "0cc66d2f-6914-4de0-e743-f76674166b3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "forest3 = forest_builder(loan_table, splitter_columns, 'Loan_Status', hypers={'total-trees':17, 'random-state':rng})\n",
        "len(forest3)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "Sh3evOrbnHD8",
        "colab_type": "code",
        "outputId": "15cdb886-bdf2-4104-edea-b13b8bdbf792",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "forest_scores(loan_table, forest3, 'Loan_Status')\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8094462540716613, 0.8764519535374868, 0.4104956556082149]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "cfoOXy5JnHEA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<hr>\n",
        "<h1>\n",
        "2: Implement Out of Bag testing (80)\n",
        "</h1>\n",
        "<p>\n",
        "<div class=h1_cell>\n",
        "<p>\n",
        "Last module we looked at the use of K-Folding as a means to test our trees. Random Forests give us an alternative by using out of bag testing. Using notes from the content notebook this week, find a way to do prediction using the oob idea. As reminder, the set union of all the oob lists in a forest make up the testing set. If there is a row in loan_table that is not in any oob list, that row should be omitted from the test set. Further, a tree only gets to vote on a specific row if that row is in the tree's oob list.\n",
        "  <p>\n",
        "  I am going to leave it to you to come up with an algorithm for doing oob testing. If you get totally stuck, I can supply hints. For grading I am looking to make sure you only use oob rows for testing and that each individual tree only votes on rows in its own oob list.\n",
        "    <p>\n",
        "      It is worthwhile solving this problem given something like it will likely be on next midterm.\n",
        "</div>"
      ]
    },
    {
      "metadata": {
        "id": "dNb9H_Tygh7f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "11645b6e-82dc-44e3-ea4e-75808aba2aaf"
      },
      "cell_type": "code",
      "source": [
        "print(type(loan_table))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QYlMHr1RnHEK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#find out of bag rows - make sure we get no true values\n",
        "#create union of oob rows\n",
        "#left_out1 = titanic_table.loc[~titanic_table.index.isin(train1['index'])]\n",
        "def oob_test(forest):\n",
        "  oob_list = []\n",
        "  for tree in forest:\n",
        "    oob_list += tree['oob']\n",
        "  oob_list = list(set(oob_list))\n",
        "  testing_table = loan_table.loc[loan_table.index.isin(oob_list)]\n",
        "  testing_table = testing_table.reset_index()\n",
        "  return testing_table\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G9gDrRf8p1E1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h2>Check your oob testing against my results</h2>\n",
        "\n",
        "If you used the random seeds to build your trees, your results should be the same as mine. No randomness during oob testing."
      ]
    },
    {
      "metadata": {
        "id": "B5PW22KtotRM",
        "colab_type": "code",
        "outputId": "8d9fc290-9f27-4aa0-b239-f05b76cd27d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#whole table from above: [0.8094462540716613, 0.8764519535374868, 0.4104956556082149]\n",
        "testing_table_1 = oob_test(forest1)\n",
        "forest_scores(testing_table_1, forest1, 'Loan_Status')\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8087431693989071, 0.8760330578512397, 0.40866744557864965]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "NeopvaI5psYx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wcj4Oy5vpxlW",
        "colab_type": "code",
        "outputId": "0d6d32d4-6445-44b0-f474-e0f5fc533daf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#from above: [0.7785016286644951, 0.8597938144329897, 0.3058599921011058]\n",
        "testing_table_2 = oob_test(forest2)\n",
        "forest_scores(testing_table_2, forest2, 'Loan_Status')\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7783251231527094, 0.8598130841121495, 0.3045667476640195]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "ut4tfLw0p-k2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V_bnlpv-p_mm",
        "colab_type": "code",
        "outputId": "789510b6-0e4a-419e-e5e4-4db4fbd055dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#from above: [0.8094462540716613, 0.8764519535374868, 0.4104956556082149]\n",
        "testing_table_3 = oob_test(forest3)\n",
        "forest_scores(testing_table_3, forest3, 'Loan_Status')\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8094462540716613, 0.8764519535374868, 0.4104956556082149]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "9ofRzrrInfGp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h2>Not a lot of change</h2>\n",
        "\n",
        "Using oob testing did not affect scores much. I think we would need to work with bigger tables, e.g., the 25K shelter table, to see a difference."
      ]
    },
    {
      "metadata": {
        "id": "pqg9TP5Cqpy8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<hr>\n",
        "<h1>Write it out</h1>\n",
        "<div class=h1_cell>\n",
        "\n",
        "Did not change table but we did define new functions. Add them to your library as `!rm library_w19_week6b.py`. I added the `b` to designate functions from assignment portion of module.\n",
        "</div>"
      ]
    }
  ]
}