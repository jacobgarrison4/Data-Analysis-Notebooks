{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "practice_midterm2_w19_v2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "CcejYk1YkV0f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h1>\n",
        "<center>\n",
        "Practice Midterm 2\n",
        "</center>\n",
        "</h1>\n",
        "<div class=h1_cell>\n",
        "<p>\n",
        "The Practice and Actual midterm will focus on weeks 6 and 7. In particular, you will be asked to import your week7 library. You can still work on the week6 piece of this practice midterm but will need to finish week7 homework to do it all.\n",
        "<p>\n",
        "  I'll use the shelter table here. The actual midterm will use another dataset.\n",
        "</div>"
      ]
    },
    {
      "metadata": {
        "id": "jW3rzozVkvEB",
        "colab_type": "code",
        "outputId": "fd28beb8-40ee-4a74-ab61-1ab5ca15159e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "shelter_table = pd.read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vT44JuI4VWv1ZOov2Gz7ZlMZk4scUkI5xXbwGQwK455Ue7a-jy77KZ_olLf6JQyBl7RjeNmF2KOIiwE/pub?gid=1192502698&single=true&output=csv')\n",
        "shelter_table.head(1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AnimalID</th>\n",
              "      <th>Name</th>\n",
              "      <th>DateTime</th>\n",
              "      <th>OutcomeType</th>\n",
              "      <th>OutcomeSubtype</th>\n",
              "      <th>AnimalType</th>\n",
              "      <th>SexuponOutcome</th>\n",
              "      <th>AgeuponOutcome</th>\n",
              "      <th>Breed</th>\n",
              "      <th>Color</th>\n",
              "      <th>adopted</th>\n",
              "      <th>n/s</th>\n",
              "      <th>mix</th>\n",
              "      <th>type_Cat</th>\n",
              "      <th>type_Dog</th>\n",
              "      <th>no_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A671945</td>\n",
              "      <td>Hambone</td>\n",
              "      <td>2/12/2014 18:22:00</td>\n",
              "      <td>Return_to_owner</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Dog</td>\n",
              "      <td>Neutered Male</td>\n",
              "      <td>1 year</td>\n",
              "      <td>Shetland Sheepdog Mix</td>\n",
              "      <td>Brown/White</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  AnimalID     Name            DateTime      OutcomeType OutcomeSubtype  \\\n",
              "0  A671945  Hambone  2/12/2014 18:22:00  Return_to_owner            NaN   \n",
              "\n",
              "  AnimalType SexuponOutcome AgeuponOutcome                  Breed  \\\n",
              "0        Dog  Neutered Male         1 year  Shetland Sheepdog Mix   \n",
              "\n",
              "         Color  adopted  n/s  mix  type_Cat  type_Dog  no_name  \n",
              "0  Brown/White        0    1    1         0         1        0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "metadata": {
        "id": "mU7U1eqxjPWo",
        "colab_type": "code",
        "outputId": "14e6076c-8005-4ffc-d593-bcfc1cfacd58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(shelter_table)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "4j7H9XDmLW2n",
        "colab_type": "code",
        "outputId": "ff9ae583-39db-497a-8584-d77e8305c5e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#Note that if you are not done with week 7 homework, you can load week6b instead and work on the first part on random forests\n",
        "\n",
        "!rm library_w19_week7.py"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'library_w19_week7.py': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "x5caMXU3m91b",
        "colab_type": "code",
        "outputId": "888dc74f-460e-4ffa-d249-97a6e00c1204",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c03d6f8b-dda4-4966-95f3-ce02584a72af\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-c03d6f8b-dda4-4966-95f3-ce02584a72af\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving library_w19_week7.py to library_w19_week7.py\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'library_w19_week7.py': b'import pandas as pd\\nimport numpy as np\\nfrom functools import reduce\\n\\ndef predictor_case(row, pred, target):\\n\\tcase_dict = {(0,0): \\'true_negative\\', (1,1): \\'true_positive\\', (0,1): \\'false_negative\\', (1,0): \\'false_positive\\'}\\n\\tactual = row[target]\\n\\tprediction = row[pred]\\n\\tcase = case_dict[(prediction, actual)]\\n\\treturn case\\n\\ndef accuracy(cases):\\n    tp = cases[\\'true_positive\\'] if \\'true_positive\\' in cases else 0\\n    tn = cases[\\'true_negative\\'] if \\'true_negative\\' in cases else 0\\n    fp = cases[\\'false_positive\\'] if \\'false_positive\\' in cases else 0\\n    fn = cases[\\'false_negative\\'] if \\'false_negative\\' in cases else 0\\n\\n    result = (tp + tn)/(tp+tn+fp+fn) if (tp+tn+fp+fn) != 0 else 0\\n    return result\\n\\ndef f1(cases):\\n    #the heart of the matrix\\n    tp = cases[\\'true_positive\\'] if \\'true_positive\\' in cases else 0\\n    tn = cases[\\'true_negative\\'] if \\'true_negative\\' in cases else 0\\n    fp = cases[\\'false_positive\\'] if \\'false_positive\\' in cases else 0\\n    fn = cases[\\'false_negative\\'] if \\'false_negative\\' in cases else 0\\n    \\n    #other measures we can derive\\n    recall = tp/(tp+fn)  if (tp+fn) != 0 else 0 # positive correct divided by total positive in the table\\n    precision = tp/(tp+fp) if (tp+fp) != 0 else 0 # positive correct divided by all positive predictions made\\n    \\n    #now for the one we want\\n    recall_div = 1/recall if recall != 0 else 0\\n    precision_div = 1/precision if precision != 0 else 0\\n    f1 = 2/(recall_div + precision_div) if (recall_div + precision_div) != 0 else 0\\n    \\n    return f1\\n\\ndef informedness(cases):\\n    tp = cases[\\'true_positive\\'] if \\'true_positive\\' in cases else 0\\n    tn = cases[\\'true_negative\\'] if \\'true_negative\\' in cases else 0\\n    fp = cases[\\'false_positive\\'] if \\'false_positive\\' in cases else 0\\n    fn = cases[\\'false_negative\\'] if \\'false_negative\\' in cases else 0\\n\\n    recall = tp/(tp+fn)  if (tp+fn) != 0 else 0 # positive correct divided by total positive in the table\\n    specificty = tn/(tn+fp) if (tn+fp) != 0 else 0# negative correct divided by total negative in the table\\n    J = (recall + specificty) - 1\\n    return J\\n\\n#starting week 3\\n\\ndef probabilities(counts):\\n    count_0 = 0 if 0 not in counts else counts[0]  #could have no 0 values\\n    count_1 = 0 if 1 not in counts else counts[1]\\n    total = count_0 + count_1\\n    probs = (0,0) if total == 0 else (count_0/total, count_1/total)  #build 2-tuple\\n    return probs\\n\\ndef gini(counts):\\n    (p0,p1) = probabilities(counts)\\n    sum_probs = p0**2 + p1**2\\n    gini = 1 - sum_probs\\n    return gini\\n\\ndef gig(starting_table, split_column, target_column):\\n    \\n    #split into two branches, i.e., two sub-tables\\n    true_table = starting_table.loc[starting_table[split_column] == 1]\\n    false_table = starting_table.loc[starting_table[split_column] == 0]\\n    \\n    #Now see how the target column is divided up in each sub-table (and the starting table)\\n    true_counts = true_table[target_column].value_counts()  # Note using true_table and not starting_table\\n    false_counts = false_table[target_column].value_counts()  # Note using false_table and not starting_table\\n    starting_counts = starting_table[target_column].value_counts() \\n    \\n    #compute the gini impurity for the 3 tables\\n    starting_gini = gini(starting_counts)\\n    true_gini = gini(true_counts)\\n    false_gini = gini(false_counts)\\n\\n    #compute the weights\\n    starting_size = len(starting_table.index)\\n    true_weight = 0.0 if starting_size == 0 else len(true_table.index)/starting_size\\n    false_weight = 0.0 if starting_size == 0 else len(false_table.index)/starting_size\\n    \\n    #wrap it up and put on a bow\\n    gig = starting_gini - (true_weight * true_gini + false_weight * false_gini)\\n    \\n    return gig\\n\\n\\'\\'\\'\\ndef entropy(counts):\\n    (p0, p1) = probabilities(counts)\\n    term1 = -p0*math.log(p0,2) if p0 > 0 else 0\\n    term2 = -p1*math.log(p1,2) if p1 > 0 else 0\\n    entropy = term1 + term2\\n    return entropy\\n\\ndef IGain(starting_table, split_column, target_column):\\n    \\n    #split into two branches, i.e., two sub-tables\\n    true_table = starting_table.loc[starting_table[split_column] == 1]\\n    false_table = starting_table.loc[starting_table[split_column] == 0]\\n    \\n    #Now see how the target column is divided up in each sub-table (and the starting table)\\n    true_counts = true_table[target_column].value_counts()\\n    false_counts = false_table[target_column].value_counts()  # Note using true_table and not titanic_table\\n    starting_counts = starting_table[target_column].value_counts() \\n    \\n    #compute the entropy for the 3 tables\\n    starting_e = entropy(starting_counts)\\n    true_e = entropy(true_counts)\\n    false_e = entropy(false_counts)\\n\\n    #compute the weights\\n    starting_size = len(starting_table.index)\\n    true_weight = 0.0 if starting_size == 0 else 1.0*len(true_table.index)/starting_size\\n    false_weight = 0.0 if starting_size == 0 else 1.0*len(false_table.index)/starting_size\\n    \\n    #wrap it up and put on a bow\\n    infogain = starting_e - (true_weight * true_e + false_weight * false_e)\\n    \\n    return infogain\\n\\'\\'\\'\\n\\n#week 4\\n\\ndef build_pred(column, branch):\\n    return lambda row: row[column] == branch\\n\\ndef find_best_splitter(table, choice_list, target):\\n  \\n    assert (len(table)>0),\"Cannot split empty table\"\\n    assert (target in table),\"Target must be column in table\"\\n    \\n    gig_scores = map(lambda col: (col, gig(table, col, target)), choice_list)  #compute tuple (col, gig) for each column\\n    gig_sorted = sorted(gig_scores, key=lambda item: item[1], reverse=True)  # sort on gig\\n    return gig_sorted\\n\\nfrom functools import reduce\\n\\ndef generate_table(table, conjunction):\\n  \\n    assert (len(table)>0),\"Cannot generate from empty table\"\\n\\n    sub_table = reduce(lambda subtable, pair: subtable.loc[pair[1]], conjunction, table)\\n    return sub_table\\n\\ndef compute_prediction(table, target):\\n  \\n    assert (len(table)>0),\"Cannot predict from empty table\"\\n    assert (target in table),\"Target must be column in table\"\\n    \\n    counts = table[target].value_counts()  # counts looks like {0: v1, 1: v2}\\n\\n    if 0 not in counts:\\n        prediction = 1\\n    elif 1 not in counts:\\n        prediction = 0\\n    elif counts[1] > counts[0]:  # ties go to 0 (negative)\\n        prediction = 1\\n    else:\\n        prediction = 0\\n\\n    return prediction\\n\\ndef build_tree_iter(table, choices, target, hypers={} ):\\n\\n    assert (len(choices)>0),\"Must have at least one column in choices\"\\n    assert (target in table), \"Target column not in table\"\\n    assert (len(table) > 1), \"Table must have more than 1 row\"\\n\\n    hyper_keys = [*hypers]  #fails on 2.7\\n    target_set = set([\\'max-depth\\',\\'gig-cutoff\\'])\\n    diff_set = set(hyper_keys) - target_set\\n    if diff_set: print(\\'WARNING: unrecognized hyper parameters \\' + str(diff_set))\\n    \\n    k = hypers[\\'max-depth\\'] if \\'max-depth\\' in hypers else min(4, len(choices))\\n    gig_cutoff = hypers[\\'gig-cutoff\\'] if \\'gig-cutoff\\' in hypers else 0.0\\n    \\n    def iterative_build(k):\\n        columns_sorted = find_best_splitter(table, choices, target)\\n        (best_column, gig_value) = columns_sorted[0]\\n        \\n        #Note I add _1 or _0 to make it more readable for debugging\\n        current_paths = [{\\'conjunction\\': [(best_column+\\'_1\\', build_pred(best_column, 1))],\\n                          \\'prediction\\': None,\\n                          \\'gig_score\\': gig_value},\\n                         {\\'conjunction\\': [(best_column+\\'_0\\', build_pred(best_column, 0))],\\n                          \\'prediction\\': None,\\n                          \\'gig_score\\': gig_value}\\n                        ]\\n        k -= 1  # we just built a level as seed so subtract 1 from k\\n        tree_paths = []  # add completed paths here\\n        \\n        while k>0:\\n            new_paths = []\\n            for path in current_paths:\\n                old_conjunction = path[\\'conjunction\\']  # a list of (name, lambda)\\n                before_table = generate_table(table, old_conjunction)  #the subtable the current conjunct leads to\\n                columns_sorted = find_best_splitter(before_table, choices, target)\\n                (best_column, gig_value) = columns_sorted[0]\\n                if gig_value > gig_cutoff:\\n                    new_path_1 = {\\'conjunction\\': old_conjunction + [(best_column+\\'_1\\', build_pred(best_column, 1))],\\n                                \\'prediction\\': None,\\n                                 \\'gig_score\\': gig_value}\\n                    new_paths.append( new_path_1 ) #true\\n                    new_path_0 = {\\'conjunction\\': old_conjunction + [(best_column+\\'_0\\', build_pred(best_column, 0))],\\n                                \\'prediction\\': None,\\n                                 \\'gig_score\\': gig_value}\\n                    new_paths.append( new_path_0 ) #false\\n                else:\\n                    #not worth splitting so complete the path with a prediction\\n                    path[\\'prediction\\'] = compute_prediction(before_table, target)\\n                    tree_paths.append(path)\\n            #end for loop\\n            \\n            current_paths = new_paths\\n            if current_paths != []:\\n                k -= 1\\n            else:\\n                break  # nothing left to extend so have copied all paths to tree_paths\\n        #end while loop\\n\\n        #Generate predictions for all paths that have None\\n        for path in current_paths:\\n            conjunction = path[\\'conjunction\\']\\n            before_table = generate_table(table, conjunction)\\n            path[\\'prediction\\'] = compute_prediction(before_table, target)\\n            tree_paths.append(path)\\n        return tree_paths\\n\\n    return {\\'paths\\': iterative_build(k), \\'weight\\': None}\\n\\ndef tree_predictor(row, tree):\\n  \\n    assert (len(tree[\\'paths\\']) > 0), \"Tree must have at least one path\"\\n    \\n    #go through each path, one by one (could use a map instead of for loop?)\\n    for path in tree[\\'paths\\']:\\n        conjuncts = path[\\'conjunction\\']\\n        result = map(lambda tuple: tuple[1](row), conjuncts)  # potential to be parallelized\\n        if all(result):\\n            return path[\\'prediction\\']\\n    raise LookupError(\\'No true paths found for row: \\' + str(row))\\n\\n#============== Week 4 version b\\n\\ndef path_id(row, tree):\\n  \\n    assert (len(tree[\\'paths\\']) > 0), \"Tree must have at least one path\"\\n    \\n    #go through each path, one by one (could use a map instead of for loop?)\\n    for i, path in enumerate( tree[\\'paths\\']):\\n        conjuncts = path[\\'conjunction\\']\\n        result = map(lambda tup: tup[1](row), conjuncts)  # potential to be parallelized\\n        if all(result):\\n            return i\\n    raise LookupError(\\'No true paths found for row: \\' + str(row))\\n\\ndef reorder_paths(table, tree):\\n  \\n    new_paths = []\\n    paths = tree[\\'paths\\']\\n\\n    tempcounts = table.apply(lambda row: path_id(row, tree), axis=1)\\n    valcounts= tempcounts.value_counts()\\n    dictcounts = dict(valcounts)\\n    listcounts = list(dictcounts.items())\\n    sortedcounts = sorted(listcounts, key=lambda x: x[1], reverse=True)\\n    print(sortedcounts)\\n    \\n    for tup in sortedcounts:\\n        new_paths.append(paths[tup[0]])\\n        \\n    return new_paths\\n\\n#============== Week 5\\nfrom types import SimpleNamespace\\n\\ndef produce_scores(table, tree, target):\\n    scratch_table = pd.DataFrame(columns=[\\'prediction\\', \\'actual\\'])\\n    scratch_table[\\'prediction\\'] = table.apply(lambda row: tree_predictor(row, tree), axis=1)\\n    scratch_table[\\'actual\\'] = table[target]  # just copy the target column\\n    cases = scratch_table.apply(lambda row: predictor_case(row, pred=\\'prediction\\', target=\\'actual\\'), axis=1)\\n    vc = cases.value_counts()\\n    return [accuracy(vc), f1(vc), informedness(vc)]\\n\\ndef compute_training(slices, left_out):\\n    training_slices = []\\n    for i,slice in enumerate(slices):\\n        if i == left_out:\\n            continue\\n        training_slices.append(slices[i])\\n    return pd.concat(training_slices)  # note we are returning a table (DataFrame)\\n\\ndef k_fold(table, k, target, hypers, candidate_columns):\\n\\n    result_columns = [\\'name\\',  \\'accuracy\\', \\'f1\\', \\'informedness\\']\\n    k_fold_results_table = pd.DataFrame(columns=result_columns)\\n    \\n    total_len = len(table.index)\\n    slice_size = int(total_len/(1.0*k))\\n\\n    #generate the slices\\n    slices = []\\n    for i in range(k-1):\\n        a_slice =  table[i*slice_size:(i+1)*slice_size]\\n        slices.append( a_slice )\\n    slices.append( table[(k-1)*slice_size:] )  # whatever is left\\n    \\n    #do cross validation\\n    all_scores = []\\n    for i in range(k):\\n        test_table = slices[i]\\n        train_table = compute_training(slices, i)\\n        fold_tree = build_tree_iter(train_table, candidate_columns, target, hypers)  # train\\n        scores = produce_scores(test_table, fold_tree, target)  # test\\n        result_row = {\\'name\\':\\'fold_\\'+str(i), \\'accuracy\\':scores[0], \\'f1\\':scores[1], \\'informedness\\':scores[2]}\\n        k_fold_results_table = k_fold_results_table.append(result_row,ignore_index=True)\\n        all_scores.append(scores)\\n        \\n    #compute the average\\n    average = list(reduce(np.add, all_scores[1:], all_scores[0])/k)\\n    result_row = {\\'name\\':\\'average\\', \\'accuracy\\':average[0], \\'f1\\':average[1], \\'informedness\\':average[2]}\\n    k_fold_results_table = k_fold_results_table.append(result_row,ignore_index=True)\\n    \\n    return k_fold_results_table\\n\\n########  Added from assignment notebook\\n\\n\\n\\ndef k_fold_random(table, k, target, hypers, candidate_columns):\\n\\n    result_columns = [\\'name\\',  \\'accuracy\\', \\'f1\\', \\'informedness\\']\\n    k_fold_results_table = pd.DataFrame(columns=result_columns)\\n    \\n    total_len = len(table.index)\\n    slice_size = int(total_len/(1.0*k))\\n\\n    #generate the slices\\n    \\n    #your new code here\\n    sub_table = table\\n    slices = []\\n    for i in range(k-1):\\n        new_slice = sub_table.sample(n=slice_size)\\n        sub_table = sub_table.loc[~sub_table.index.isin(new_slice.index)]\\n        slices.append( new_slice )\\n    slices.append( sub_table )\\n    verify_unique(slices)\\n    \\n    #do cross validation\\n    all_scores = []\\n    for i in range(k):\\n        test_table = slices[i]\\n        train_table = compute_training(slices, i)\\n        fold_tree = build_tree_iter(train_table, candidate_columns, target, hypers)  # train\\n        scores = produce_scores(test_table, fold_tree, target)  # test\\n        result_row = {\\'name\\':\\'fold_\\'+str(i), \\'accuracy\\':scores[0], \\'f1\\':scores[1], \\'informedness\\':scores[2]}\\n        k_fold_results_table = k_fold_results_table.append(result_row,ignore_index=True)\\n        all_scores.append(scores)\\n        \\n    #compute the average\\n    average = list(reduce(np.add, all_scores[1:], all_scores[0])/k)\\n    result_row = {\\'name\\':\\'average\\', \\'accuracy\\':average[0], \\'f1\\':average[1], \\'informedness\\':average[2]}\\n    k_fold_results_table = k_fold_results_table.append(result_row,ignore_index=True)\\n    \\n    return k_fold_results_table\\n\\n#Determine if slices are mutually exclusive\\ndef verify_unique(slices):\\n    print((\\'total length all slices\\', sum([len(s) for s in slices])))\\n    for i, a_slice in enumerate(slices[:-1]):\\n        a_set = set(a_slice.index)\\n        for j, b_slice in enumerate(slices[i+1:]):\\n            b_set = set(b_slice.index)\\n            int_set = a_set.intersection(b_set)  # should be empty set as result\\n            print((i,j+i+1,int_set))\\n    return None\\n\\n####  week 6\\n\\nimport random\\n\\ndef vote_taker(row, forest):\\n    votes = {0:0, 1:0}\\n    for tree in forest:\\n        prediction = tree_predictor(row, tree)\\n        votes[prediction] += 1\\n    winner = 1 if votes[1]>votes[0] else 0  #ties go to 0\\n    return winner\\n\\n\\ndef forest_scores(table, forest, target):\\n    scratch_table = pd.DataFrame(columns=[\\'prediction\\', \\'actual\\'])\\n    scratch_table[\\'prediction\\'] = table.apply(lambda row: vote_taker(row, forest), axis=1)  #only change is to call vote_taker\\n    scratch_table[\\'actual\\'] = table[target]  # just copy the target column\\n    cases = scratch_table.apply(lambda row: predictor_case(row, pred=\\'prediction\\', target=\\'actual\\'), axis=1)\\n    vc = cases.value_counts()\\n    return [accuracy(vc), f1(vc), informedness(vc)]\\n\\n\\ndef forest_builder(table, column_choices, target, hypers):\\n    \\n    tree_n = 5 if \\'total-trees\\' not in hypers else hypers[\\'total-trees\\']\\n    m = int(len(column_choices)**.5) if \\'m\\' not in hypers else hypers[\\'m\\']\\n    k = hypers[\\'max-depth\\'] if \\'max-depth\\' in hypers else min(2, len(column_choices))\\n    gig_cutoff = hypers[\\'gig-cutoff\\'] if \\'gig-cutoff\\' in hypers else 0.0\\n    rgen = hypers[\\'random-state\\'] if \\'random-state\\' in hypers else 0  #an int will work as seed with the sample method.\\n\\n    #build a single tree of depth n - call it multiple times to build multiple trees\\n    def iterative_build(n):\\n        train = table.sample(frac=1.0, replace=True, random_state=rgen)\\n        train = train.reset_index()\\n        left_out = table.loc[~table.index.isin(train[\\'index\\'])]\\n        left_out = left_out.reset_index() # this gives us the old index in its own column\\n        oob_list = left_out[\\'index\\'].tolist()  # list of row indices from original titanic table\\n        \\n        rcols = random.sample(column_choices, m)  # subspacce sampling - uses random.seed, not rng\\n        columns_sorted = find_best_splitter(train, rcols, target)\\n        (best_column, gig_value) = columns_sorted[0]\\n\\n        #Note I add _1 or _0 to make it more readable for debugging\\n        current_paths = [{\\'conjunction\\': [(best_column+\\'_1\\', build_pred(best_column, 1))],\\n                          \\'prediction\\': None,\\n                          \\'gig_score\\': gig_value},\\n                         {\\'conjunction\\': [(best_column+\\'_0\\', build_pred(best_column, 0))],\\n                          \\'prediction\\': None,\\n                          \\'gig_score\\': gig_value}\\n                        ]\\n        n -= 1  # we just built a level as seed so subtract 1 from n\\n        tree_paths = []  # add completed paths here\\n\\n        while n>0:\\n            new_paths = []\\n            for path in current_paths:\\n                conjunct = path[\\'conjunction\\']  # a list of (name, lambda)\\n                before_table = generate_table(train, conjunct)  #the subtable the current conjunct leads to\\n                rcols = random.sample(column_choices, m)  # subspace\\n                columns_sorted = find_best_splitter(before_table, rcols, target)\\n                (best_column, gig_value) = columns_sorted[0]\\n                if gig_value > gig_cutoff:\\n                    new_path_1 = {\\'conjunction\\': conjunct + [(best_column+\\'_1\\', build_pred(best_column, 1))],\\n                                \\'prediction\\': None,\\n                                 \\'gig_score\\': gig_value}\\n                    new_paths.append( new_path_1 ) #true\\n                    new_path_0 = {\\'conjunction\\': conjunct + [(best_column+\\'_0\\', build_pred(best_column, 0))],\\n                                \\'prediction\\': None,\\n                                 \\'gig_score\\': gig_value\\n                                 }\\n                    new_paths.append( new_path_0 ) #false\\n                else:\\n                    #not worth splitting so complete the path with a prediction\\n                    path[\\'prediction\\'] = compute_prediction(before_table, target)\\n                    tree_paths.append(path)\\n            #end for loop\\n\\n            current_paths = new_paths\\n            if current_paths != []:\\n                n -= 1\\n            else:\\n                break  # nothing left to extend so have copied all paths to tree_paths\\n        #end while loop\\n\\n        #Generate predictions for all paths that have None\\n        for path in current_paths:\\n            conjunct = path[\\'conjunction\\']\\n            before_table = generate_table(train, conjunct)\\n            path[\\'prediction\\'] = compute_prediction(before_table, target)\\n            tree_paths.append(path)\\n        return (tree_paths, oob_list)\\n    \\n    #let\\'s build a forest\\n    forest = []\\n    for i in range(tree_n):\\n        (paths, oob) = iterative_build(k)  #always use k for now\\n        forest.append({\\'paths\\': paths, \\'weight\\': None, \\'oob\\': oob})\\n        \\n    return forest\\n\\n######## week 6 2nd version b from assignment\\n\\n\\ndef oob_table(table, forest):\\n    oob_set = set([])\\n    for tree in forest:\\n        oob_set = oob_set.union(set(tree[\\'oob\\']))\\n    oob_list = list(oob_set)\\n    \\n    oob_table = pd.DataFrame(columns=splitter_columns+[\\'oob_index\\'])  #oob_index used to remember place in oob_list\\n    for index in oob_list:\\n        loan_row = table.iloc[index].copy()\\n        oob_table = oob_table.append(loan_row)\\n        end = oob_table.last_valid_index()\\n        oob_table.oob_index.loc[end] = index\\n \\n    return oob_table.reset_index()\\n\\ndef oob_vote_taker(row, forest):\\n    votes = {0:0, 1:0}\\n    for tree in forest:\\n        if row[\\'index\\'] in tree[\\'oob\\']:\\n            prediction = tree_predictor(row, tree)\\n            votes[prediction] += 1\\n    winner = 1 if votes[1]>votes[0] else 0  #ties go to 0\\n    if votes[0] == 0 and votes[1] == 0:\\n        raise LookupError(\\'row with no votes: \\' + str(index))\\n    return winner\\n\\n######  week 7\\n\\ndef row_to_vect(row, features):\\n    vect = []\\n    for feature in features:\\n        vect.append(float(row[feature]))\\n    return tuple(vect)\\n\\ndef euclidean_distance(vect1, vect2):\\n    sum = 0\\n    for i in range(len(vect1)):\\n        sum += (vect1[i] - vect2[i])**2\\n    return sum**.5  # I claim that this square root is not needed in K-NN - don\\'t need real distance and square root does not affect comparisons\\n\\n\\ndef all_distances(table, i, columns, target):\\n    distances = []\\n    vecti = row_to_vect(table.iloc[i], columns)\\n    for j in range(len(table)):\\n        if j == i: continue  # more efficient to let it through then trim after sorting?\\n        vectj = row_to_vect(table.iloc[j], columns)\\n        dist = euclidean_distance(vecti,vectj)\\n        distances.append((j, dist))\\n    return distances\\n\\ndef knn(i, table, columns, k, target):\\n    cut = int(k/2)\\n    \\'\\'\\'\\n    if i%10 == 0:\\n        print((i,\\'processed 10\\'))\\n    \\'\\'\\'\\n    distances = sorted(all_distances(table, i, columns, target), key=lambda pair: pair[1], reverse=False)\\n    rows = [table.iloc[pair[0]]  for pair in distances[:k]]\\n    predictions = [row[target] for row in rows]\\n    \\n    if sum(predictions) > cut:  #ties to 0\\n        prediction = 1\\n    else:\\n        prediction = 0\\n    return prediction'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "a3CXUrUXCoXE",
        "colab_type": "code",
        "outputId": "f3422b72-bf7e-482e-cdb7-696fcb03d78a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "cell_type": "code",
      "source": [
        "from library_w19_week7 import *\n",
        "%who function"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy\t all_distances\t build_pred\t build_tree_iter\t compute_prediction\t compute_training\t euclidean_distance\t f1\t find_best_splitter\t \n",
            "forest_builder\t forest_scores\t generate_table\t gig\t gini\t informedness\t k_fold\t k_fold_random\t knn\t \n",
            "oob_table\t oob_vote_taker\t path_id\t predictor_case\t probabilities\t produce_scores\t reorder_paths\t row_to_vect\t tree_predictor\t \n",
            "verify_unique\t vote_taker\t \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "aEW8foPAm91g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_columns', None)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mYPJRcSZsznx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h2>Columns used in all questions</h2>\n",
        "\n",
        "We will use 5 columns from the table to make predictions on `adopted`."
      ]
    },
    {
      "metadata": {
        "id": "3TDm9WllKCAv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "usable_columns = [\n",
        " 'n/s', 'mix', 'type_Cat', 'type_Dog', 'no_name'\n",
        "]\n",
        "\n",
        "target = 'adopted'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "843csVX-py7C"
      },
      "cell_type": "markdown",
      "source": [
        "<h1>\n",
        "Part 1. Explore random forest behavior\n",
        "</h1>\n",
        "<div class=h1_cell>\n",
        "<p>\n",
        "For prediction purposes, we have been treating a forest as a single predictor. It does call on its trees to get a prediction, but we don't see that. All we see is the final prediction. I'd like to dig deeper into individual tree behavior. I'll ask you to complete a set of programming problems to do this.\n",
        "</div>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "l9S58jH5py7D"
      },
      "cell_type": "markdown",
      "source": [
        "<h2>\n",
        "Problem 1. Build a matrix of tree predictions\n",
        "</h2>\n",
        "<div class=h1_cell>\n",
        "<p>\n",
        "The matrix will be a list of lists. Let's say the forest we are working with has 11 trees. Then the first list will be the predictions of the 11 trees for row 0 of the shelter table, i.e., it will be a list of 11 binary values. The next list will be the 11 predictions for row 1 of the shelter table. Given that we have 1000 rows in the shelter table, we will have 1000 lists in our outer list.\n",
        "<p>\n",
        "Let's say I store my matrix in `all_trees`. Then `all_trees[i][j]` will represent the vote of the jth tree for row i.\n",
        "  <p>\n",
        "    Here is what you should see for the first 10 rows.\n",
        "<p>\n",
        "<img src='https://www.dropbox.com/s/zwde42yc2z2lq4j/Screenshot%202019-02-18%2009.44.33.png?raw=1'>\n",
        "\n",
        "</div>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "kr4hJ08Tpy7D"
      },
      "cell_type": "markdown",
      "source": [
        "<h2>\n",
        "Here is forest to test on\n",
        "</h2>\n",
        "<div class=h1_cell>\n",
        "<p>\n",
        "  But first set random seeds so you get same results as mine.\n",
        "</div>"
      ]
    },
    {
      "metadata": {
        "id": "NN01O5OJqioB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "rng = np.random.RandomState(24)  #Will pass as arg to pandas sample method\n",
        "random.seed(2000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "d8f06252-c893-42e3-98b1-5c1d7f7c9dc2",
        "id": "GysL7AY8py7N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "forest11 = forest_builder(shelter_table, usable_columns, target, hypers={'total-trees':11, 'random-state':rng})\n",
        "len(forest11)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "DD3xu8n7py7O",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "bad5dea2-1a46-4025-b201-6a9cfe26a3dc",
        "id": "UjMSCnflpy7R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0],\n",
              " [1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1],\n",
              " [0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0],\n",
              " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1],\n",
              " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0],\n",
              " [0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "_F2mzKWhpy7a"
      },
      "cell_type": "markdown",
      "source": [
        "<h2>\n",
        "Problem 2: find the rows where all trees have the same answer\n",
        "</h2>\n",
        "<div class=h1_cell>\n",
        "<p>\n",
        "Right or wrong, they are unanimous. Place your answer in `unan_rows`.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "d77xY8cBpy7c",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "fs3ODoFhpy7k",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "unan_rows = unanimous_rows(all_trees)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "3e37e0e1-f599-48c0-fec6-1aabc9aa7af1",
        "id": "-bOH640Jpy7m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(unan_rows)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "244"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "metadata": {
        "id": "B2nxH1pBmWYS",
        "colab_type": "code",
        "outputId": "4e5f79ab-2cbd-4c48-96a8-edc9da6c570b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "print(unan_rows)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3, 5, 7, 10, 16, 17, 20, 31, 35, 37, 39, 41, 43, 47, 49, 50, 52, 55, 57, 64, 67, 68, 76, 77, 81, 83, 87, 88, 98, 102, 103, 113, 114, 115, 117, 123, 127, 137, 138, 147, 149, 156, 157, 158, 162, 164, 170, 179, 184, 187, 199, 200, 210, 214, 216, 218, 221, 230, 233, 239, 244, 246, 248, 256, 268, 272, 273, 277, 279, 280, 283, 285, 286, 294, 300, 312, 313, 318, 321, 326, 330, 336, 337, 339, 341, 343, 345, 347, 351, 356, 363, 366, 370, 382, 385, 387, 388, 391, 393, 399, 409, 418, 423, 428, 433, 439, 442, 443, 446, 448, 449, 454, 456, 458, 459, 464, 468, 473, 474, 478, 483, 487, 491, 493, 497, 498, 500, 505, 507, 508, 509, 511, 517, 522, 525, 527, 542, 558, 559, 562, 563, 566, 570, 576, 581, 587, 589, 593, 599, 600, 602, 603, 604, 609, 612, 613, 617, 619, 623, 625, 630, 632, 642, 643, 646, 647, 658, 666, 672, 676, 682, 700, 707, 712, 713, 722, 724, 726, 732, 738, 741, 745, 750, 751, 753, 754, 760, 761, 766, 768, 775, 781, 785, 787, 798, 802, 803, 804, 806, 808, 809, 811, 813, 818, 829, 831, 832, 834, 841, 843, 844, 852, 862, 863, 870, 877, 880, 886, 887, 893, 896, 910, 911, 924, 925, 929, 931, 938, 939, 942, 949, 950, 951, 956, 957, 968, 971, 980, 981, 986, 994, 996, 997, 998]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "zfxIr9ULpy7o"
      },
      "cell_type": "markdown",
      "source": [
        "<h2>\n",
        "Problem 3: find the trees that give the same answer for all rows\n",
        "</h2>\n",
        "<div class=h1_cell>\n",
        "<p>\n",
        "Which trees, if any, always produce the same prediction. Place your answer in `constant_trees`. The values in the list are tree indices.\n",
        "</div>"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "e1657413-f623-4e6f-9ea5-441ff870e214",
        "id": "V8S2qbF-py7y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "nc = never_change(all_trees)  #no trees are constant\n",
        "nc"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "metadata": {
        "id": "ilwS1scZzfLH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h2>Problem 4: razor-thin majority</h2>\n",
        "\n",
        "Find the rows that are decided by a bare majority. In the case of 11 trees, 6 vote one way and 5 the other. So majority of only 1 vote."
      ]
    },
    {
      "metadata": {
        "id": "Q_pi4NsX03tl",
        "colab_type": "code",
        "outputId": "934235ce-ae25-4994-b018-7e591d79599a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "cell_type": "code",
      "source": [
        "print(razor_list)\n",
        "len(razor_list)  #142"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[4, 9, 22, 33, 45, 59, 72, 75, 78, 80, 85, 91, 92, 95, 111, 121, 125, 132, 134, 139, 153, 165, 172, 174, 177, 178, 180, 186, 190, 192, 194, 211, 212, 225, 227, 229, 231, 232, 245, 249, 252, 254, 257, 260, 265, 271, 274, 278, 288, 293, 304, 320, 327, 335, 338, 344, 349, 354, 355, 357, 360, 365, 373, 378, 384, 389, 394, 396, 404, 407, 408, 414, 422, 441, 451, 467, 479, 501, 502, 514, 519, 520, 523, 533, 539, 541, 543, 554, 556, 569, 588, 591, 601, 605, 607, 629, 637, 640, 654, 673, 679, 706, 721, 723, 731, 743, 748, 762, 773, 774, 777, 786, 789, 797, 810, 812, 816, 817, 839, 848, 858, 864, 866, 868, 872, 873, 885, 897, 900, 909, 914, 919, 921, 927, 935, 937, 945, 947, 963, 972, 985, 989]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "142"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "KqgzYLNN1NKx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h1>Part 2. Explore K-NN behavior</h1>\n",
        "\n",
        "Once you have finished week 7 homework, you can take these on.\n",
        "<p>\n",
        "  Note: you may want to slice off the first 100 rows of the Shelter table for debugging. Remember that KNN runs slow. Once you are happy with results on small table you can try on full table. Up to you."
      ]
    },
    {
      "metadata": {
        "id": "Jci-WoYQkV1E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h2>\n",
        "Problem 5: K-NN voting weights\n",
        "</h2>\n",
        "<div class=h1_cell>\n",
        "<p>\n",
        "Normally the top K rows in K-NN have an equal vote. Let's modify this, I want a new voting scheme as follows:\n",
        "  <pre>\n",
        "  if a row in top-k is within 0 distance from the target row, give it 4 votes.\n",
        "  if a row in top-k is within 1 distance from the target row, give it 3 votes.\n",
        "  if a row in top-k is within 1.5 distance from the target row, give it 2 votes.\n",
        "  else give it 1 vote\n",
        "  </pre>\n",
        "  The row gets its top score. So a row within distance 0 gets exactly 4 votes.\n",
        "  <p>\n",
        "    Add the votes up as normal to get a prediction, ties go to prediction of 0.\n",
        "</div>"
      ]
    },
    {
      "metadata": {
        "id": "ZyDX4Zrivp7i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h2>Here are my results with k=10</h2>\n",
        "\n",
        "When I compute accuracy with no scaeld-voting, i.e., as normal, I get .621 accuracy.\n",
        "<p>\n",
        "When I compute accuracy with my new scaled-voting scheme, I get .596 accuracy."
      ]
    },
    {
      "metadata": {
        "id": "5-GPwByLIrHS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "all_predictions_w = []\n",
        "all_predictions_r = []\n",
        "for i in range(len(shelter_table)):\n",
        "  all_predictions_w.append(knn2(i, shelter_table, usable_columns, 10, target))\n",
        "  all_predictions_r.append(knn(i, shelter_table, usable_columns, 10, target))\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8JOyFRzlztQB",
        "colab_type": "code",
        "outputId": "f808a435-6b26-4585-edee-96f89b423bbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "z = list(zip(all_predictions_w, shelter_table[target]))\n",
        "correct = z.count((0,0)) + z.count((1,1))\n",
        "correct/len(shelter_table)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.596"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "nkHv9j6A2tC3",
        "colab_type": "code",
        "outputId": "9a7c6709-9385-4770-8922-be759ae929b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "z = list(zip(all_predictions_r, shelter_table[target]))\n",
        "correct = z.count((0,0)) + z.count((1,1))\n",
        "correct/len(shelter_table)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.621"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "hwmzC4vIkV1P",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h2>\n",
        "Problem 6: Determine how many times each row was correct\n",
        "</h2>\n",
        "<div class=h1_cell>\n",
        "<p>\n"
      ]
    },
    {
      "metadata": {
        "id": "GnzbWj5SAomY",
        "colab_type": "code",
        "outputId": "6f71b5f0-91cb-4382-97f0-33476c2d6b34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 16817
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "sorted(participant_pairs, key=lambda pair: pair[1], reverse=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 168),\n",
              " (13, 168),\n",
              " (14, 168),\n",
              " (19, 168),\n",
              " (24, 168),\n",
              " (3, 136),\n",
              " (7, 136),\n",
              " (10, 136),\n",
              " (16, 136),\n",
              " (37, 136),\n",
              " (39, 136),\n",
              " (41, 136),\n",
              " (43, 136),\n",
              " (47, 136),\n",
              " (50, 134),\n",
              " (15, 130),\n",
              " (28, 130),\n",
              " (2, 128),\n",
              " (8, 128),\n",
              " (12, 128),\n",
              " (23, 128),\n",
              " (26, 128),\n",
              " (40, 127),\n",
              " (44, 127),\n",
              " (51, 127),\n",
              " (22, 65),\n",
              " (59, 65),\n",
              " (78, 65),\n",
              " (80, 65),\n",
              " (91, 65),\n",
              " (95, 65),\n",
              " (1, 60),\n",
              " (21, 60),\n",
              " (29, 60),\n",
              " (38, 60),\n",
              " (46, 58),\n",
              " (33, 54),\n",
              " (45, 54),\n",
              " (75, 54),\n",
              " (92, 54),\n",
              " (17, 42),\n",
              " (20, 40),\n",
              " (31, 40),\n",
              " (114, 40),\n",
              " (117, 40),\n",
              " (147, 40),\n",
              " (199, 40),\n",
              " (214, 40),\n",
              " (230, 40),\n",
              " (248, 40),\n",
              " (6, 39),\n",
              " (18, 39),\n",
              " (25, 39),\n",
              " (42, 39),\n",
              " (60, 39),\n",
              " (62, 39),\n",
              " (73, 39),\n",
              " (82, 39),\n",
              " (118, 39),\n",
              " (35, 35),\n",
              " (57, 35),\n",
              " (88, 35),\n",
              " (210, 35),\n",
              " (283, 35),\n",
              " (312, 35),\n",
              " (370, 35),\n",
              " (439, 35),\n",
              " (446, 35),\n",
              " (32, 25),\n",
              " (89, 25),\n",
              " (97, 25),\n",
              " (140, 25),\n",
              " (141, 25),\n",
              " (166, 25),\n",
              " (11, 24),\n",
              " (99, 24),\n",
              " (122, 24),\n",
              " (146, 24),\n",
              " (191, 24),\n",
              " (202, 24),\n",
              " (215, 24),\n",
              " (226, 24),\n",
              " (5, 21),\n",
              " (30, 14),\n",
              " (67, 14),\n",
              " (79, 14),\n",
              " (195, 14),\n",
              " (203, 14),\n",
              " (337, 14),\n",
              " (382, 14),\n",
              " (393, 14),\n",
              " (399, 14),\n",
              " (442, 14),\n",
              " (449, 14),\n",
              " (478, 14),\n",
              " (517, 14),\n",
              " (4, 13),\n",
              " (9, 13),\n",
              " (72, 13),\n",
              " (85, 13),\n",
              " (174, 13),\n",
              " (212, 13),\n",
              " (245, 13),\n",
              " (265, 13),\n",
              " (152, 12),\n",
              " (168, 12),\n",
              " (52, 10),\n",
              " (448, 10),\n",
              " (642, 10),\n",
              " (169, 9),\n",
              " (286, 9),\n",
              " (124, 7),\n",
              " (344, 7),\n",
              " (49, 6),\n",
              " (157, 6),\n",
              " (229, 6),\n",
              " (237, 6),\n",
              " (300, 6),\n",
              " (304, 6),\n",
              " (522, 6),\n",
              " (609, 6),\n",
              " (738, 6),\n",
              " (893, 6),\n",
              " (27, 5),\n",
              " (54, 5),\n",
              " (111, 4),\n",
              " (76, 3),\n",
              " (156, 3),\n",
              " (164, 3),\n",
              " (269, 2),\n",
              " (804, 2),\n",
              " (285, 1),\n",
              " (386, 1),\n",
              " (845, 1),\n",
              " (996, 1),\n",
              " (34, 0),\n",
              " (36, 0),\n",
              " (48, 0),\n",
              " (53, 0),\n",
              " (55, 0),\n",
              " (56, 0),\n",
              " (58, 0),\n",
              " (61, 0),\n",
              " (63, 0),\n",
              " (64, 0),\n",
              " (65, 0),\n",
              " (66, 0),\n",
              " (68, 0),\n",
              " (69, 0),\n",
              " (70, 0),\n",
              " (71, 0),\n",
              " (74, 0),\n",
              " (77, 0),\n",
              " (81, 0),\n",
              " (83, 0),\n",
              " (84, 0),\n",
              " (86, 0),\n",
              " (87, 0),\n",
              " (90, 0),\n",
              " (93, 0),\n",
              " (94, 0),\n",
              " (96, 0),\n",
              " (98, 0),\n",
              " (100, 0),\n",
              " (101, 0),\n",
              " (102, 0),\n",
              " (103, 0),\n",
              " (104, 0),\n",
              " (105, 0),\n",
              " (106, 0),\n",
              " (107, 0),\n",
              " (108, 0),\n",
              " (109, 0),\n",
              " (110, 0),\n",
              " (112, 0),\n",
              " (113, 0),\n",
              " (115, 0),\n",
              " (116, 0),\n",
              " (119, 0),\n",
              " (120, 0),\n",
              " (121, 0),\n",
              " (123, 0),\n",
              " (125, 0),\n",
              " (126, 0),\n",
              " (127, 0),\n",
              " (128, 0),\n",
              " (129, 0),\n",
              " (130, 0),\n",
              " (131, 0),\n",
              " (132, 0),\n",
              " (133, 0),\n",
              " (134, 0),\n",
              " (135, 0),\n",
              " (136, 0),\n",
              " (137, 0),\n",
              " (138, 0),\n",
              " (139, 0),\n",
              " (142, 0),\n",
              " (143, 0),\n",
              " (144, 0),\n",
              " (145, 0),\n",
              " (148, 0),\n",
              " (149, 0),\n",
              " (150, 0),\n",
              " (151, 0),\n",
              " (153, 0),\n",
              " (154, 0),\n",
              " (155, 0),\n",
              " (158, 0),\n",
              " (159, 0),\n",
              " (160, 0),\n",
              " (161, 0),\n",
              " (162, 0),\n",
              " (163, 0),\n",
              " (165, 0),\n",
              " (167, 0),\n",
              " (170, 0),\n",
              " (171, 0),\n",
              " (172, 0),\n",
              " (173, 0),\n",
              " (175, 0),\n",
              " (176, 0),\n",
              " (177, 0),\n",
              " (178, 0),\n",
              " (179, 0),\n",
              " (180, 0),\n",
              " (181, 0),\n",
              " (182, 0),\n",
              " (183, 0),\n",
              " (184, 0),\n",
              " (185, 0),\n",
              " (186, 0),\n",
              " (187, 0),\n",
              " (188, 0),\n",
              " (189, 0),\n",
              " (190, 0),\n",
              " (192, 0),\n",
              " (193, 0),\n",
              " (194, 0),\n",
              " (196, 0),\n",
              " (197, 0),\n",
              " (198, 0),\n",
              " (200, 0),\n",
              " (201, 0),\n",
              " (204, 0),\n",
              " (205, 0),\n",
              " (206, 0),\n",
              " (207, 0),\n",
              " (208, 0),\n",
              " (209, 0),\n",
              " (211, 0),\n",
              " (213, 0),\n",
              " (216, 0),\n",
              " (217, 0),\n",
              " (218, 0),\n",
              " (219, 0),\n",
              " (220, 0),\n",
              " (221, 0),\n",
              " (222, 0),\n",
              " (223, 0),\n",
              " (224, 0),\n",
              " (225, 0),\n",
              " (227, 0),\n",
              " (228, 0),\n",
              " (231, 0),\n",
              " (232, 0),\n",
              " (233, 0),\n",
              " (234, 0),\n",
              " (235, 0),\n",
              " (236, 0),\n",
              " (238, 0),\n",
              " (239, 0),\n",
              " (240, 0),\n",
              " (241, 0),\n",
              " (242, 0),\n",
              " (243, 0),\n",
              " (244, 0),\n",
              " (246, 0),\n",
              " (247, 0),\n",
              " (249, 0),\n",
              " (250, 0),\n",
              " (251, 0),\n",
              " (252, 0),\n",
              " (253, 0),\n",
              " (254, 0),\n",
              " (255, 0),\n",
              " (256, 0),\n",
              " (257, 0),\n",
              " (258, 0),\n",
              " (259, 0),\n",
              " (260, 0),\n",
              " (261, 0),\n",
              " (262, 0),\n",
              " (263, 0),\n",
              " (264, 0),\n",
              " (266, 0),\n",
              " (267, 0),\n",
              " (268, 0),\n",
              " (270, 0),\n",
              " (271, 0),\n",
              " (272, 0),\n",
              " (273, 0),\n",
              " (274, 0),\n",
              " (275, 0),\n",
              " (276, 0),\n",
              " (277, 0),\n",
              " (278, 0),\n",
              " (279, 0),\n",
              " (280, 0),\n",
              " (281, 0),\n",
              " (282, 0),\n",
              " (284, 0),\n",
              " (287, 0),\n",
              " (288, 0),\n",
              " (289, 0),\n",
              " (290, 0),\n",
              " (291, 0),\n",
              " (292, 0),\n",
              " (293, 0),\n",
              " (294, 0),\n",
              " (295, 0),\n",
              " (296, 0),\n",
              " (297, 0),\n",
              " (298, 0),\n",
              " (299, 0),\n",
              " (301, 0),\n",
              " (302, 0),\n",
              " (303, 0),\n",
              " (305, 0),\n",
              " (306, 0),\n",
              " (307, 0),\n",
              " (308, 0),\n",
              " (309, 0),\n",
              " (310, 0),\n",
              " (311, 0),\n",
              " (313, 0),\n",
              " (314, 0),\n",
              " (315, 0),\n",
              " (316, 0),\n",
              " (317, 0),\n",
              " (318, 0),\n",
              " (319, 0),\n",
              " (320, 0),\n",
              " (321, 0),\n",
              " (322, 0),\n",
              " (323, 0),\n",
              " (324, 0),\n",
              " (325, 0),\n",
              " (326, 0),\n",
              " (327, 0),\n",
              " (328, 0),\n",
              " (329, 0),\n",
              " (330, 0),\n",
              " (331, 0),\n",
              " (332, 0),\n",
              " (333, 0),\n",
              " (334, 0),\n",
              " (335, 0),\n",
              " (336, 0),\n",
              " (338, 0),\n",
              " (339, 0),\n",
              " (340, 0),\n",
              " (341, 0),\n",
              " (342, 0),\n",
              " (343, 0),\n",
              " (345, 0),\n",
              " (346, 0),\n",
              " (347, 0),\n",
              " (348, 0),\n",
              " (349, 0),\n",
              " (350, 0),\n",
              " (351, 0),\n",
              " (352, 0),\n",
              " (353, 0),\n",
              " (354, 0),\n",
              " (355, 0),\n",
              " (356, 0),\n",
              " (357, 0),\n",
              " (358, 0),\n",
              " (359, 0),\n",
              " (360, 0),\n",
              " (361, 0),\n",
              " (362, 0),\n",
              " (363, 0),\n",
              " (364, 0),\n",
              " (365, 0),\n",
              " (366, 0),\n",
              " (367, 0),\n",
              " (368, 0),\n",
              " (369, 0),\n",
              " (371, 0),\n",
              " (372, 0),\n",
              " (373, 0),\n",
              " (374, 0),\n",
              " (375, 0),\n",
              " (376, 0),\n",
              " (377, 0),\n",
              " (378, 0),\n",
              " (379, 0),\n",
              " (380, 0),\n",
              " (381, 0),\n",
              " (383, 0),\n",
              " (384, 0),\n",
              " (385, 0),\n",
              " (387, 0),\n",
              " (388, 0),\n",
              " (389, 0),\n",
              " (390, 0),\n",
              " (391, 0),\n",
              " (392, 0),\n",
              " (394, 0),\n",
              " (395, 0),\n",
              " (396, 0),\n",
              " (397, 0),\n",
              " (398, 0),\n",
              " (400, 0),\n",
              " (401, 0),\n",
              " (402, 0),\n",
              " (403, 0),\n",
              " (404, 0),\n",
              " (405, 0),\n",
              " (406, 0),\n",
              " (407, 0),\n",
              " (408, 0),\n",
              " (409, 0),\n",
              " (410, 0),\n",
              " (411, 0),\n",
              " (412, 0),\n",
              " (413, 0),\n",
              " (414, 0),\n",
              " (415, 0),\n",
              " (416, 0),\n",
              " (417, 0),\n",
              " (418, 0),\n",
              " (419, 0),\n",
              " (420, 0),\n",
              " (421, 0),\n",
              " (422, 0),\n",
              " (423, 0),\n",
              " (424, 0),\n",
              " (425, 0),\n",
              " (426, 0),\n",
              " (427, 0),\n",
              " (428, 0),\n",
              " (429, 0),\n",
              " (430, 0),\n",
              " (431, 0),\n",
              " (432, 0),\n",
              " (433, 0),\n",
              " (434, 0),\n",
              " (435, 0),\n",
              " (436, 0),\n",
              " (437, 0),\n",
              " (438, 0),\n",
              " (440, 0),\n",
              " (441, 0),\n",
              " (443, 0),\n",
              " (444, 0),\n",
              " (445, 0),\n",
              " (447, 0),\n",
              " (450, 0),\n",
              " (451, 0),\n",
              " (452, 0),\n",
              " (453, 0),\n",
              " (454, 0),\n",
              " (455, 0),\n",
              " (456, 0),\n",
              " (457, 0),\n",
              " (458, 0),\n",
              " (459, 0),\n",
              " (460, 0),\n",
              " (461, 0),\n",
              " (462, 0),\n",
              " (463, 0),\n",
              " (464, 0),\n",
              " (465, 0),\n",
              " (466, 0),\n",
              " (467, 0),\n",
              " (468, 0),\n",
              " (469, 0),\n",
              " (470, 0),\n",
              " (471, 0),\n",
              " (472, 0),\n",
              " (473, 0),\n",
              " (474, 0),\n",
              " (475, 0),\n",
              " (476, 0),\n",
              " (477, 0),\n",
              " (479, 0),\n",
              " (480, 0),\n",
              " (481, 0),\n",
              " (482, 0),\n",
              " (483, 0),\n",
              " (484, 0),\n",
              " (485, 0),\n",
              " (486, 0),\n",
              " (487, 0),\n",
              " (488, 0),\n",
              " (489, 0),\n",
              " (490, 0),\n",
              " (491, 0),\n",
              " (492, 0),\n",
              " (493, 0),\n",
              " (494, 0),\n",
              " (495, 0),\n",
              " (496, 0),\n",
              " (497, 0),\n",
              " (498, 0),\n",
              " (499, 0),\n",
              " (500, 0),\n",
              " (501, 0),\n",
              " (502, 0),\n",
              " (503, 0),\n",
              " (504, 0),\n",
              " (505, 0),\n",
              " (506, 0),\n",
              " (507, 0),\n",
              " (508, 0),\n",
              " (509, 0),\n",
              " (510, 0),\n",
              " (511, 0),\n",
              " (512, 0),\n",
              " (513, 0),\n",
              " (514, 0),\n",
              " (515, 0),\n",
              " (516, 0),\n",
              " (518, 0),\n",
              " (519, 0),\n",
              " (520, 0),\n",
              " (521, 0),\n",
              " (523, 0),\n",
              " (524, 0),\n",
              " (525, 0),\n",
              " (526, 0),\n",
              " (527, 0),\n",
              " (528, 0),\n",
              " (529, 0),\n",
              " (530, 0),\n",
              " (531, 0),\n",
              " (532, 0),\n",
              " (533, 0),\n",
              " (534, 0),\n",
              " (535, 0),\n",
              " (536, 0),\n",
              " (537, 0),\n",
              " (538, 0),\n",
              " (539, 0),\n",
              " (540, 0),\n",
              " (541, 0),\n",
              " (542, 0),\n",
              " (543, 0),\n",
              " (544, 0),\n",
              " (545, 0),\n",
              " (546, 0),\n",
              " (547, 0),\n",
              " (548, 0),\n",
              " (549, 0),\n",
              " (550, 0),\n",
              " (551, 0),\n",
              " (552, 0),\n",
              " (553, 0),\n",
              " (554, 0),\n",
              " (555, 0),\n",
              " (556, 0),\n",
              " (557, 0),\n",
              " (558, 0),\n",
              " (559, 0),\n",
              " (560, 0),\n",
              " (561, 0),\n",
              " (562, 0),\n",
              " (563, 0),\n",
              " (564, 0),\n",
              " (565, 0),\n",
              " (566, 0),\n",
              " (567, 0),\n",
              " (568, 0),\n",
              " (569, 0),\n",
              " (570, 0),\n",
              " (571, 0),\n",
              " (572, 0),\n",
              " (573, 0),\n",
              " (574, 0),\n",
              " (575, 0),\n",
              " (576, 0),\n",
              " (577, 0),\n",
              " (578, 0),\n",
              " (579, 0),\n",
              " (580, 0),\n",
              " (581, 0),\n",
              " (582, 0),\n",
              " (583, 0),\n",
              " (584, 0),\n",
              " (585, 0),\n",
              " (586, 0),\n",
              " (587, 0),\n",
              " (588, 0),\n",
              " (589, 0),\n",
              " (590, 0),\n",
              " (591, 0),\n",
              " (592, 0),\n",
              " (593, 0),\n",
              " (594, 0),\n",
              " (595, 0),\n",
              " (596, 0),\n",
              " (597, 0),\n",
              " (598, 0),\n",
              " (599, 0),\n",
              " (600, 0),\n",
              " (601, 0),\n",
              " (602, 0),\n",
              " (603, 0),\n",
              " (604, 0),\n",
              " (605, 0),\n",
              " (606, 0),\n",
              " (607, 0),\n",
              " (608, 0),\n",
              " (610, 0),\n",
              " (611, 0),\n",
              " (612, 0),\n",
              " (613, 0),\n",
              " (614, 0),\n",
              " (615, 0),\n",
              " (616, 0),\n",
              " (617, 0),\n",
              " (618, 0),\n",
              " (619, 0),\n",
              " (620, 0),\n",
              " (621, 0),\n",
              " (622, 0),\n",
              " (623, 0),\n",
              " (624, 0),\n",
              " (625, 0),\n",
              " (626, 0),\n",
              " (627, 0),\n",
              " (628, 0),\n",
              " (629, 0),\n",
              " (630, 0),\n",
              " (631, 0),\n",
              " (632, 0),\n",
              " (633, 0),\n",
              " (634, 0),\n",
              " (635, 0),\n",
              " (636, 0),\n",
              " (637, 0),\n",
              " (638, 0),\n",
              " (639, 0),\n",
              " (640, 0),\n",
              " (641, 0),\n",
              " (643, 0),\n",
              " (644, 0),\n",
              " (645, 0),\n",
              " (646, 0),\n",
              " (647, 0),\n",
              " (648, 0),\n",
              " (649, 0),\n",
              " (650, 0),\n",
              " (651, 0),\n",
              " (652, 0),\n",
              " (653, 0),\n",
              " (654, 0),\n",
              " (655, 0),\n",
              " (656, 0),\n",
              " (657, 0),\n",
              " (658, 0),\n",
              " (659, 0),\n",
              " (660, 0),\n",
              " (661, 0),\n",
              " (662, 0),\n",
              " (663, 0),\n",
              " (664, 0),\n",
              " (665, 0),\n",
              " (666, 0),\n",
              " (667, 0),\n",
              " (668, 0),\n",
              " (669, 0),\n",
              " (670, 0),\n",
              " (671, 0),\n",
              " (672, 0),\n",
              " (673, 0),\n",
              " (674, 0),\n",
              " (675, 0),\n",
              " (676, 0),\n",
              " (677, 0),\n",
              " (678, 0),\n",
              " (679, 0),\n",
              " (680, 0),\n",
              " (681, 0),\n",
              " (682, 0),\n",
              " (683, 0),\n",
              " (684, 0),\n",
              " (685, 0),\n",
              " (686, 0),\n",
              " (687, 0),\n",
              " (688, 0),\n",
              " (689, 0),\n",
              " (690, 0),\n",
              " (691, 0),\n",
              " (692, 0),\n",
              " (693, 0),\n",
              " (694, 0),\n",
              " (695, 0),\n",
              " (696, 0),\n",
              " (697, 0),\n",
              " (698, 0),\n",
              " (699, 0),\n",
              " (700, 0),\n",
              " (701, 0),\n",
              " (702, 0),\n",
              " (703, 0),\n",
              " (704, 0),\n",
              " (705, 0),\n",
              " (706, 0),\n",
              " (707, 0),\n",
              " (708, 0),\n",
              " (709, 0),\n",
              " (710, 0),\n",
              " (711, 0),\n",
              " (712, 0),\n",
              " (713, 0),\n",
              " (714, 0),\n",
              " (715, 0),\n",
              " (716, 0),\n",
              " (717, 0),\n",
              " (718, 0),\n",
              " (719, 0),\n",
              " (720, 0),\n",
              " (721, 0),\n",
              " (722, 0),\n",
              " (723, 0),\n",
              " (724, 0),\n",
              " (725, 0),\n",
              " (726, 0),\n",
              " (727, 0),\n",
              " (728, 0),\n",
              " (729, 0),\n",
              " (730, 0),\n",
              " (731, 0),\n",
              " (732, 0),\n",
              " (733, 0),\n",
              " (734, 0),\n",
              " (735, 0),\n",
              " (736, 0),\n",
              " (737, 0),\n",
              " (739, 0),\n",
              " (740, 0),\n",
              " (741, 0),\n",
              " (742, 0),\n",
              " (743, 0),\n",
              " (744, 0),\n",
              " (745, 0),\n",
              " (746, 0),\n",
              " (747, 0),\n",
              " (748, 0),\n",
              " (749, 0),\n",
              " (750, 0),\n",
              " (751, 0),\n",
              " (752, 0),\n",
              " (753, 0),\n",
              " (754, 0),\n",
              " (755, 0),\n",
              " (756, 0),\n",
              " (757, 0),\n",
              " (758, 0),\n",
              " (759, 0),\n",
              " (760, 0),\n",
              " (761, 0),\n",
              " (762, 0),\n",
              " (763, 0),\n",
              " (764, 0),\n",
              " (765, 0),\n",
              " (766, 0),\n",
              " (767, 0),\n",
              " (768, 0),\n",
              " (769, 0),\n",
              " (770, 0),\n",
              " (771, 0),\n",
              " (772, 0),\n",
              " (773, 0),\n",
              " (774, 0),\n",
              " (775, 0),\n",
              " (776, 0),\n",
              " (777, 0),\n",
              " (778, 0),\n",
              " (779, 0),\n",
              " (780, 0),\n",
              " (781, 0),\n",
              " (782, 0),\n",
              " (783, 0),\n",
              " (784, 0),\n",
              " (785, 0),\n",
              " (786, 0),\n",
              " (787, 0),\n",
              " (788, 0),\n",
              " (789, 0),\n",
              " (790, 0),\n",
              " (791, 0),\n",
              " (792, 0),\n",
              " (793, 0),\n",
              " (794, 0),\n",
              " (795, 0),\n",
              " (796, 0),\n",
              " (797, 0),\n",
              " (798, 0),\n",
              " (799, 0),\n",
              " (800, 0),\n",
              " (801, 0),\n",
              " (802, 0),\n",
              " (803, 0),\n",
              " (805, 0),\n",
              " (806, 0),\n",
              " (807, 0),\n",
              " (808, 0),\n",
              " (809, 0),\n",
              " (810, 0),\n",
              " (811, 0),\n",
              " (812, 0),\n",
              " (813, 0),\n",
              " (814, 0),\n",
              " (815, 0),\n",
              " (816, 0),\n",
              " (817, 0),\n",
              " (818, 0),\n",
              " (819, 0),\n",
              " (820, 0),\n",
              " (821, 0),\n",
              " (822, 0),\n",
              " (823, 0),\n",
              " (824, 0),\n",
              " (825, 0),\n",
              " (826, 0),\n",
              " (827, 0),\n",
              " (828, 0),\n",
              " (829, 0),\n",
              " (830, 0),\n",
              " (831, 0),\n",
              " (832, 0),\n",
              " (833, 0),\n",
              " (834, 0),\n",
              " (835, 0),\n",
              " (836, 0),\n",
              " (837, 0),\n",
              " (838, 0),\n",
              " (839, 0),\n",
              " (840, 0),\n",
              " (841, 0),\n",
              " (842, 0),\n",
              " (843, 0),\n",
              " (844, 0),\n",
              " (846, 0),\n",
              " (847, 0),\n",
              " (848, 0),\n",
              " (849, 0),\n",
              " (850, 0),\n",
              " (851, 0),\n",
              " (852, 0),\n",
              " (853, 0),\n",
              " (854, 0),\n",
              " (855, 0),\n",
              " (856, 0),\n",
              " (857, 0),\n",
              " (858, 0),\n",
              " (859, 0),\n",
              " (860, 0),\n",
              " (861, 0),\n",
              " (862, 0),\n",
              " (863, 0),\n",
              " (864, 0),\n",
              " (865, 0),\n",
              " (866, 0),\n",
              " (867, 0),\n",
              " (868, 0),\n",
              " (869, 0),\n",
              " (870, 0),\n",
              " (871, 0),\n",
              " (872, 0),\n",
              " (873, 0),\n",
              " (874, 0),\n",
              " (875, 0),\n",
              " (876, 0),\n",
              " (877, 0),\n",
              " (878, 0),\n",
              " (879, 0),\n",
              " (880, 0),\n",
              " (881, 0),\n",
              " (882, 0),\n",
              " (883, 0),\n",
              " (884, 0),\n",
              " (885, 0),\n",
              " (886, 0),\n",
              " (887, 0),\n",
              " (888, 0),\n",
              " (889, 0),\n",
              " (890, 0),\n",
              " (891, 0),\n",
              " (892, 0),\n",
              " (894, 0),\n",
              " (895, 0),\n",
              " (896, 0),\n",
              " (897, 0),\n",
              " (898, 0),\n",
              " (899, 0),\n",
              " (900, 0),\n",
              " (901, 0),\n",
              " (902, 0),\n",
              " (903, 0),\n",
              " (904, 0),\n",
              " (905, 0),\n",
              " (906, 0),\n",
              " (907, 0),\n",
              " (908, 0),\n",
              " (909, 0),\n",
              " (910, 0),\n",
              " (911, 0),\n",
              " (912, 0),\n",
              " (913, 0),\n",
              " (914, 0),\n",
              " (915, 0),\n",
              " (916, 0),\n",
              " (917, 0),\n",
              " (918, 0),\n",
              " (919, 0),\n",
              " (920, 0),\n",
              " (921, 0),\n",
              " (922, 0),\n",
              " (923, 0),\n",
              " (924, 0),\n",
              " (925, 0),\n",
              " (926, 0),\n",
              " (927, 0),\n",
              " (928, 0),\n",
              " (929, 0),\n",
              " (930, 0),\n",
              " (931, 0),\n",
              " (932, 0),\n",
              " (933, 0),\n",
              " (934, 0),\n",
              " (935, 0),\n",
              " (936, 0),\n",
              " (937, 0),\n",
              " (938, 0),\n",
              " (939, 0),\n",
              " (940, 0),\n",
              " (941, 0),\n",
              " (942, 0),\n",
              " (943, 0),\n",
              " (944, 0),\n",
              " (945, 0),\n",
              " (946, 0),\n",
              " (947, 0),\n",
              " (948, 0),\n",
              " (949, 0),\n",
              " (950, 0),\n",
              " (951, 0),\n",
              " (952, 0),\n",
              " (953, 0),\n",
              " (954, 0),\n",
              " (955, 0),\n",
              " (956, 0),\n",
              " (957, 0),\n",
              " (958, 0),\n",
              " (959, 0),\n",
              " (960, 0),\n",
              " (961, 0),\n",
              " (962, 0),\n",
              " (963, 0),\n",
              " (964, 0),\n",
              " (965, 0),\n",
              " (966, 0),\n",
              " (967, 0),\n",
              " (968, 0),\n",
              " (969, 0),\n",
              " (970, 0),\n",
              " (971, 0),\n",
              " (972, 0),\n",
              " (973, 0),\n",
              " (974, 0),\n",
              " (975, 0),\n",
              " (976, 0),\n",
              " (977, 0),\n",
              " (978, 0),\n",
              " (979, 0),\n",
              " (980, 0),\n",
              " (981, 0),\n",
              " (982, 0),\n",
              " (983, 0),\n",
              " (984, 0),\n",
              " (985, 0),\n",
              " (986, 0),\n",
              " (987, 0),\n",
              " (988, 0),\n",
              " (989, 0),\n",
              " (990, 0),\n",
              " (991, 0),\n",
              " (992, 0),\n",
              " (993, 0),\n",
              " (994, 0),\n",
              " (995, 0),\n",
              " (997, 0),\n",
              " (998, 0),\n",
              " (999, 0)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "metadata": {
        "id": "wSwL7UbjB9ZG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h2>Problem 7: K-NN how many voting blocks</h2>\n",
        "  \n",
        "  I'd like to know how often pairs of rows in the top-k vote the same. So if k is 3, I will have 3 rows in top-3. Call them r1, r2, r3. I would check the following:\n",
        "  \n",
        "1. if (r1,r2) vote the same then I record that.\n",
        "2. if (r1,r3) vote the same then I record that.\n",
        "3. if (r2,r3) vote the same then I record that.\n",
        "\n",
        "I do that for the entire table. What I whould have is a list or dictionary of counts across the entire table. Final I thing I want is sorted list. Here is first part of sorted list I got for k = 10.\n",
        "<pre>\n",
        "[((2, 23), 296),\n",
        " ((2, 26), 296),\n",
        " ((0, 13), 296),\n",
        " ((0, 14), 296),\n",
        " ((0, 19), 296),\n",
        " ((0, 24), 296),\n",
        " ((2, 12), 294),\n",
        " ((8, 26), 288),\n",
        " ((1, 29), 190),\n",
        " ((1, 38), 190),\n",
        " ((1, 21), 189),\n",
        " ((1, 46), 185),\n",
        " ((3, 39), 136),\n",
        " ((3, 41), 136),\n",
        " ((3, 43), 136),\n",
        " ((3, 47), 136),\n",
        " ((7, 50), 134),\n",
        " ((3, 50), 134),\n",
        " ((3, 37), 133),\n",
        " ((7, 47), 129),\n",
        " ((6, 118), 46),\n",
        " ((6, 82), 40),\n",
        " ((4, 229), 19),\n",
        " ((4, 304), 19),\n",
        " ((4, 5), 14),\n",
        " ((5, 449), 13),\n",
        " ((5, 478), 13),\n",
        " ((5, 517), 13),\n",
        "</pre>"
      ]
    },
    {
      "metadata": {
        "id": "TTSmXPs9DcoT",
        "colab_type": "code",
        "outputId": "9a97ce32-3f2a-4c51-ec87-86fea7edfd71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "sorted(block_pairs, key=lambda pair: pair[1], reverse=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[((2, 23), 296),\n",
              " ((2, 26), 296),\n",
              " ((0, 13), 296),\n",
              " ((0, 14), 296),\n",
              " ((0, 19), 296),\n",
              " ((0, 24), 296),\n",
              " ((2, 12), 294),\n",
              " ((8, 26), 288),\n",
              " ((1, 29), 190),\n",
              " ((1, 38), 190),\n",
              " ((1, 21), 189),\n",
              " ((1, 46), 185),\n",
              " ((3, 39), 136),\n",
              " ((3, 41), 136),\n",
              " ((3, 43), 136),\n",
              " ((3, 47), 136),\n",
              " ((7, 50), 134),\n",
              " ((3, 50), 134),\n",
              " ((3, 37), 133),\n",
              " ((7, 47), 129),\n",
              " ((6, 118), 46),\n",
              " ((6, 82), 40),\n",
              " ((4, 229), 19),\n",
              " ((4, 304), 19),\n",
              " ((4, 5), 14),\n",
              " ((5, 449), 13),\n",
              " ((5, 478), 13),\n",
              " ((5, 517), 13),\n",
              " ((2, 27), 9),\n",
              " ((8, 27), 9),\n",
              " ((7, 52), 9),\n",
              " ((3, 52), 9),\n",
              " ((6, 169), 9),\n",
              " ((5, 642), 9),\n",
              " ((5, 442), 8),\n",
              " ((4, 4), 7),\n",
              " ((4, 17), 7),\n",
              " ((5, 5), 7),\n",
              " ((5, 17), 7),\n",
              " ((4, 893), 6),\n",
              " ((1, 1), 5),\n",
              " ((1, 996), 4),\n",
              " ((3, 16), 2),\n",
              " ((7, 43), 2),\n",
              " ((1, 285), 2),\n",
              " ((4, 738), 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "uk10ZgNKu08G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}