{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Practice_Midterm2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "CcejYk1YkV0f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h1>\n",
        "<center>\n",
        "Practice Midterm 2\n",
        "</center>\n",
        "</h1>\n",
        "<div class=h1_cell>\n",
        "<p>\n",
        "The Practice and Actual midterm will focus on weeks 6 and 7. In particular, you will be asked to import your week7 library. You can still work on the week6 piece of this practice midterm but will need to finish week7 homework to do it all.\n",
        "<p>\n",
        "  I'll use the shelter table here. The actual midterm will use another dataset.\n",
        "</div>"
      ]
    },
    {
      "metadata": {
        "id": "jW3rzozVkvEB",
        "colab_type": "code",
        "outputId": "94724803-9b52-483c-95dd-b145f4c5eaa4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math \n",
        "import operator\n",
        "\n",
        "shelter_table = pd.read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vT44JuI4VWv1ZOov2Gz7ZlMZk4scUkI5xXbwGQwK455Ue7a-jy77KZ_olLf6JQyBl7RjeNmF2KOIiwE/pub?gid=1192502698&single=true&output=csv')\n",
        "shelter_table.head(1)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AnimalID</th>\n",
              "      <th>Name</th>\n",
              "      <th>DateTime</th>\n",
              "      <th>OutcomeType</th>\n",
              "      <th>OutcomeSubtype</th>\n",
              "      <th>AnimalType</th>\n",
              "      <th>SexuponOutcome</th>\n",
              "      <th>AgeuponOutcome</th>\n",
              "      <th>Breed</th>\n",
              "      <th>Color</th>\n",
              "      <th>adopted</th>\n",
              "      <th>n/s</th>\n",
              "      <th>mix</th>\n",
              "      <th>type_Cat</th>\n",
              "      <th>type_Dog</th>\n",
              "      <th>no_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A671945</td>\n",
              "      <td>Hambone</td>\n",
              "      <td>2/12/2014 18:22:00</td>\n",
              "      <td>Return_to_owner</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Dog</td>\n",
              "      <td>Neutered Male</td>\n",
              "      <td>1 year</td>\n",
              "      <td>Shetland Sheepdog Mix</td>\n",
              "      <td>Brown/White</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  AnimalID     Name            DateTime      OutcomeType OutcomeSubtype  \\\n",
              "0  A671945  Hambone  2/12/2014 18:22:00  Return_to_owner            NaN   \n",
              "\n",
              "  AnimalType SexuponOutcome AgeuponOutcome                  Breed  \\\n",
              "0        Dog  Neutered Male         1 year  Shetland Sheepdog Mix   \n",
              "\n",
              "         Color  adopted  n/s  mix  type_Cat  type_Dog  no_name  \n",
              "0  Brown/White        0    1    1         0         1        0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "mU7U1eqxjPWo",
        "colab_type": "code",
        "outputId": "1b015e13-c4e9-4d65-d2d4-d366ff0bf53b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(shelter_table)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "4j7H9XDmLW2n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Note that if you are not done with week 7 homework, you can load week6b instead and work on the first part on random forests\n",
        "\n",
        "!rm library_w19_week7.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x5caMXU3m91b",
        "colab_type": "code",
        "outputId": "904fc192-a389-4f8a-8ce3-21dcc9d1bb74",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b75c312d-74f1-4109-be5b-0231f86a188a\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-b75c312d-74f1-4109-be5b-0231f86a188a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving library_w19_week7.py to library_w19_week7.py\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'library_w19_week7.py': b'import pandas as pd\\r\\nimport numpy as np\\r\\nfrom functools import reduce\\r\\nfrom types import SimpleNamespace\\r\\nimport random\\r\\nimport math\\r\\nimport operator\\r\\n\\r\\n\\r\\ndef predictor_case(row, pred, target):\\r\\n    case_dict = {(0,0): \\'true_negative\\', (1,1): \\'true_positive\\', (0,1): \\'false_negative\\', (1,0): \\'false_positive\\'}\\r\\n    actual = row[target]\\r\\n    prediction = row[pred]\\r\\n    case = case_dict[(prediction, actual)]\\r\\n    return case\\r\\n\\r\\ndef accuracy(cases):\\r\\n   # if cases.empty:\\r\\n    #    return 0\\r\\n    tp = 0\\r\\n    if \\'true_positive\\'in cases:\\r\\n        tp = cases[\\'true_positive\\']\\r\\n    tn = 0\\r\\n    if \\'true_negative\\' in cases:\\r\\n        tn = cases[\\'true_negative\\']\\r\\n    fp =0\\r\\n    if \\'false_positive\\' in cases:\\r\\n        fp = cases[\\'false_positive\\']\\r\\n    fn = 0\\r\\n    if \\'false_negative\\' in cases:\\r\\n        fn = cases[\\'false_negative\\']\\r\\n    if (tp+tn+fp+fn)==0:\\r\\n        return 0\\r\\n    else:\\r\\n        return (tp + tn)/(tp+tn+fp+fn)\\r\\n\\r\\ndef f1(cases):\\r\\n   # if cases.empty:\\r\\n    #    return 0\\r\\n    tp = 0\\r\\n    if \\'true_positive\\'in cases:\\r\\n        tp = cases[\\'true_positive\\']\\r\\n    tn = 0\\r\\n    if \\'true_negative\\' in cases:\\r\\n        tn = cases[\\'true_negative\\']\\r\\n    fp =0\\r\\n    if \\'false_positive\\' in cases:\\r\\n        fp = cases[\\'false_positive\\']\\r\\n    fn = 0\\r\\n    if \\'false_negative\\' in cases:\\r\\n        fn = cases[\\'false_negative\\']\\r\\n  #other measures we can derive\\r\\n    if (((tp+fn) == 0) or ((tp+fp) == 0)):\\r\\n        return 0\\r\\n    else:\\r\\n        recall = 1.0*tp/(tp+fn)  # positive correct divided by total positive in the table\\r\\n        precision = 1.0*tp/(tp+fp) # positive correct divided by all positive predictions made\\r\\n    \\r\\n  #now for the one we want\\r\\n    if ((recall == 0) or (precision == 0)):\\r\\n        return 0\\r\\n    else:\\r\\n        f1 = 2/(1/recall + 1/precision)\\r\\n    return f1\\r\\n\\r\\ndef informedness(cases):\\r\\n   # if cases.empty:\\r\\n    #    return -1\\r\\n    tp = 0\\r\\n    if \\'true_positive\\'in cases:\\r\\n      tp = cases[\\'true_positive\\']\\r\\n    tn = 0\\r\\n    if \\'true_negative\\' in cases:\\r\\n      tn = cases[\\'true_negative\\']\\r\\n    fp =0\\r\\n    if \\'false_positive\\' in cases:\\r\\n        fp = cases[\\'false_positive\\']\\r\\n    fn = 0\\r\\n    if \\'false_negative\\' in cases:\\r\\n        fn = cases[\\'false_negative\\']\\r\\n  #other measures we can derive\\r\\n    if (((tp+fn) == 0) or ((tn+fp) == 0)):\\r\\n        return 0\\r\\n    else:\\r\\n        recall = 1.0*tp/(tp+fn)  # positive correct divided by total positive in the table\\r\\n        specificty = 1.0*tn/(tn+fp)\\r\\n        J = (recall + specificty) - 1\\r\\n    return J\\r\\n\\r\\ndef gini(counts):\\r\\n    (p0,p1) = probabilities(counts)\\r\\n    sum_probs = p0**2 + p1**2\\r\\n    gini = 1 - sum_probs\\r\\n    return gini\\r\\n\\r\\ndef gig(starting_table, split_column, target_column):\\r\\n    \\r\\n    #split into two branches, i.e., two sub-tables\\r\\n    true_table = starting_table.loc[starting_table[split_column] == 1]\\r\\n    false_table = starting_table.loc[starting_table[split_column] == 0]\\r\\n    \\r\\n    #Now see how the target column is divided up in each sub-table (and the starting table)\\r\\n    true_counts = true_table[target_column].value_counts()  # Note using true_table and not starting_table\\r\\n    false_counts = false_table[target_column].value_counts()  # Note using false_table and not starting_table\\r\\n    starting_counts = starting_table[target_column].value_counts() \\r\\n    \\r\\n    #compute the gini impurity for the 3 tables\\r\\n    starting_gini = gini(starting_counts)\\r\\n    true_gini = gini(true_counts)\\r\\n    false_gini = gini(false_counts)\\r\\n\\r\\n    #compute the weights\\r\\n    starting_size = len(starting_table.index)\\r\\n    true_weight = 0.0 if starting_size == 0 else len(true_table.index)/starting_size\\r\\n    false_weight = 0.0 if starting_size == 0 else len(false_table.index)/starting_size\\r\\n    \\r\\n    #wrap it up and put on a bow\\r\\n    gig = starting_gini - (true_weight * true_gini + false_weight * false_gini)\\r\\n    \\r\\n    return gig\\r\\n\\r\\ndef probabilities(counts):\\r\\n    count_0 = 0 if 0 not in counts else counts[0]  #could have no 0 values\\r\\n    count_1 = 0 if 1 not in counts else counts[1]\\r\\n    total = count_0 + count_1\\r\\n    probs = (0,0) if total == 0 else (count_0/total, count_1/total)  #build 2-tuple\\r\\n    return probs\\r\\n\\r\\ndef build_pred(column,branch):\\r\\n    return lambda row: row[column] == branch\\r\\n\\r\\ndef find_best_splitter(table, choice_list, target):\\r\\n  \\r\\n    assert (len(table)>0),\"Cannot split empty table\"\\r\\n    assert (target in table),\"Target must be column in table\"\\r\\n    \\r\\n    gig_scores = map(lambda col: (col, gig(table, col, target)), choice_list)  #compute tuple (col, gig) for each column\\r\\n    gig_sorted = sorted(gig_scores, key=lambda item: item[1], reverse=True)  # sort on gig\\r\\n    return gig_sorted\\r\\n\\r\\nfrom functools import reduce\\r\\n\\r\\ndef generate_table(table, conjunction):\\r\\n    assert (len(table)>0),\"Cannot generate from empty table\"\\r\\n    sub_table = reduce(lambda subtable, pair: subtable.loc[pair[1]], conjunction, table)\\r\\n    return sub_table\\r\\n\\r\\ndef compute_prediction(table, target):\\r\\n  \\r\\n    assert (len(table)>0),\"Cannot predict from empty table\"\\r\\n    assert (target in table),\"Target must be column in table\"\\r\\n    \\r\\n    counts = table[target].value_counts()  # counts looks like {0: v1, 1: v2}\\r\\n\\r\\n    if 0 not in counts:\\r\\n        prediction = 1\\r\\n    elif 1 not in counts:\\r\\n        prediction = 0\\r\\n    elif counts[1] > counts[0]:  # ties go to 0 (negative)\\r\\n        prediction = 1\\r\\n    else:\\r\\n        prediction = 0\\r\\n\\r\\n    return prediction\\r\\n\\r\\ndef build_tree_iter(table, choices, target, hypers={} ):\\r\\n    assert (len(choices)>0),\"Must have at least one column in choices\"\\r\\n    assert (target in table), \"Target column not in table\"\\r\\n    assert (len(table) > 1), \"Table must have more than 1 row\"\\r\\n    \\r\\n    k = hypers[\\'max-depth\\'] if \\'max-depth\\' in hypers else min(4, len(choices))\\r\\n    gig_cutoff = hypers[\\'gig-cutoff\\'] if \\'gig-cutoff\\' in hypers else 0.0\\r\\n    \\r\\n    def iterative_build(k):\\r\\n        columns_sorted = find_best_splitter(table, choices, target)\\r\\n        (best_column, gig_value) = columns_sorted[0]\\r\\n        \\r\\n        #Note I add _1 or _0 to make it more readable for debugging\\r\\n        current_paths = [{\\'conjunction\\': [(best_column+\\'_1\\', build_pred(best_column, 1))],\\r\\n                          \\'prediction\\': None,\\r\\n                          \\'gig_score\\': gig_value},\\r\\n                         {\\'conjunction\\': [(best_column+\\'_0\\', build_pred(best_column, 0))],\\r\\n                          \\'prediction\\': None,\\r\\n                          \\'gig_score\\': gig_value}\\r\\n                        ]\\r\\n        k -= 1  # we just built a level as seed so subtract 1 from k\\r\\n        tree_paths = []  # add completed paths here\\r\\n        \\r\\n        while k>0:\\r\\n            new_paths = []\\r\\n            for path in current_paths:\\r\\n                old_conjunction = path[\\'conjunction\\']  # a list of (name, lambda)\\r\\n                before_table = generate_table(table, old_conjunction)  #the subtable the current conjunct leads to\\r\\n                columns_sorted = find_best_splitter(before_table, choices, target)\\r\\n                (best_column, gig_value) = columns_sorted[0]\\r\\n                if gig_value > gig_cutoff:\\r\\n                    new_path_1 = {\\'conjunction\\': old_conjunction + [(best_column+\\'_1\\', build_pred(best_column, 1))],\\r\\n                                \\'prediction\\': None,\\r\\n                                 \\'gig_score\\': gig_value}\\r\\n                    new_paths.append( new_path_1 ) #true\\r\\n                    new_path_0 = {\\'conjunction\\': old_conjunction + [(best_column+\\'_0\\', build_pred(best_column, 0))],\\r\\n                                \\'prediction\\': None,\\r\\n                                 \\'gig_score\\': gig_value}\\r\\n                    new_paths.append( new_path_0 ) #false\\r\\n                else:\\r\\n                    #not worth splitting so complete the path with a prediction\\r\\n                    path[\\'prediction\\'] = compute_prediction(before_table, target)\\r\\n                    tree_paths.append(path)\\r\\n            #end for loop\\r\\n            \\r\\n            current_paths = new_paths\\r\\n            if current_paths != []:\\r\\n                k -= 1\\r\\n            else:\\r\\n                break  # nothing left to extend so have copied all paths to tree_paths\\r\\n        #end while loop\\r\\n\\r\\n        #Generate predictions for all paths that have None\\r\\n        for path in current_paths:\\r\\n            conjunction = path[\\'conjunction\\']\\r\\n            before_table = generate_table(table, conjunction)\\r\\n            path[\\'prediction\\'] = compute_prediction(before_table, target)\\r\\n            tree_paths.append(path)\\r\\n        return tree_paths\\r\\n\\r\\n    return {\\'paths\\': iterative_build(k), \\'weight\\': None}\\r\\n\\r\\ndef tree_predictor(row, tree):\\r\\n    \\r\\n    #go through each path, one by one (could use a map instead of for loop?)\\r\\n    for path in tree[\\'paths\\']:\\r\\n        conjuncts = path[\\'conjunction\\']\\r\\n        result = map(lambda tuple: tuple[1](row), conjuncts)  # potential to be parallelized\\r\\n        if all(result):\\r\\n            return path[\\'prediction\\']\\r\\n    raise LookupError(\\'No true paths found for row: \\' + str(row))\\r\\n\\r\\ndef path_id(row, tree):\\r\\n  \\r\\n    assert (len(tree[\\'paths\\']) > 0), \"Tree must have at least one path\"\\r\\n   # count_dict = {}\\r\\n    for path in tree[\\'paths\\']:\\r\\n      conjuncts = path[\\'conjunction\\']\\r\\n      result = map(lambda tuple: tuple[1](row), conjuncts)  # potential to be parallelized\\r\\n      if all(result):\\r\\n        return tree[\\'paths\\'].index(path)\\r\\n\\r\\ndef reorder_paths(table, tree):\\r\\n  pcount = table.apply(lambda row: path_id(row,tree), axis=1)\\r\\n  test = pcount.value_counts()\\r\\n  t = sorted(test.items(), key=lambda x: x[1], reverse= True)\\r\\n  new_paths =[]\\r\\n  old_paths = tree[\\'paths\\']\\r\\n  print(t)\\r\\n  for i,j in t:\\r\\n    old_path = old_paths[i]\\r\\n    new_paths.append(old_path)\\r\\n  \\r\\n  return new_paths\\r\\n\\r\\ndef produce_scores(table, tree, target):\\r\\n    scratch_table = pd.DataFrame(columns=[\\'prediction\\', \\'actual\\'])\\r\\n    scratch_table[\\'prediction\\'] = table.apply(lambda row: tree_predictor(row, tree), axis=1)\\r\\n    scratch_table[\\'actual\\'] = table[target]  # just copy the target column\\r\\n    cases = scratch_table.apply(lambda row: predictor_case(row, pred=\\'prediction\\', target=\\'actual\\'), axis=1)\\r\\n    vc = cases.value_counts()\\r\\n    return [accuracy(vc), f1(vc), informedness(vc)]\\r\\n\\r\\ndef compute_training(slices, left_out):\\r\\n    training_slices = []\\r\\n    for i,slice in enumerate(slices):\\r\\n        if i == left_out:\\r\\n            continue\\r\\n        training_slices.append(slices[i])\\r\\n    return pd.concat(training_slices)  # note we are returning a table (DataFrame)\\r\\n\\r\\ndef k_fold(table, k, target, hypers, candidate_columns):\\r\\n  \\r\\n    #set up the table where we will record fold results\\r\\n    result_columns = [\\'name\\',  \\'accuracy\\', \\'f1\\', \\'informedness\\']\\r\\n    k_fold_results_table = pd.DataFrame(columns=result_columns)\\r\\n    \\r\\n    #generate the slices\\r\\n    total_len = len(table.index)\\r\\n    slice_size = int(total_len/(1.0*k))\\r\\n    slices = []\\r\\n    for i in range(k-1):\\r\\n        a_slice =  table[i*slice_size:(i+1)*slice_size]\\r\\n        slices.append( a_slice )\\r\\n    slices.append( table[(k-1)*slice_size:] )  # whatever is left\\r\\n    \\r\\n    #generate test results\\r\\n    all_scores = []  #keep track of all k results\\r\\n    for i in range(k):\\r\\n        test_table = slices[i]\\r\\n        train_table = compute_training(slices, i)\\r\\n        fold_tree = build_tree_iter(train_table, candidate_columns, target, hypers)  # train\\r\\n        scores = produce_scores(test_table, fold_tree, target)  # test\\r\\n        results_row = {\\'name\\': \\'fold_\\'+str(i), \\'accuracy\\': scores[0], \\'f1\\': scores[1], \\'informedness\\': scores[2]}\\r\\n        k_fold_results_table = k_fold_results_table.append(results_row,ignore_index=True)\\r\\n        all_scores.append(scores)\\r\\n    \\r\\n    #compute average of all folds\\r\\n    avg_scores = tuple(reduce(lambda total, triple: np.add(triple, total), all_scores)/k)\\r\\n    results_row = {\\'name\\': \\'average\\', \\'accuracy\\': avg_scores[0], \\'f1\\': avg_scores[1], \\'informedness\\': avg_scores[2]}\\r\\n    k_fold_results_table = k_fold_results_table.append(results_row,ignore_index=True)\\r\\n    \\r\\n    #note that I add the meta comment as last step to avoid it being wiped out\\r\\n    k_fold_results_table.meta = SimpleNamespace()\\r\\n    k_fold_results_table.meta.hypers  = hypers # adds comment to remind me of hyper params used\\r\\n    \\r\\n    return k_fold_results_table\\r\\n\\r\\ndef k_fold_random(table, k, target, hypers, candidate_columns):\\r\\n  table = shuffle(table)\\r\\n\\r\\n  total_len = len(table.index)\\r\\n  split_size = int(total_len/(1.0*k))\\r\\n  slices = []\\r\\n  \\r\\n  result_columns = [\\'name\\',  \\'accuracy\\', \\'f1\\', \\'informedness\\']\\r\\n  k_fold_results_table = pd.DataFrame(columns=result_columns)\\r\\n\\r\\n#generate the slices\\r\\n  for i in range(k-1):\\r\\n      a_slice =  table[i*split_size:(i+1)*split_size]\\r\\n      slices.append( a_slice )\\r\\n  slices.append( table[(k-1)*split_size:] )\\r\\n  \\r\\n  verify_unique(slices)  # should see 614 length and empty sets all the way down\\r\\n  \\r\\n  all_scores = []  #keep track of all k results\\r\\n  for i in range(k):\\r\\n    test_table = slices[i]\\r\\n    train_table = compute_training(slices, i)\\r\\n    fold_tree = build_tree_iter(train_table, candidate_columns, target, hypers)  # train\\r\\n    scores = produce_scores(test_table, fold_tree, target)  # test\\r\\n    results_row = {\\'name\\': \\'fold_\\'+str(i), \\'accuracy\\': scores[0], \\'f1\\': scores[1], \\'informedness\\': scores[2]}\\r\\n    k_fold_results_table = k_fold_results_table.append(results_row,ignore_index=True)\\r\\n    all_scores.append(scores)\\r\\n    \\r\\n    #compute average of all folds\\r\\n  avg_scores = tuple(reduce(lambda total, triple: np.add(triple, total), all_scores)/k)\\r\\n  results_row = {\\'name\\': \\'average\\', \\'accuracy\\': avg_scores[0], \\'f1\\': avg_scores[1], \\'informedness\\': avg_scores[2]}\\r\\n  k_fold_results_table = k_fold_results_table.append(results_row,ignore_index=True)\\r\\n    \\r\\n    #note that I add the meta comment as last step to avoid it being wiped out\\r\\n  k_fold_results_table.meta = SimpleNamespace()\\r\\n  k_fold_results_table.meta.hypers  = hypers # adds comment to remind me of hyper params used\\r\\n    \\r\\n  return k_fold_results_table\\r\\n\\r\\ndef verify_unique(slices):\\r\\n    print((\\'total length all slices\\', sum([len(s) for s in slices])))\\r\\n    for i, a_slice in enumerate(slices[:-1]):\\r\\n        a_set = set(a_slice.index)\\r\\n        for j, b_slice in enumerate(slices[i+1:]):\\r\\n            b_set = set(b_slice.index)\\r\\n            int_set = a_set.intersection(b_set)  # should be empty set as result\\r\\n            print((i,j+i+1,int_set))\\r\\n    return None\\r\\n\\r\\ndef vote_taker(row, forest):\\r\\n    votes = {0:0, 1:0}\\r\\n    for tree in forest:\\r\\n        prediction = tree_predictor(row, tree)\\r\\n        votes[prediction] += 1\\r\\n    winner = 1 if votes[1]>votes[0] else 0  #ties go to 0\\r\\n    return winner\\r\\n\\r\\ndef forest_scores(table, forest, target):\\r\\n    scratch_table = pd.DataFrame(columns=[\\'prediction\\', \\'actual\\'])\\r\\n    scratch_table[\\'prediction\\'] = table.apply(lambda row: vote_taker(row, forest), axis=1)  #only change is to call vote_taker\\r\\n    scratch_table[\\'actual\\'] = table[target]  # just copy the target column\\r\\n    cases = scratch_table.apply(lambda row: predictor_case(row, pred=\\'prediction\\', target=\\'actual\\'), axis=1)\\r\\n    vc = cases.value_counts()\\r\\n    return [accuracy(vc), f1(vc), informedness(vc)]\\r\\n\\r\\ndef forest_builder(table, column_choices, target, hypers):\\r\\n\\r\\n    tree_n = 5 if \\'total-trees\\' not in hypers else hypers[\\'total-trees\\']\\r\\n    m = int(len(column_choices)**.5) if \\'m\\' not in hypers else hypers[\\'m\\']\\r\\n    k = hypers[\\'max-depth\\'] if \\'max-depth\\' in hypers else min(2, len(column_choices))\\r\\n    gig_cutoff = hypers[\\'gig-cutoff\\'] if \\'gig-cutoff\\' in hypers else 0.0\\r\\n    rgen = hypers[\\'random-state\\'] if \\'random-state\\' in hypers else 0  #an int will work as seed with the sample method.\\r\\n\\r\\n    #build a single tree of depth n - call it multiple times to build multiple trees\\r\\n    def iterative_build(n):\\r\\n        train = table.sample(frac=1.0, replace=True, random_state=rgen)\\r\\n        train = train.reset_index()\\r\\n        left_out = table.loc[~table.index.isin(train[\\'index\\'])]\\r\\n        left_out = left_out.reset_index() # this gives us the old index in its own column\\r\\n        oob_list = left_out[\\'index\\'].tolist()  # list of row indices from original titanic table\\r\\n        \\r\\n        rcols = random.sample(column_choices, m)  # subspcace sampling - uses random.seed, not rng\\r\\n        columns_sorted = find_best_splitter(train, rcols, target)\\r\\n        (best_column, gig_value) = columns_sorted[0]\\r\\n\\r\\n        #Note I add _1 or _0 to make it more readable for debugging\\r\\n        current_paths = [{\\'conjunction\\': [(best_column+\\'_1\\', build_pred(best_column, 1))],\\r\\n                          \\'prediction\\': None,\\r\\n                          \\'gig_score\\': gig_value},\\r\\n                         {\\'conjunction\\': [(best_column+\\'_0\\', build_pred(best_column, 0))],\\r\\n                          \\'prediction\\': None,\\r\\n                          \\'gig_score\\': gig_value}\\r\\n                        ]\\r\\n        n -= 1  # we just built a level as seed so subtract 1 from n\\r\\n        tree_paths = []  # add completed paths here\\r\\n\\r\\n        while n>0:\\r\\n            new_paths = []\\r\\n            for path in current_paths:\\r\\n                conjunct = path[\\'conjunction\\']  # a list of (name, lambda)\\r\\n                before_table = generate_table(train, conjunct)  #the subtable the current conjunct leads to\\r\\n                rcols = random.sample(column_choices, m)  # subspace\\r\\n                columns_sorted = find_best_splitter(before_table, rcols, target)\\r\\n                (best_column, gig_value) = columns_sorted[0]\\r\\n                if gig_value > gig_cutoff:\\r\\n                    new_path_1 = {\\'conjunction\\': conjunct + [(best_column+\\'_1\\', build_pred(best_column, 1))],\\r\\n                                \\'prediction\\': None,\\r\\n                                 \\'gig_score\\': gig_value}\\r\\n                    new_paths.append( new_path_1 ) #true\\r\\n                    new_path_0 = {\\'conjunction\\': conjunct + [(best_column+\\'_0\\', build_pred(best_column, 0))],\\r\\n                                \\'prediction\\': None,\\r\\n                                 \\'gig_score\\': gig_value\\r\\n                                 }\\r\\n                    new_paths.append( new_path_0 ) #false\\r\\n                else:\\r\\n                    #not worth splitting so complete the path with a prediction\\r\\n                    path[\\'prediction\\'] = compute_prediction(before_table, target)\\r\\n                    tree_paths.append(path)\\r\\n            #end for loop\\r\\n\\r\\n            current_paths = new_paths\\r\\n            if current_paths != []:\\r\\n                n -= 1\\r\\n            else:\\r\\n                break  # nothing left to extend so have copied all paths to tree_paths\\r\\n        #end while loop\\r\\n\\r\\n        #Generate predictions for all paths that have None\\r\\n        for path in current_paths:\\r\\n            conjunct = path[\\'conjunction\\']\\r\\n            before_table = generate_table(train, conjunct)\\r\\n            path[\\'prediction\\'] = compute_prediction(before_table, target)\\r\\n            tree_paths.append(path)\\r\\n        return (tree_paths, oob_list)\\r\\n    \\r\\n    #let\\'s build a forest\\r\\n    forest = []\\r\\n    for i in range(tree_n):\\r\\n        (paths, oob) = iterative_build(k)  #always use k for now\\r\\n        forest.append({\\'paths\\': paths, \\'weight\\': None, \\'oob\\': oob})\\r\\n        \\r\\n    return forest\\r\\n\\r\\ndef oob_test(forest):\\r\\n  outofbag_list = []\\r\\n  for tree in forest:\\r\\n    outofbag_list += tree[\\'oob\\']\\r\\n  outofbag_list = list(set(outofbag_list))\\r\\n  testing_table = loan_table.loc[outofbag_list]\\r\\n  testing_table = testing_table.reset_index()\\r\\n  return testing_table\\r\\n\\r\\ndef oob_vote_taker(row, forest):\\r\\n  votes = {0:0, 1:0}\\r\\n  for tree in forest:\\r\\n    if row[\\'index\\'] in tree[\\'oob\\']:\\r\\n      prediction = tree_predictor(row, tree)\\r\\n      votes[prediction] += 1\\r\\n  winner = 1 if votes[1]>votes[0] else 0  #ties go to 0\\r\\n  return winner\\r\\n\\r\\ndef oob_forest_scores(table, forest, target):\\r\\n    scratch_table = pd.DataFrame(columns=[\\'prediction\\', \\'actual\\'])\\r\\n    scratch_table[\\'prediction\\'] = table.apply(lambda row: oob_vote_taker(row, forest), axis=1)  #only change is to call vote_taker\\r\\n    scratch_table[\\'actual\\'] = table[target]  # just copy the target column\\r\\n    cases = scratch_table.apply(lambda row: predictor_case(row, pred=\\'prediction\\', target=\\'actual\\'), axis=1)\\r\\n    vc = cases.value_counts()\\r\\n    return [accuracy(vc), f1(vc), informedness(vc)]\\r\\n\\r\\n\\r\\ndef euclidean(v1, v2):\\r\\n    dist = [(a - b)**2 for a, b in zip(v1, v2)]\\r\\n    dist = math.sqrt(sum(dist))\\r\\n    return dist\\r\\n\\r\\ndef knn(row_index,table,columns,k,target):#provide prediction for row given K-NN algorithm. Only use values in columns.\\r\\n  distances = []\\r\\n  row1 = table[columns].iloc[row_index].tolist()\\r\\n  for index, row in table.iterrows():\\r\\n    if index == row_index:\\r\\n      continue\\r\\n    distances.append((index,euclidean(row1,row[columns].tolist())))\\r\\n  distances.sort(key=operator.itemgetter(1))\\r\\n  \\r\\n  votes = []\\r\\n  for (i,j) in distances[:k]:\\r\\n    votes.append(table[target].iloc[i])\\r\\n\\r\\n  return max(set(votes), key=votes.count)\\r\\n\\r\\ndef knn_tester(table,k,columns, target):\\r\\n  all_votes = []\\r\\n  for n, row in table.iterrows():\\r\\n    all_votes.append(knn(n,table,columns,k,target))\\r\\n  table[\\'new_col\\'] = all_votes\\r\\n  table[\\'vote_type\\'] = table.apply(lambda row: predictor_case(row, pred=\\'new_col\\', target=target),axis=1)\\r\\n  p1_types = table[\\'vote_type\\'].value_counts()\\r\\n  return accuracy(p1_types)\\r\\n'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "a3CXUrUXCoXE",
        "colab_type": "code",
        "outputId": "8cd73004-705b-4df7-ba0f-4668de84c2fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "cell_type": "code",
      "source": [
        "from library_w19_week7 import *\n",
        "%who function"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy\t build_pred\t build_tree_iter\t compute_prediction\t compute_training\t euclidean\t f1\t find_best_splitter\t forest_builder\t \n",
            "forest_scores\t generate_table\t gig\t gini\t informedness\t k_fold\t k_fold_random\t knn\t knn_tester\t \n",
            "oob_forest_scores\t oob_test\t oob_vote_taker\t path_id\t predictor_case\t probabilities\t produce_scores\t reorder_paths\t tree_predictor\t \n",
            "verify_unique\t vote_taker\t \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "aEW8foPAm91g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_columns', None)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mYPJRcSZsznx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h2>Columns used in all questions</h2>\n",
        "\n",
        "We will use 5 columns from the table to make predictions on `adopted`."
      ]
    },
    {
      "metadata": {
        "id": "3TDm9WllKCAv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "usable_columns = [\n",
        " 'n/s', 'mix', 'type_Cat', 'type_Dog', 'no_name'\n",
        "]\n",
        "\n",
        "target = 'adopted'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "843csVX-py7C"
      },
      "cell_type": "markdown",
      "source": [
        "<h1>\n",
        "Part 1. Explore random forest behavior\n",
        "</h1>\n",
        "<div class=h1_cell>\n",
        "<p>\n",
        "For prediction purposes, we have been treating a forest as a single predictor. It does call on its trees to get a prediction, but we don't see that. All we see is the final prediction. I'd like to dig deeper into individual tree behavior. I'll ask you to complete a set of programming problems to do this.\n",
        "</div>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "l9S58jH5py7D"
      },
      "cell_type": "markdown",
      "source": [
        "<h2>\n",
        "Problem 1. Build a matrix of tree predictions\n",
        "</h2>\n",
        "<div class=h1_cell>\n",
        "<p>\n",
        "The matrix will be a list of lists. Let's say the forest we are working with has 11 trees. Then the first list will be the predictions of the 11 trees for row 0 of the shelter table, i.e., it will be a list of 11 binary values. The next list will be the 11 predictions for row 1 of the shelter table. Given that we have 1000 rows in the shelter table, we will have 1000 lists in our outer list.\n",
        "<p>\n",
        "Let's say I store my matrix in `all_trees`. Then `all_trees[i][j]` will represent the vote of the jth tree for row i.\n",
        "  <p>\n",
        "    Here is what you should see for the first 10 rows.\n",
        "<p>\n",
        "<img src='https://www.dropbox.com/s/zwde42yc2z2lq4j/Screenshot%202019-02-18%2009.44.33.png?raw=1'>\n",
        "\n",
        "</div>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "kr4hJ08Tpy7D"
      },
      "cell_type": "markdown",
      "source": [
        "<h2>\n",
        "Here is forest to test on\n",
        "</h2>\n",
        "<div class=h1_cell>\n",
        "<p>\n",
        "  But first set random seeds so you get same results as mine.\n",
        "</div>"
      ]
    },
    {
      "metadata": {
        "id": "NN01O5OJqioB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "rng = np.random.RandomState(24)  #Will pass as arg to pandas sample method\n",
        "random.seed(2000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "fce890c5-5bae-403f-bb7d-fd50ab5d0501",
        "id": "GysL7AY8py7N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "forest11 = forest_builder(shelter_table, usable_columns, target, hypers={'total-trees':11, 'random-state':rng})\n",
        "len(forest11)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "DD3xu8n7py7O",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "all_trees = []\n",
        "for index, row in shelter_table.iterrows():\n",
        "  temp_list = []\n",
        "  for tree in forest11:\n",
        "    prediction = tree_predictor(row,tree)\n",
        "    temp_list.append(prediction)\n",
        "  all_trees.append(temp_list)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "boQlUeSwBiba",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "3b9a33ec-2e4c-46d4-fa9e-caef50b2dac2",
        "id": "UjMSCnflpy7R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "cell_type": "code",
      "source": [
        "all_trees[:10]  #first 10 rows in voting matrix\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0],\n",
              " [1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1],\n",
              " [0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0],\n",
              " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1],\n",
              " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0],\n",
              " [0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "_F2mzKWhpy7a"
      },
      "cell_type": "markdown",
      "source": [
        "<h2>\n",
        "Problem 2: find the rows where all trees have the same answer\n",
        "</h2>\n",
        "<div class=h1_cell>\n",
        "<p>\n",
        "Right or wrong, they are unanimous. Place your answer in `unan_rows`.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "metadata": {
        "id": "ag-U8V-JEaSN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Stack overflow\n",
        "def all_same(items):\n",
        "    return all(x == items[0] for x in items)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CdFseBGJFqEJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "all_same(all_trees[3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "d77xY8cBpy7c",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def unanimous_rows(vote_matrix):\n",
        "  results = []\n",
        "  for item in range(len(vote_matrix)-1):\n",
        "    if all_same(vote_matrix[item]):\n",
        "      results.append(item)\n",
        "  return results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "fs3ODoFhpy7k",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "unan_rows = unanimous_rows(all_trees)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "fbe38ddb-00bf-4c18-fa79-2cac640461f7",
        "id": "-bOH640Jpy7m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(unan_rows)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "244"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "P6oMD3orBmLh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B2nxH1pBmWYS",
        "colab_type": "code",
        "outputId": "2737e7ed-7ff7-4e50-f9cb-2b4a3cc2f749",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "print(unan_rows)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3, 5, 7, 10, 16, 17, 20, 31, 35, 37, 39, 41, 43, 47, 49, 50, 52, 55, 57, 64, 67, 68, 76, 77, 81, 83, 87, 88, 98, 102, 103, 113, 114, 115, 117, 123, 127, 137, 138, 147, 149, 156, 157, 158, 162, 164, 170, 179, 184, 187, 199, 200, 210, 214, 216, 218, 221, 230, 233, 239, 244, 246, 248, 256, 268, 272, 273, 277, 279, 280, 283, 285, 286, 294, 300, 312, 313, 318, 321, 326, 330, 336, 337, 339, 341, 343, 345, 347, 351, 356, 363, 366, 370, 382, 385, 387, 388, 391, 393, 399, 409, 418, 423, 428, 433, 439, 442, 443, 446, 448, 449, 454, 456, 458, 459, 464, 468, 473, 474, 478, 483, 487, 491, 493, 497, 498, 500, 505, 507, 508, 509, 511, 517, 522, 525, 527, 542, 558, 559, 562, 563, 566, 570, 576, 581, 587, 589, 593, 599, 600, 602, 603, 604, 609, 612, 613, 617, 619, 623, 625, 630, 632, 642, 643, 646, 647, 658, 666, 672, 676, 682, 700, 707, 712, 713, 722, 724, 726, 732, 738, 741, 745, 750, 751, 753, 754, 760, 761, 766, 768, 775, 781, 785, 787, 798, 802, 803, 804, 806, 808, 809, 811, 813, 818, 829, 831, 832, 834, 841, 843, 844, 852, 862, 863, 870, 877, 880, 886, 887, 893, 896, 910, 911, 924, 925, 929, 931, 938, 939, 942, 949, 950, 951, 956, 957, 968, 971, 980, 981, 986, 994, 996, 997, 998]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "zfxIr9ULpy7o"
      },
      "cell_type": "markdown",
      "source": [
        "<h2>\n",
        "Problem 3: find the trees that give the same answer for all rows\n",
        "</h2>\n",
        "<div class=h1_cell>\n",
        "<p>\n",
        "Which trees, if any, always produce the same prediction. Place your answer in `constant_trees`. The values in the list are tree indices.\n",
        "</div>"
      ]
    },
    {
      "metadata": {
        "id": "hf-cNfXFGetF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def never_change(vote_matrix):\n",
        "  constants = []\n",
        "  trees = []\n",
        "  for item in range(len(vote_matrix[0])):\n",
        "    lists = [row[item] for row in vote_matrix]\n",
        "    constants.append(lists)\n",
        "  indexes = 0\n",
        "  for i in constants:\n",
        "    if all_same(i):\n",
        "      trees.append(indexes)\n",
        "    indexes += 1\n",
        "  return trees"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3GJL6UbCHaDA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "18e6326e-e1b7-4e76-b9e2-c789f7dcd1df"
      },
      "cell_type": "code",
      "source": [
        "never_change(all_trees)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "4b5105fc-ab44-4803-88c0-35048e989f3a",
        "id": "V8S2qbF-py7y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "nc = never_change(all_trees)  #no trees are constant\n",
        "nc"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "ilwS1scZzfLH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h2>Problem 4: razor-thin majority</h2>\n",
        "\n",
        "Find the rows that are decided by a bare majority. In the case of 11 trees, 6 vote one way and 5 the other. So majority of only 1 vote."
      ]
    },
    {
      "metadata": {
        "id": "Q_pi4NsX03tl",
        "colab_type": "code",
        "outputId": "1d860f23-3a79-48e8-b431-3911852cd5a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "cell_type": "code",
      "source": [
        "target = 1\n",
        "razor_list = []\n",
        "for item in range(len(all_trees)):\n",
        "  target = 1\n",
        "  count1 = all_trees[item].count(1)\n",
        "  count0 = all_trees[item].count(0)\n",
        "  if (count0 -count1) == target:\n",
        "    razor_list.append(item)\n",
        "print(razor_list)\n",
        "len(razor_list)  #142"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[4, 9, 22, 33, 45, 59, 72, 75, 78, 80, 85, 91, 92, 95, 111, 121, 125, 132, 134, 139, 153, 165, 172, 174, 177, 178, 180, 186, 190, 192, 194, 211, 212, 225, 227, 229, 231, 232, 245, 249, 252, 254, 257, 260, 265, 271, 274, 278, 288, 293, 304, 320, 327, 335, 338, 344, 349, 354, 355, 357, 360, 365, 373, 378, 384, 389, 394, 396, 404, 407, 408, 414, 422, 441, 451, 467, 479, 501, 502, 514, 519, 520, 523, 533, 539, 541, 543, 554, 556, 569, 588, 591, 601, 605, 607, 629, 637, 640, 654, 673, 679, 706, 721, 723, 731, 743, 748, 762, 773, 774, 777, 786, 789, 797, 810, 812, 816, 817, 839, 848, 858, 864, 866, 868, 872, 873, 885, 897, 900, 909, 914, 919, 921, 927, 935, 937, 945, 947, 963, 972, 985, 989]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "142"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "jxLJw_LAFs-H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KqgzYLNN1NKx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h1>Part 2. Explore K-NN behavior</h1>\n",
        "\n",
        "Once you have finished week 7 homework, you can take these on.\n",
        "<p>\n",
        "  Note: you may want to slice off the first 100 rows of the Shelter table for debugging. Remember that KNN runs slow. Once you are happy with results on small table you can try on full table. Up to you."
      ]
    },
    {
      "metadata": {
        "id": "Jci-WoYQkV1E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h2>\n",
        "Problem 5: K-NN voting weights\n",
        "</h2>\n",
        "<div class=h1_cell>\n",
        "<p>\n",
        "Normally the top K rows in K-NN have an equal vote. Let's modify this, I want a new voting scheme as follows:\n",
        "  <pre>\n",
        "  if a row in top-k is within 0 distance from the target row, give it 4 votes.\n",
        "  if a row in top-k is within 1 distance from the target row, give it 3 votes.\n",
        "  if a row in top-k is within 1.5 distance from the target row, give it 2 votes.\n",
        "  else give it 1 vote\n",
        "  </pre>\n",
        "  The row gets its top score. So a row within distance 0 gets exactly 4 votes.\n",
        "  <p>\n",
        "    Add the votes up as normal to get a prediction, ties go to prediction of 0.\n",
        "</div>"
      ]
    },
    {
      "metadata": {
        "id": "EGrAwtKVLbbG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "debug = shelter_table[:100]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RdGGIOxeNJ99",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "array = debug.as_matrix(columns=usable_columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9tdKcdoydHGq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def eucl(v1, v2):\n",
        "    return sum((p-q)**2 for p, q in zip(v1, v2)) ** .5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5EK9SS28LY_H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def knn2(i, table, columns, k, target):\n",
        "  table2 = table.copy()\n",
        "  distances = []\n",
        "  table2 = table.as_matrix(columns=columns)\n",
        "  row1 = table2[i]\n",
        "  target_votes = table[target].tolist()\n",
        "  \n",
        "  for item in range(len(table)):\n",
        "    if item == i:\n",
        "      continue\n",
        "    distances.append((item,eucl(row1,table2[item])))\n",
        "  distances.sort(key=operator.itemgetter(1))\n",
        "  \n",
        "  \n",
        "  votes = []\n",
        "  count0 =0\n",
        "  count1 =0\n",
        "  for (j,k) in distances[:k]:\n",
        "    \n",
        "    if (1<= k <= 0):\n",
        "      if target_votes[j] == 0:\n",
        "        count0 += 3\n",
        "      else:\n",
        "        count1 += 3\n",
        "    if k < 0:\n",
        "      if target_votes[j] == 0:\n",
        "        count0 += 4\n",
        "      else:\n",
        "        count1 += 4\n",
        "    if (1< k < 1.5):\n",
        "      if target_votes[j] == 0:\n",
        "        count0 += 2\n",
        "      else:\n",
        "        count1 += 2\n",
        "    if (k >= 1.5):\n",
        "      if target_votes[j] == 0:\n",
        "        count0 += 1\n",
        "      else:\n",
        "        count1 += 1\n",
        "    \n",
        "  if count0 == count1:\n",
        "    return 0\n",
        "  return 0 if count0 > count1 else 1\n",
        "  \n",
        "  \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "frANxbiU4CBx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def knn3(row_index,table,columns,k,target):#provide prediction for row given K-NN algorithm. Only use values in columns.\n",
        "  table2 = table.copy()\n",
        "  distances = []\n",
        "  table2 = table.as_matrix(columns=columns)\n",
        "  row1 = table2[row_index]\n",
        "  target_votes = table[target].tolist()\n",
        "  for item in range(len(table)):\n",
        "    if item == row_index:\n",
        "      continue\n",
        "    distances.append((item,eucl(row1,table2[item])))\n",
        "  distances.sort(key=operator.itemgetter(1))\n",
        "\n",
        "  votes = []\n",
        "  for (i,j) in distances[:k]:\n",
        "    votes.append(target_votes[i])\n",
        "  \n",
        "\n",
        "  #  votes.append(table.iloc[i][target])\n",
        "  return max(set(votes), key=votes.count)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bFX9_Dsd4gPp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "d175de55-7e42-40a2-9708-7a9948662e53"
      },
      "cell_type": "code",
      "source": [
        "shelter_table[:4]"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AnimalID</th>\n",
              "      <th>Name</th>\n",
              "      <th>DateTime</th>\n",
              "      <th>OutcomeType</th>\n",
              "      <th>OutcomeSubtype</th>\n",
              "      <th>AnimalType</th>\n",
              "      <th>SexuponOutcome</th>\n",
              "      <th>AgeuponOutcome</th>\n",
              "      <th>Breed</th>\n",
              "      <th>Color</th>\n",
              "      <th>adopted</th>\n",
              "      <th>n/s</th>\n",
              "      <th>mix</th>\n",
              "      <th>type_Cat</th>\n",
              "      <th>type_Dog</th>\n",
              "      <th>no_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A671945</td>\n",
              "      <td>Hambone</td>\n",
              "      <td>2/12/2014 18:22:00</td>\n",
              "      <td>Return_to_owner</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Dog</td>\n",
              "      <td>Neutered Male</td>\n",
              "      <td>1 year</td>\n",
              "      <td>Shetland Sheepdog Mix</td>\n",
              "      <td>Brown/White</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A656520</td>\n",
              "      <td>Emily</td>\n",
              "      <td>10/13/2013 12:44:00</td>\n",
              "      <td>Euthanasia</td>\n",
              "      <td>Suffering</td>\n",
              "      <td>Cat</td>\n",
              "      <td>Spayed Female</td>\n",
              "      <td>1 year</td>\n",
              "      <td>Domestic Shorthair Mix</td>\n",
              "      <td>Cream Tabby</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A686464</td>\n",
              "      <td>Pearce</td>\n",
              "      <td>1/31/2015 12:28:00</td>\n",
              "      <td>Adoption</td>\n",
              "      <td>Foster</td>\n",
              "      <td>Dog</td>\n",
              "      <td>Neutered Male</td>\n",
              "      <td>2 years</td>\n",
              "      <td>Pit Bull Mix</td>\n",
              "      <td>Blue/White</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A683430</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7/11/2014 19:09:00</td>\n",
              "      <td>Transfer</td>\n",
              "      <td>Partner</td>\n",
              "      <td>Cat</td>\n",
              "      <td>Intact Male</td>\n",
              "      <td>3 weeks</td>\n",
              "      <td>Domestic Shorthair Mix</td>\n",
              "      <td>Blue Cream</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  AnimalID     Name             DateTime      OutcomeType OutcomeSubtype  \\\n",
              "0  A671945  Hambone   2/12/2014 18:22:00  Return_to_owner            NaN   \n",
              "1  A656520    Emily  10/13/2013 12:44:00       Euthanasia      Suffering   \n",
              "2  A686464   Pearce   1/31/2015 12:28:00         Adoption         Foster   \n",
              "3  A683430      NaN   7/11/2014 19:09:00         Transfer        Partner   \n",
              "\n",
              "  AnimalType SexuponOutcome AgeuponOutcome                   Breed  \\\n",
              "0        Dog  Neutered Male         1 year   Shetland Sheepdog Mix   \n",
              "1        Cat  Spayed Female         1 year  Domestic Shorthair Mix   \n",
              "2        Dog  Neutered Male        2 years            Pit Bull Mix   \n",
              "3        Cat    Intact Male        3 weeks  Domestic Shorthair Mix   \n",
              "\n",
              "         Color  adopted  n/s  mix  type_Cat  type_Dog  no_name  \n",
              "0  Brown/White        0    1    1         0         1        0  \n",
              "1  Cream Tabby        0    1    1         1         0        0  \n",
              "2   Blue/White        1    1    1         0         1        0  \n",
              "3   Blue Cream        0    0    1         1         0        1  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "metadata": {
        "id": "3JPR6b7_5HEP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "shelter_table['adopted'].tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wYd0heK6MtPp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "kn2(4, shelter_table[:10], usable_columns, 10, target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wCafBADm7Nrv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "51986838-bf97-44a6-b70b-74cbea7dbba8"
      },
      "cell_type": "code",
      "source": [
        "knn3(4, shelter_table, usable_columns, 10, target)"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "metadata": {
        "id": "ZyDX4Zrivp7i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h2>Here are my results with k=10</h2>\n",
        "\n",
        "When I compute accuracy with no scaeld-voting, i.e., as normal, I get .621 accuracy.\n",
        "<p>\n",
        "When I compute accuracy with my new scaled-voting scheme, I get .596 accuracy."
      ]
    },
    {
      "metadata": {
        "id": "5-GPwByLIrHS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "all_predictions_w = []\n",
        "all_predictions_r = []\n",
        "for i in range(len(shelter_table)):\n",
        "  all_predictions_w.append(knn2(i, shelter_table, usable_columns, 10, target))\n",
        "  all_predictions_r.append(knn3(i, shelter_table, usable_columns, 10, target))\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8JOyFRzlztQB",
        "colab_type": "code",
        "outputId": "97abb50b-e33b-4577-b7ef-3deb9f1c7d87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "z = list(zip(all_predictions_w, shelter_table[target]))\n",
        "correct = z.count((0,0)) + z.count((1,1))\n",
        "correct/len(shelter_table)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.596"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "metadata": {
        "id": "nkHv9j6A2tC3",
        "colab_type": "code",
        "outputId": "f3cc0c09-d4b9-463a-a5bd-51fcbb5ec891",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "z = list(zip(all_predictions_r, shelter_table[target]))\n",
        "correct = z.count((0,0)) + z.count((1,1))\n",
        "correct/len(shelter_table)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.621"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "metadata": {
        "id": "hwmzC4vIkV1P",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h2>\n",
        "Problem 6: Determine how many times each row was correct\n",
        "</h2>\n",
        "<div class=h1_cell>\n",
        "<p>\n"
      ]
    },
    {
      "metadata": {
        "id": "GnzbWj5SAomY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "sorted(participant_pairs, key=lambda pair: pair[1], reverse=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wSwL7UbjB9ZG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h2>Problem 7: K-NN how many voting blocks</h2>\n",
        "  \n",
        "  I'd like to know how often pairs of rows in the top-k vote the same. So if k is 3, I will have 3 rows in top-3. Call them r1, r2, r3. I would check the following:\n",
        "  \n",
        "1. if (r1,r2) vote the same then I record that.\n",
        "2. if (r1,r3) vote the same then I record that.\n",
        "3. if (r2,r3) vote the same then I record that.\n",
        "\n",
        "I do that for the entire table. What I whould have is a list or dictionary of counts across the entire table. Final I thing I want is sorted list. Here is first part of sorted list I got for k = 10.\n",
        "<pre>\n",
        "[((2, 23), 296),\n",
        " ((2, 26), 296),\n",
        " ((0, 13), 296),\n",
        " ((0, 14), 296),\n",
        " ((0, 19), 296),\n",
        " ((0, 24), 296),\n",
        " ((2, 12), 294),\n",
        " ((8, 26), 288),\n",
        " ((1, 29), 190),\n",
        " ((1, 38), 190),\n",
        " ((1, 21), 189),\n",
        " ((1, 46), 185),\n",
        " ((3, 39), 136),\n",
        " ((3, 41), 136),\n",
        " ((3, 43), 136),\n",
        " ((3, 47), 136),\n",
        " ((7, 50), 134),\n",
        " ((3, 50), 134),\n",
        " ((3, 37), 133),\n",
        " ((7, 47), 129),\n",
        " ((6, 118), 46),\n",
        " ((6, 82), 40),\n",
        " ((4, 229), 19),\n",
        " ((4, 304), 19),\n",
        " ((4, 5), 14),\n",
        " ((5, 449), 13),\n",
        " ((5, 478), 13),\n",
        " ((5, 517), 13),\n",
        "</pre>"
      ]
    },
    {
      "metadata": {
        "id": "TTSmXPs9DcoT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "sorted(block_pairs, key=lambda pair: pair[1], reverse=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uk10ZgNKu08G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}